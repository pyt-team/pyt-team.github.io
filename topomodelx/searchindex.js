Search.setIndex({"alltitles": {"1. Complex Classification": [[82, "1.-Complex-Classification"], [85, "1.-Complex-Classification"]], "2. Node Classification": [[82, "2.-Node-Classification"], [85, "2.-Node-Classification"]], "API Reference": [[4, null]], "Abstract": [[79, "Abstract"]], "Abstract:": [[62, "Abstract:"]], "Additional theoretical clarifications": [[66, "Additional-theoretical-clarifications"], [67, "Additional-theoretical-clarifications"], [72, "Additional-theoretical-clarifications"]], "Aggregation": [[0, null]], "AllSet": [[12, null]], "AllSet_Layer": [[13, null]], "AllSet_Transformer": [[14, null]], "AllSet_Transformer_Layer": [[15, null]], "Base": [[2, null]], "CAN": [[5, null]], "CCXN": [[7, null]], "CCXN_Layer": [[8, null]], "CWN": [[9, null]], "Can_Layer": [[6, null]], "Cell": [[11, null]], "Coadjacency Message Passing Scheme (CMPS):": [[80, "Coadjacency-Message-Passing-Scheme-(CMPS):"]], "Contributing": [[60, null]], "Conv": [[1, null]], "Create Features": [[77, "Create-Features"]], "Create and Train the Neural Network": [[82, "Create-and-Train-the-Neural-Network"], [82, "id2"]], "Create the Neural Network": [[62, "Create-the-Neural-Network"], [63, "Create-the-Neural-Network"], [64, "Create-the-Neural-Network"], [65, "Create-the-Neural-Network"], [66, "Create-the-Neural-Network"], [67, "Create-the-Neural-Network"], [68, "Create-the-Neural-Network"], [70, "Create-the-Neural-Network"], [72, "Create-the-Neural-Network"], [73, "Create-the-Neural-Network"], [75, "Create-the-Neural-Network"], [76, "Create-the-Neural-Network"], [77, "Create-the-Neural-Network"], [78, "Create-the-Neural-Network"], [79, "Create-the-Neural-Network"], [81, "Create-the-Neural-Network"], [83, "Create-the-Neural-Network"]], "Create the Neural Networks": [[80, "Create-the-Neural-Networks"]], "Create the SCNN for node classification": [[85, "Create-the-SCNN-for-node-classification"]], "Creating PyTorch dataloaders": [[86, "Creating-PyTorch-dataloaders"]], "Creating a neural network": [[74, "Creating-a-neural-network"]], "Creating the Neural Network": [[86, "Creating-the-Neural-Network"]], "Cwn_Layer": [[10, null]], "DHGCN": [[16, null]], "DHGCN_Layer": [[17, null]], "Dataset generation": [[86, "Dataset-generation"]], "Deadline": [[59, "deadline"]], "Define Neighborhood Strctures": [[82, "Define-Neighborhood-Strctures"], [82, "id1"], [85, "Define-Neighborhood-Strctures"], [85, "id1"]], "Define Neighbourhood Structures": [[83, "Define-Neighbourhood-Structures"]], "Define binary labels": [[77, "Define-binary-labels"], [78, "Define-binary-labels"], [80, "Define-binary-labels"], [81, "Define-binary-labels"], [82, "Define-binary-labels"], [83, "Define-binary-labels"]], "Define binary labels and Prepare the training-testing split": [[85, "Define-binary-labels-and-Prepare-the-training-testing-split"]], "Define neighborhood structures and lift into hypergraph domain.": [[68, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [70, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [71, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [74, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."], [76, "Define-neighborhood-structures-and-lift-into-hypergraph-domain."]], "Define neighborhood structures.": [[77, "Define-neighborhood-structures."], [78, "Define-neighborhood-structures."], [80, "Define-neighborhood-structures."], [81, "Define-neighborhood-structures."], [84, "Define-neighborhood-structures."]], "Description of the Challenge": [[59, "description-of-the-challenge"]], "Docstring Examples": [[60, "docstring-examples"]], "Evaluating the model on test data": [[86, "Evaluating-the-model-on-test-data"]], "Evaluation": [[59, "evaluation"]], "Generating trajectories": [[86, "Generating-trajectories"]], "Guidelines": [[59, "guidelines"]], "HMPNN": [[18, null]], "HMPNN_Layer": [[19, null]], "HNHN": [[20, null]], "HNHN_Layer": [[21, null]], "HNHN_Layer_Bis": [[22, null]], "How to Submit": [[59, "how-to-submit"]], "Hypergat": [[23, null]], "Hypergat_Layer": [[24, null]], "Hypergraph": [[27, null]], "Hypersage": [[25, null]], "Hypersage_Layer": [[26, null]], "ICML 2023 Topological Deep Learning Challenge": [[59, null]], "Import Karate dataset": [[85, "Import-Karate-dataset"]], "Import data": [[65, "Import-data"], [68, "Import-data"], [70, "Import-data"], [71, "Import-data"], [73, "Import-data"], [74, "Import-data"], [75, "Import-data"], [76, "Import-data"]], "Import dataset": [[77, "Import-dataset"], [78, "Import-dataset"], [80, "Import-dataset"], [81, "Import-dataset"], [83, "Import-dataset"], [84, "Import-dataset"]], "Import shrec dataset": [[82, "Import-shrec-dataset"]], "Import signal": [[77, "Import-signal"], [78, "Import-signal"], [80, "Import-signal"], [81, "Import-signal"], [82, "Import-signal"], [83, "Import-signal"]], "Import signals": [[85, "Import-signals"]], "Intro to Docstrings": [[60, "intro-to-docstrings"]], "Making Changes": [[60, "making-changes"]], "Message Passing": [[3, null]], "Neural Networks": [[36, null]], "Packages & Modules": [[4, null]], "Pre-processing": [[62, "Pre-processing"], [63, "Pre-processing"], [64, "Pre-processing"], [65, "Pre-processing"], [66, "Pre-processing"], [67, "Pre-processing"], [68, "Pre-processing"], [69, "Pre-processing"], [70, "Pre-processing"], [71, "Pre-processing"], [72, "Pre-processing"], [73, "Pre-processing"], [74, "Pre-processing"], [75, "Pre-processing"], [76, "Pre-processing"], [77, "Pre-processing"], [78, "Pre-processing"], [79, "Pre-processing"], [80, "Pre-processing"], [81, "Pre-processing"], [82, "Pre-processing"], [83, "Pre-processing"], [84, "Pre-processing"], [85, "Pre-processing"]], "Questions": [[59, "questions"]], "References": [[84, "References"]], "Run Tests": [[60, "run-tests"]], "Set-up": [[62, "Set-up"], [63, "Set-up"], [64, "Set-up"], [65, "Set-up"]], "Simplicial": [[41, null]], "Simplicial Complex Convolutional Neural Networks [SCCNN]": [[82, "Simplicial-Complex-Convolutional-Neural-Networks-[SCCNN]"]], "Simplicial Convolutional Neural Networks [SCNN]": [[85, "Simplicial-Convolutional-Neural-Networks-[SCNN]"]], "Submission Requirements": [[59, "submission-requirements"]], "Suggestions for further experimentation": [[86, "Suggestions-for-further-experimentation"]], "Table of contents": [[86, "Table-of-contents"]], "The Anatomy of a Docstring": [[60, "the-anatomy-of-a-docstring"]], "The Neural Network": [[79, "The-Neural-Network"]], "The Neural Network:": [[62, "The-Neural-Network:"], [63, "The-Neural-Network:"], [64, "The-Neural-Network:"], [65, "The-Neural-Network:"]], "The Task:": [[62, "The-Task:"], [63, "The-Task:"], [64, "The-Task:"], [65, "The-Task:"], [79, "The-Task:"]], "Topological Neural Nets on Cellular Complexes": [[87, "topological-neural-nets-on-cellular-complexes"]], "Topological Neural Nets on Hypergraphs": [[87, "topological-neural-nets-on-hypergraphs"]], "Topological Neural Nets on Simplicial Complexes": [[87, "topological-neural-nets-on-simplicial-complexes"]], "Train a CW Network (CWN)": [[64, null]], "Train a Cell Attention Network (CAN)": [[62, null]], "Train a Combinatorial Complex Attention Neural Network for Mesh Classification.": [[65, null]], "Train a Convolutional Cell Complex Network (CCXN)": [[63, null]], "Train a DHGCN TNN": [[68, null]], "Train a Hypergraph Message Passing Neural Network (HMPNN)": [[69, null]], "Train a Hypergraph Networks with Hyperedge Neurons (HNHN)": [[70, null]], "Train a Hypergraph Neural Network": [[71, null]], "Train a Hypersage TNN": [[72, null]], "Train a SCCNN": [[82, null]], "Train a Simplex Convolutional Network (SCN) of Rank 2": [[84, null]], "Train a Simplicial 2-complex convolutional neural network (SCConv)": [[83, null]], "Train a Simplicial Attention Network (SAN)": [[79, null]], "Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)": [[80, null]], "Train a Simplicial Complex Convolutional Network (SCCN)": [[81, null]], "Train a Simplicial Complex Net (SCoNe)": [[86, null]], "Train a Simplicial Convolutional Neural Network (SCNN)": [[85, null]], "Train a Simplicial High-Skip Network (HSN)": [[78, null]], "Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)": [[77, null]], "Train a UNIGCN TNN": [[73, null]], "Train a UNIGIN TNN": [[75, null]], "Train a Uni-sage TNN": [[76, null]], "Train a hypergraph neural network using UniGCNII layers": [[74, null]], "Train an All-Set TNN": [[66, null]], "Train an All-Set-Transformer TNN": [[67, null]], "Train the Neural Network": [[62, "Train-the-Neural-Network"], [63, "Train-the-Neural-Network"], [64, "Train-the-Neural-Network"], [65, "Train-the-Neural-Network"], [66, "Train-the-Neural-Network"], [67, "Train-the-Neural-Network"], [68, "Train-the-Neural-Network"], [69, "Train-the-Neural-Network"], [70, "Train-the-Neural-Network"], [71, "Train-the-Neural-Network"], [72, "Train-the-Neural-Network"], [73, "Train-the-Neural-Network"], [75, "Train-the-Neural-Network"], [76, "Train-the-Neural-Network"], [77, "Train-the-Neural-Network"], [78, "Train-the-Neural-Network"], [79, "Train-the-Neural-Network"], [80, "Train-the-Neural-Network"], [81, "Train-the-Neural-Network"], [83, "Train-the-Neural-Network"], [84, "Train-the-Neural-Network"], [85, "Train-the-Neural-Network"]], "Train the Neural Network with Attention": [[63, "Train-the-Neural-Network-with-Attention"]], "Train the SCNN": [[85, "Train-the-SCNN"]], "Training the Neural Network": [[86, "Training-the-Neural-Network"]], "Training the neural network": [[74, "Training-the-neural-network"]], "Tutorials": [[87, null]], "Unigcn": [[28, null]], "Unigcn_Layer": [[29, null]], "Unigcnii": [[30, null]], "Unigcnii_Layer": [[31, null]], "Utils": [[58, null]], "We train the model to perform:": [[82, "We-train-the-model-to-perform:"], [85, "We-train-the-model-to-perform:"]], "Weighted Hodge Laplacians": [[85, "Weighted-Hodge-Laplacians"]], "Write Documentation": [[60, "write-documentation"]], "Write Tests": [[60, "write-tests"]], "\u2b50\ufe0f Publication Outcomes for Participants \u2b50\ufe0f": [[59, "publication-outcomes-for-participants"]], "\ud83c\udf10 TopoModelX (TMX) \ud83c\udf69": [[61, null]], "\ud83d\udd0d References": [[61, "references"]], "\ud83e\uddbe Getting Started": [[61, "getting-started"]]}, "docnames": ["api/base/aggregation", "api/base/conv", "api/base/index", "api/base/message_passing", "api/index", "api/nn/cell/can", "api/nn/cell/can_layer", "api/nn/cell/ccxn", "api/nn/cell/ccxn_layer", "api/nn/cell/cwn", "api/nn/cell/cwn_layer", "api/nn/cell/index", "api/nn/hypergraph/allset", "api/nn/hypergraph/allset_layer", "api/nn/hypergraph/allset_transformer", "api/nn/hypergraph/allset_transformer_layer", "api/nn/hypergraph/dhgcn", "api/nn/hypergraph/dhgcn_layer", "api/nn/hypergraph/hmpnn", "api/nn/hypergraph/hmpnn_layer", "api/nn/hypergraph/hnhn", "api/nn/hypergraph/hnhn_layer", "api/nn/hypergraph/hnhn_layer_bis", "api/nn/hypergraph/hypergat", "api/nn/hypergraph/hypergat_layer", "api/nn/hypergraph/hypersage", "api/nn/hypergraph/hypersage_layer", "api/nn/hypergraph/index", "api/nn/hypergraph/unigcn", "api/nn/hypergraph/unigcn_layer", "api/nn/hypergraph/unigcnii", "api/nn/hypergraph/unigcnii_layer", "api/nn/hypergraph/unigin", "api/nn/hypergraph/unigin_layer", "api/nn/hypergraph/unisage", "api/nn/hypergraph/unisage_layer", "api/nn/index", "api/nn/simplicial/dist2cycle", "api/nn/simplicial/dist2cycle_layer", "api/nn/simplicial/hsn", "api/nn/simplicial/hsn_layer", "api/nn/simplicial/index", "api/nn/simplicial/san", "api/nn/simplicial/san_layer", "api/nn/simplicial/sca_cmps", "api/nn/simplicial/sca_cmps_layer", "api/nn/simplicial/sccn", "api/nn/simplicial/sccn_layer", "api/nn/simplicial/sccnn", "api/nn/simplicial/sccnn_layer", "api/nn/simplicial/scconv", "api/nn/simplicial/scconv_layer", "api/nn/simplicial/scn2", "api/nn/simplicial/scn2_layer", "api/nn/simplicial/scnn", "api/nn/simplicial/scnn_layer", "api/nn/simplicial/scone", "api/nn/simplicial/scone_layer", "api/utils/index", "challenge/index", "contributing/index", "index", "notebooks/cell/can_train", "notebooks/cell/ccxn_train", "notebooks/cell/cwn_train", "notebooks/combinatorial/hmc_train", "notebooks/hypergraph/allset_train", "notebooks/hypergraph/allset_transformer_train", "notebooks/hypergraph/dhgcn_train", "notebooks/hypergraph/hmpnn_train", "notebooks/hypergraph/hnhn_train", "notebooks/hypergraph/hypergat_train", "notebooks/hypergraph/hypersage_train", "notebooks/hypergraph/unigcn_train", "notebooks/hypergraph/unigcnii_train", "notebooks/hypergraph/unigin_train", "notebooks/hypergraph/unisage_train", "notebooks/simplicial/dist2cycle_train", "notebooks/simplicial/hsn_train", "notebooks/simplicial/san_train", "notebooks/simplicial/sca_cmps_train", "notebooks/simplicial/sccn_train", "notebooks/simplicial/sccnn_train", "notebooks/simplicial/scconv_train", "notebooks/simplicial/scn2_train", "notebooks/simplicial/scnn_train", "notebooks/simplicial/scone_train", "tutorials/index"], "envversion": {"nbsphinx": 4, "sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1}, "filenames": ["api/base/aggregation.rst", "api/base/conv.rst", "api/base/index.rst", "api/base/message_passing.rst", "api/index.rst", "api/nn/cell/can.rst", "api/nn/cell/can_layer.rst", "api/nn/cell/ccxn.rst", "api/nn/cell/ccxn_layer.rst", "api/nn/cell/cwn.rst", "api/nn/cell/cwn_layer.rst", "api/nn/cell/index.rst", "api/nn/hypergraph/allset.rst", "api/nn/hypergraph/allset_layer.rst", "api/nn/hypergraph/allset_transformer.rst", "api/nn/hypergraph/allset_transformer_layer.rst", "api/nn/hypergraph/dhgcn.rst", "api/nn/hypergraph/dhgcn_layer.rst", "api/nn/hypergraph/hmpnn.rst", "api/nn/hypergraph/hmpnn_layer.rst", "api/nn/hypergraph/hnhn.rst", "api/nn/hypergraph/hnhn_layer.rst", "api/nn/hypergraph/hnhn_layer_bis.rst", "api/nn/hypergraph/hypergat.rst", "api/nn/hypergraph/hypergat_layer.rst", "api/nn/hypergraph/hypersage.rst", "api/nn/hypergraph/hypersage_layer.rst", "api/nn/hypergraph/index.rst", "api/nn/hypergraph/unigcn.rst", "api/nn/hypergraph/unigcn_layer.rst", "api/nn/hypergraph/unigcnii.rst", "api/nn/hypergraph/unigcnii_layer.rst", "api/nn/hypergraph/unigin.rst", "api/nn/hypergraph/unigin_layer.rst", "api/nn/hypergraph/unisage.rst", "api/nn/hypergraph/unisage_layer.rst", "api/nn/index.rst", "api/nn/simplicial/dist2cycle.rst", "api/nn/simplicial/dist2cycle_layer.rst", "api/nn/simplicial/hsn.rst", "api/nn/simplicial/hsn_layer.rst", "api/nn/simplicial/index.rst", "api/nn/simplicial/san.rst", "api/nn/simplicial/san_layer.rst", "api/nn/simplicial/sca_cmps.rst", "api/nn/simplicial/sca_cmps_layer.rst", "api/nn/simplicial/sccn.rst", "api/nn/simplicial/sccn_layer.rst", "api/nn/simplicial/sccnn.rst", "api/nn/simplicial/sccnn_layer.rst", "api/nn/simplicial/scconv.rst", "api/nn/simplicial/scconv_layer.rst", "api/nn/simplicial/scn2.rst", "api/nn/simplicial/scn2_layer.rst", "api/nn/simplicial/scnn.rst", "api/nn/simplicial/scnn_layer.rst", "api/nn/simplicial/scone.rst", "api/nn/simplicial/scone_layer.rst", "api/utils/index.rst", "challenge/index.rst", "contributing/index.rst", "index.rst", "notebooks/cell/can_train.ipynb", "notebooks/cell/ccxn_train.ipynb", "notebooks/cell/cwn_train.ipynb", "notebooks/combinatorial/hmc_train.ipynb", "notebooks/hypergraph/allset_train.ipynb", "notebooks/hypergraph/allset_transformer_train.ipynb", "notebooks/hypergraph/dhgcn_train.ipynb", "notebooks/hypergraph/hmpnn_train.ipynb", "notebooks/hypergraph/hnhn_train.ipynb", "notebooks/hypergraph/hypergat_train.ipynb", "notebooks/hypergraph/hypersage_train.ipynb", "notebooks/hypergraph/unigcn_train.ipynb", "notebooks/hypergraph/unigcnii_train.ipynb", "notebooks/hypergraph/unigin_train.ipynb", "notebooks/hypergraph/unisage_train.ipynb", "notebooks/simplicial/dist2cycle_train.ipynb", "notebooks/simplicial/hsn_train.ipynb", "notebooks/simplicial/san_train.ipynb", "notebooks/simplicial/sca_cmps_train.ipynb", "notebooks/simplicial/sccn_train.ipynb", "notebooks/simplicial/sccnn_train.ipynb", "notebooks/simplicial/scconv_train.ipynb", "notebooks/simplicial/scn2_train.ipynb", "notebooks/simplicial/scnn_train.ipynb", "notebooks/simplicial/scone_train.ipynb", "tutorials/index.rst"], "indexentries": {"add_self_loops() (in module topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.add_self_loops", false]], "aggr_norm_func() (topomodelx.nn.simplicial.sccnn_layer.sccnnlayer method)": [[49, "topomodelx.nn.simplicial.sccnn_layer.SCCNNLayer.aggr_norm_func", false]], "aggr_norm_func() (topomodelx.nn.simplicial.scnn_layer.scnnlayer method)": [[55, "topomodelx.nn.simplicial.scnn_layer.SCNNLayer.aggr_norm_func", false]], "aggregate() (topomodelx.base.message_passing.messagepassing method)": [[3, "topomodelx.base.message_passing.MessagePassing.aggregate", false]], "aggregate() (topomodelx.nn.hypergraph.hypersage_layer.hypersagelayer method)": [[26, "topomodelx.nn.hypergraph.hypersage_layer.HyperSAGELayer.aggregate", false]], "aggregation (class in topomodelx.base.aggregation)": [[0, "topomodelx.base.aggregation.Aggregation", false]], "allset (class in topomodelx.nn.hypergraph.allset)": [[12, "topomodelx.nn.hypergraph.allset.AllSet", false]], "allsetblock (class in topomodelx.nn.hypergraph.allset_layer)": [[13, "topomodelx.nn.hypergraph.allset_layer.AllSetBlock", false]], "allsetlayer (class in topomodelx.nn.hypergraph.allset_layer)": [[13, "topomodelx.nn.hypergraph.allset_layer.AllSetLayer", false]], "apply_regular_dropout() (topomodelx.nn.hypergraph.hmpnn_layer.hmpnnlayer method)": [[19, "topomodelx.nn.hypergraph.hmpnn_layer.HMPNNLayer.apply_regular_dropout", false]], "attention() (topomodelx.base.message_passing.messagepassing method)": [[3, "topomodelx.base.message_passing.MessagePassing.attention", false]], "attention() (topomodelx.nn.cell.can_layer.multiheadcellattention method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention.attention", false]], "attention() (topomodelx.nn.cell.can_layer.multiheadcellattention_v2 method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention_v2.attention", false]], "attention() (topomodelx.nn.hypergraph.hypergat_layer.hypergatlayer method)": [[24, "topomodelx.nn.hypergraph.hypergat_layer.HyperGATLayer.attention", false]], "broadcast() (in module topomodelx.utils.scatter)": [[58, "topomodelx.utils.scatter.broadcast", false]], "can (class in topomodelx.nn.cell.can)": [[5, "topomodelx.nn.cell.can.CAN", false]], "canlayer (class in topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.CANLayer", false]], "ccxn (class in topomodelx.nn.cell.ccxn)": [[7, "topomodelx.nn.cell.ccxn.CCXN", false]], "ccxnlayer (class in topomodelx.nn.cell.ccxn_layer)": [[8, "topomodelx.nn.cell.ccxn_layer.CCXNLayer", false]], "chebyshev_conv() (topomodelx.nn.simplicial.sccnn_layer.sccnnlayer method)": [[49, "topomodelx.nn.simplicial.sccnn_layer.SCCNNLayer.chebyshev_conv", false]], "chebyshev_conv() (topomodelx.nn.simplicial.scnn_layer.scnnlayer method)": [[55, "topomodelx.nn.simplicial.scnn_layer.SCNNLayer.chebyshev_conv", false]], "compute_normalization_matrices() (topomodelx.nn.hypergraph.hnhn_layer.hnhnlayer method)": [[21, "topomodelx.nn.hypergraph.hnhn_layer.HNHNLayer.compute_normalization_matrices", false]], "compute_projection_matrix() (topomodelx.nn.simplicial.san.san method)": [[42, "topomodelx.nn.simplicial.san.SAN.compute_projection_matrix", false]], "conv (class in topomodelx.base.conv)": [[1, "topomodelx.base.conv.Conv", false]], "cwn (class in topomodelx.nn.cell.cwn)": [[9, "topomodelx.nn.cell.cwn.CWN", false]], "cwnlayer (class in topomodelx.nn.cell.cwn_layer)": [[10, "topomodelx.nn.cell.cwn_layer.CWNLayer", false]], "dist2cycle (class in topomodelx.nn.simplicial.dist2cycle)": [[37, "topomodelx.nn.simplicial.dist2cycle.Dist2Cycle", false]], "dist2cyclelayer (class in topomodelx.nn.simplicial.dist2cycle_layer)": [[38, "topomodelx.nn.simplicial.dist2cycle_layer.Dist2CycleLayer", false]], "forward() (topomodelx.base.aggregation.aggregation method)": [[0, "topomodelx.base.aggregation.Aggregation.forward", false]], "forward() (topomodelx.base.conv.conv method)": [[1, "topomodelx.base.conv.Conv.forward", false]], "forward() (topomodelx.base.message_passing.messagepassing method)": [[3, "topomodelx.base.message_passing.MessagePassing.forward", false]], "forward() (topomodelx.nn.cell.can.can method)": [[5, "topomodelx.nn.cell.can.CAN.forward", false]], "forward() (topomodelx.nn.cell.can_layer.canlayer method)": [[6, "topomodelx.nn.cell.can_layer.CANLayer.forward", false]], "forward() (topomodelx.nn.cell.can_layer.liftlayer method)": [[6, "topomodelx.nn.cell.can_layer.LiftLayer.forward", false]], "forward() (topomodelx.nn.cell.can_layer.multiheadcellattention method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention.forward", false]], "forward() (topomodelx.nn.cell.can_layer.multiheadcellattention_v2 method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention_v2.forward", false]], "forward() (topomodelx.nn.cell.can_layer.multiheadliftlayer method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadLiftLayer.forward", false]], "forward() (topomodelx.nn.cell.can_layer.poollayer method)": [[6, "topomodelx.nn.cell.can_layer.PoolLayer.forward", false]], "forward() (topomodelx.nn.cell.ccxn.ccxn method)": [[7, "topomodelx.nn.cell.ccxn.CCXN.forward", false]], "forward() (topomodelx.nn.cell.ccxn_layer.ccxnlayer method)": [[8, "topomodelx.nn.cell.ccxn_layer.CCXNLayer.forward", false]], "forward() (topomodelx.nn.cell.cwn.cwn method)": [[9, "topomodelx.nn.cell.cwn.CWN.forward", false]], "forward() (topomodelx.nn.cell.cwn_layer.cwnlayer method)": [[10, "topomodelx.nn.cell.cwn_layer.CWNLayer.forward", false]], "forward() (topomodelx.nn.hypergraph.allset.allset method)": [[12, "topomodelx.nn.hypergraph.allset.AllSet.forward", false]], "forward() (topomodelx.nn.hypergraph.allset_layer.allsetblock method)": [[13, "topomodelx.nn.hypergraph.allset_layer.AllSetBlock.forward", false]], "forward() (topomodelx.nn.hypergraph.allset_layer.allsetlayer method)": [[13, "topomodelx.nn.hypergraph.allset_layer.AllSetLayer.forward", false]], "forward() (topomodelx.nn.hypergraph.hmpnn.hmpnn method)": [[18, "topomodelx.nn.hypergraph.hmpnn.HMPNN.forward", false]], "forward() (topomodelx.nn.hypergraph.hmpnn_layer.hmpnnlayer method)": [[19, "topomodelx.nn.hypergraph.hmpnn_layer.HMPNNLayer.forward", false]], "forward() (topomodelx.nn.hypergraph.hnhn.hnhn method)": [[20, "topomodelx.nn.hypergraph.hnhn.HNHN.forward", false]], "forward() (topomodelx.nn.hypergraph.hnhn_layer.hnhnlayer method)": [[21, "topomodelx.nn.hypergraph.hnhn_layer.HNHNLayer.forward", false]], "forward() (topomodelx.nn.hypergraph.hypergat.hypergat method)": [[23, "topomodelx.nn.hypergraph.hypergat.HyperGAT.forward", false]], "forward() (topomodelx.nn.hypergraph.hypergat_layer.hypergatlayer method)": [[24, "topomodelx.nn.hypergraph.hypergat_layer.HyperGATLayer.forward", false]], "forward() (topomodelx.nn.hypergraph.hypersage.hypersage method)": [[25, "topomodelx.nn.hypergraph.hypersage.HyperSAGE.forward", false]], "forward() (topomodelx.nn.hypergraph.hypersage_layer.generalizedmean method)": [[26, "topomodelx.nn.hypergraph.hypersage_layer.GeneralizedMean.forward", false]], "forward() (topomodelx.nn.hypergraph.hypersage_layer.hypersagelayer method)": [[26, "topomodelx.nn.hypergraph.hypersage_layer.HyperSAGELayer.forward", false]], "forward() (topomodelx.nn.hypergraph.unigcn.unigcn method)": [[28, "topomodelx.nn.hypergraph.unigcn.UniGCN.forward", false]], "forward() (topomodelx.nn.hypergraph.unigcn_layer.unigcnlayer method)": [[29, "topomodelx.nn.hypergraph.unigcn_layer.UniGCNLayer.forward", false]], "forward() (topomodelx.nn.hypergraph.unigcnii.unigcnii method)": [[30, "topomodelx.nn.hypergraph.unigcnii.UniGCNII.forward", false]], "forward() (topomodelx.nn.hypergraph.unigcnii_layer.unigcniilayer method)": [[31, "topomodelx.nn.hypergraph.unigcnii_layer.UniGCNIILayer.forward", false]], "forward() (topomodelx.nn.hypergraph.unigin.unigin method)": [[32, "topomodelx.nn.hypergraph.unigin.UniGIN.forward", false]], "forward() (topomodelx.nn.hypergraph.unigin_layer.uniginlayer method)": [[33, "topomodelx.nn.hypergraph.unigin_layer.UniGINLayer.forward", false]], "forward() (topomodelx.nn.hypergraph.unisage.unisage method)": [[34, "topomodelx.nn.hypergraph.unisage.UniSAGE.forward", false]], "forward() (topomodelx.nn.hypergraph.unisage_layer.unisagelayer method)": [[35, "topomodelx.nn.hypergraph.unisage_layer.UniSAGELayer.forward", false]], "forward() (topomodelx.nn.simplicial.dist2cycle.dist2cycle method)": [[37, "topomodelx.nn.simplicial.dist2cycle.Dist2Cycle.forward", false]], "forward() (topomodelx.nn.simplicial.dist2cycle_layer.dist2cyclelayer method)": [[38, "topomodelx.nn.simplicial.dist2cycle_layer.Dist2CycleLayer.forward", false]], "forward() (topomodelx.nn.simplicial.hsn.hsn method)": [[39, "topomodelx.nn.simplicial.hsn.HSN.forward", false]], "forward() (topomodelx.nn.simplicial.hsn_layer.hsnlayer method)": [[40, "topomodelx.nn.simplicial.hsn_layer.HSNLayer.forward", false]], "forward() (topomodelx.nn.simplicial.san.san method)": [[42, "topomodelx.nn.simplicial.san.SAN.forward", false]], "forward() (topomodelx.nn.simplicial.san_layer.sanconv method)": [[43, "topomodelx.nn.simplicial.san_layer.SANConv.forward", false]], "forward() (topomodelx.nn.simplicial.san_layer.sanlayer method)": [[43, "topomodelx.nn.simplicial.san_layer.SANLayer.forward", false]], "forward() (topomodelx.nn.simplicial.sca_cmps.scacmps method)": [[44, "topomodelx.nn.simplicial.sca_cmps.SCACMPS.forward", false]], "forward() (topomodelx.nn.simplicial.sca_cmps_layer.scacmpslayer method)": [[45, "topomodelx.nn.simplicial.sca_cmps_layer.SCACMPSLayer.forward", false]], "forward() (topomodelx.nn.simplicial.sccn.sccn method)": [[46, "topomodelx.nn.simplicial.sccn.SCCN.forward", false]], "forward() (topomodelx.nn.simplicial.sccn_layer.sccnlayer method)": [[47, "topomodelx.nn.simplicial.sccn_layer.SCCNLayer.forward", false]], "forward() (topomodelx.nn.simplicial.sccnn.sccnn method)": [[48, "topomodelx.nn.simplicial.sccnn.SCCNN.forward", false]], "forward() (topomodelx.nn.simplicial.sccnn_layer.sccnnlayer method)": [[49, "topomodelx.nn.simplicial.sccnn_layer.SCCNNLayer.forward", false]], "forward() (topomodelx.nn.simplicial.scconv.scconv method)": [[50, "topomodelx.nn.simplicial.scconv.SCConv.forward", false]], "forward() (topomodelx.nn.simplicial.scconv_layer.scconvlayer method)": [[51, "topomodelx.nn.simplicial.scconv_layer.SCConvLayer.forward", false]], "forward() (topomodelx.nn.simplicial.scn2.scn2 method)": [[52, "topomodelx.nn.simplicial.scn2.SCN2.forward", false]], "forward() (topomodelx.nn.simplicial.scn2_layer.scn2layer method)": [[53, "topomodelx.nn.simplicial.scn2_layer.SCN2Layer.forward", false]], "forward() (topomodelx.nn.simplicial.scnn.scnn method)": [[54, "topomodelx.nn.simplicial.scnn.SCNN.forward", false]], "forward() (topomodelx.nn.simplicial.scnn_layer.scnnlayer method)": [[55, "topomodelx.nn.simplicial.scnn_layer.SCNNLayer.forward", false]], "forward() (topomodelx.nn.simplicial.scone.scone method)": [[56, "topomodelx.nn.simplicial.scone.SCoNe.forward", false]], "forward() (topomodelx.nn.simplicial.scone_layer.sconelayer method)": [[57, "topomodelx.nn.simplicial.scone_layer.SCoNeLayer.forward", false]], "generalizedmean (class in topomodelx.nn.hypergraph.hypersage_layer)": [[26, "topomodelx.nn.hypergraph.hypersage_layer.GeneralizedMean", false]], "generate_complex() (in module topomodelx.nn.simplicial.scone)": [[56, "topomodelx.nn.simplicial.scone.generate_complex", false]], "generate_trajectories() (in module topomodelx.nn.simplicial.scone)": [[56, "topomodelx.nn.simplicial.scone.generate_trajectories", false]], "hmpnn (class in topomodelx.nn.hypergraph.hmpnn)": [[18, "topomodelx.nn.hypergraph.hmpnn.HMPNN", false]], "hmpnnlayer (class in topomodelx.nn.hypergraph.hmpnn_layer)": [[19, "topomodelx.nn.hypergraph.hmpnn_layer.HMPNNLayer", false]], "hnhn (class in topomodelx.nn.hypergraph.hnhn)": [[20, "topomodelx.nn.hypergraph.hnhn.HNHN", false]], "hnhnlayer (class in topomodelx.nn.hypergraph.hnhn_layer)": [[21, "topomodelx.nn.hypergraph.hnhn_layer.HNHNLayer", false]], "hsn (class in topomodelx.nn.simplicial.hsn)": [[39, "topomodelx.nn.simplicial.hsn.HSN", false]], "hsnlayer (class in topomodelx.nn.simplicial.hsn_layer)": [[40, "topomodelx.nn.simplicial.hsn_layer.HSNLayer", false]], "hypergat (class in topomodelx.nn.hypergraph.hypergat)": [[23, "topomodelx.nn.hypergraph.hypergat.HyperGAT", false]], "hypergatlayer (class in topomodelx.nn.hypergraph.hypergat_layer)": [[24, "topomodelx.nn.hypergraph.hypergat_layer.HyperGATLayer", false]], "hypersage (class in topomodelx.nn.hypergraph.hypersage)": [[25, "topomodelx.nn.hypergraph.hypersage.HyperSAGE", false]], "hypersagelayer (class in topomodelx.nn.hypergraph.hypersage_layer)": [[26, "topomodelx.nn.hypergraph.hypersage_layer.HyperSAGELayer", false]], "init_biases() (topomodelx.nn.hypergraph.hnhn_layer.hnhnlayer method)": [[21, "topomodelx.nn.hypergraph.hnhn_layer.HNHNLayer.init_biases", false]], "intra_aggr() (topomodelx.nn.simplicial.sca_cmps_layer.scacmpslayer method)": [[45, "topomodelx.nn.simplicial.sca_cmps_layer.SCACMPSLayer.intra_aggr", false]], "liftlayer (class in topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.LiftLayer", false]], "message() (topomodelx.base.message_passing.messagepassing method)": [[3, "topomodelx.base.message_passing.MessagePassing.message", false]], "message() (topomodelx.nn.cell.can_layer.liftlayer method)": [[6, "topomodelx.nn.cell.can_layer.LiftLayer.message", false]], "message() (topomodelx.nn.cell.can_layer.multiheadcellattention method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention.message", false]], "message() (topomodelx.nn.cell.can_layer.multiheadcellattention_v2 method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention_v2.message", false]], "messagepassing (class in topomodelx.base.message_passing)": [[3, "topomodelx.base.message_passing.MessagePassing", false]], "mlp (class in topomodelx.nn.hypergraph.allset_layer)": [[13, "topomodelx.nn.hypergraph.allset_layer.MLP", false]], "module": [[0, "module-topomodelx.base.aggregation", false], [1, "module-topomodelx.base.conv", false], [3, "module-topomodelx.base.message_passing", false], [5, "module-topomodelx.nn.cell.can", false], [6, "module-topomodelx.nn.cell.can_layer", false], [7, "module-topomodelx.nn.cell.ccxn", false], [8, "module-topomodelx.nn.cell.ccxn_layer", false], [9, "module-topomodelx.nn.cell.cwn", false], [10, "module-topomodelx.nn.cell.cwn_layer", false], [12, "module-topomodelx.nn.hypergraph.allset", false], [13, "module-topomodelx.nn.hypergraph.allset_layer", false], [18, "module-topomodelx.nn.hypergraph.hmpnn", false], [19, "module-topomodelx.nn.hypergraph.hmpnn_layer", false], [20, "module-topomodelx.nn.hypergraph.hnhn", false], [21, "module-topomodelx.nn.hypergraph.hnhn_layer", false], [23, "module-topomodelx.nn.hypergraph.hypergat", false], [24, "module-topomodelx.nn.hypergraph.hypergat_layer", false], [25, "module-topomodelx.nn.hypergraph.hypersage", false], [26, "module-topomodelx.nn.hypergraph.hypersage_layer", false], [28, "module-topomodelx.nn.hypergraph.unigcn", false], [29, "module-topomodelx.nn.hypergraph.unigcn_layer", false], [30, "module-topomodelx.nn.hypergraph.unigcnii", false], [31, "module-topomodelx.nn.hypergraph.unigcnii_layer", false], [32, "module-topomodelx.nn.hypergraph.unigin", false], [33, "module-topomodelx.nn.hypergraph.unigin_layer", false], [34, "module-topomodelx.nn.hypergraph.unisage", false], [35, "module-topomodelx.nn.hypergraph.unisage_layer", false], [37, "module-topomodelx.nn.simplicial.dist2cycle", false], [38, "module-topomodelx.nn.simplicial.dist2cycle_layer", false], [39, "module-topomodelx.nn.simplicial.hsn", false], [40, "module-topomodelx.nn.simplicial.hsn_layer", false], [42, "module-topomodelx.nn.simplicial.san", false], [43, "module-topomodelx.nn.simplicial.san_layer", false], [44, "module-topomodelx.nn.simplicial.sca_cmps", false], [45, "module-topomodelx.nn.simplicial.sca_cmps_layer", false], [46, "module-topomodelx.nn.simplicial.sccn", false], [47, "module-topomodelx.nn.simplicial.sccn_layer", false], [48, "module-topomodelx.nn.simplicial.sccnn", false], [49, "module-topomodelx.nn.simplicial.sccnn_layer", false], [50, "module-topomodelx.nn.simplicial.scconv", false], [51, "module-topomodelx.nn.simplicial.scconv_layer", false], [52, "module-topomodelx.nn.simplicial.scn2", false], [53, "module-topomodelx.nn.simplicial.scn2_layer", false], [54, "module-topomodelx.nn.simplicial.scnn", false], [55, "module-topomodelx.nn.simplicial.scnn_layer", false], [56, "module-topomodelx.nn.simplicial.scone", false], [57, "module-topomodelx.nn.simplicial.scone_layer", false], [58, "module-topomodelx.utils.scatter", false]], "multiheadcellattention (class in topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention", false]], "multiheadcellattention_v2 (class in topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention_v2", false]], "multiheadliftlayer (class in topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadLiftLayer", false]], "normalize_incidence_matrices() (topomodelx.nn.hypergraph.hnhn_layer.hnhnlayer method)": [[21, "topomodelx.nn.hypergraph.hnhn_layer.HNHNLayer.normalize_incidence_matrices", false]], "poollayer (class in topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.PoolLayer", false]], "reset_parameters() (topomodelx.base.message_passing.messagepassing method)": [[3, "topomodelx.base.message_passing.MessagePassing.reset_parameters", false]], "reset_parameters() (topomodelx.nn.cell.can_layer.canlayer method)": [[6, "topomodelx.nn.cell.can_layer.CANLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.cell.can_layer.liftlayer method)": [[6, "topomodelx.nn.cell.can_layer.LiftLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.cell.can_layer.multiheadcellattention method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention.reset_parameters", false]], "reset_parameters() (topomodelx.nn.cell.can_layer.multiheadcellattention_v2 method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadCellAttention_v2.reset_parameters", false]], "reset_parameters() (topomodelx.nn.cell.can_layer.multiheadliftlayer method)": [[6, "topomodelx.nn.cell.can_layer.MultiHeadLiftLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.cell.can_layer.poollayer method)": [[6, "topomodelx.nn.cell.can_layer.PoolLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.hypergraph.allset_layer.allsetblock method)": [[13, "topomodelx.nn.hypergraph.allset_layer.AllSetBlock.reset_parameters", false]], "reset_parameters() (topomodelx.nn.hypergraph.allset_layer.allsetlayer method)": [[13, "topomodelx.nn.hypergraph.allset_layer.AllSetLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.hypergraph.hnhn_layer.hnhnlayer method)": [[21, "topomodelx.nn.hypergraph.hnhn_layer.HNHNLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.hypergraph.hypergat_layer.hypergatlayer method)": [[24, "topomodelx.nn.hypergraph.hypergat_layer.HyperGATLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.hypergraph.unigcn_layer.unigcnlayer method)": [[29, "topomodelx.nn.hypergraph.unigcn_layer.UniGCNLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.hypergraph.unigcnii_layer.unigcniilayer method)": [[31, "topomodelx.nn.hypergraph.unigcnii_layer.UniGCNIILayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.hypergraph.unisage_layer.unisagelayer method)": [[35, "topomodelx.nn.hypergraph.unisage_layer.UniSAGELayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.simplicial.dist2cycle_layer.dist2cyclelayer method)": [[38, "topomodelx.nn.simplicial.dist2cycle_layer.Dist2CycleLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.simplicial.hsn_layer.hsnlayer method)": [[40, "topomodelx.nn.simplicial.hsn_layer.HSNLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.simplicial.san_layer.sanlayer method)": [[43, "topomodelx.nn.simplicial.san_layer.SANLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.simplicial.sca_cmps_layer.scacmpslayer method)": [[45, "topomodelx.nn.simplicial.sca_cmps_layer.SCACMPSLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.simplicial.sccn_layer.sccnlayer method)": [[47, "topomodelx.nn.simplicial.sccn_layer.SCCNLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.simplicial.sccnn_layer.sccnnlayer method)": [[49, "topomodelx.nn.simplicial.sccnn_layer.SCCNNLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.simplicial.scconv_layer.scconvlayer method)": [[51, "topomodelx.nn.simplicial.scconv_layer.SCConvLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.simplicial.scn2_layer.scn2layer method)": [[53, "topomodelx.nn.simplicial.scn2_layer.SCN2Layer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.simplicial.scnn_layer.scnnlayer method)": [[55, "topomodelx.nn.simplicial.scnn_layer.SCNNLayer.reset_parameters", false]], "reset_parameters() (topomodelx.nn.simplicial.scone_layer.sconelayer method)": [[57, "topomodelx.nn.simplicial.scone_layer.SCoNeLayer.reset_parameters", false]], "san (class in topomodelx.nn.simplicial.san)": [[42, "topomodelx.nn.simplicial.san.SAN", false]], "sanconv (class in topomodelx.nn.simplicial.san_layer)": [[43, "topomodelx.nn.simplicial.san_layer.SANConv", false]], "sanlayer (class in topomodelx.nn.simplicial.san_layer)": [[43, "topomodelx.nn.simplicial.san_layer.SANLayer", false]], "scacmps (class in topomodelx.nn.simplicial.sca_cmps)": [[44, "topomodelx.nn.simplicial.sca_cmps.SCACMPS", false]], "scacmpslayer (class in topomodelx.nn.simplicial.sca_cmps_layer)": [[45, "topomodelx.nn.simplicial.sca_cmps_layer.SCACMPSLayer", false]], "scatter() (in module topomodelx.utils.scatter)": [[58, "topomodelx.utils.scatter.scatter", false]], "scatter_add() (in module topomodelx.utils.scatter)": [[58, "topomodelx.utils.scatter.scatter_add", false]], "scatter_mean() (in module topomodelx.utils.scatter)": [[58, "topomodelx.utils.scatter.scatter_mean", false]], "scatter_sum() (in module topomodelx.utils.scatter)": [[58, "topomodelx.utils.scatter.scatter_sum", false]], "sccn (class in topomodelx.nn.simplicial.sccn)": [[46, "topomodelx.nn.simplicial.sccn.SCCN", false]], "sccnlayer (class in topomodelx.nn.simplicial.sccn_layer)": [[47, "topomodelx.nn.simplicial.sccn_layer.SCCNLayer", false]], "sccnn (class in topomodelx.nn.simplicial.sccnn)": [[48, "topomodelx.nn.simplicial.sccnn.SCCNN", false]], "sccnnlayer (class in topomodelx.nn.simplicial.sccnn_layer)": [[49, "topomodelx.nn.simplicial.sccnn_layer.SCCNNLayer", false]], "scconv (class in topomodelx.nn.simplicial.scconv)": [[50, "topomodelx.nn.simplicial.scconv.SCConv", false]], "scconvlayer (class in topomodelx.nn.simplicial.scconv_layer)": [[51, "topomodelx.nn.simplicial.scconv_layer.SCConvLayer", false]], "scn2 (class in topomodelx.nn.simplicial.scn2)": [[52, "topomodelx.nn.simplicial.scn2.SCN2", false]], "scn2layer (class in topomodelx.nn.simplicial.scn2_layer)": [[53, "topomodelx.nn.simplicial.scn2_layer.SCN2Layer", false]], "scnn (class in topomodelx.nn.simplicial.scnn)": [[54, "topomodelx.nn.simplicial.scnn.SCNN", false]], "scnnlayer (class in topomodelx.nn.simplicial.scnn_layer)": [[55, "topomodelx.nn.simplicial.scnn_layer.SCNNLayer", false]], "scone (class in topomodelx.nn.simplicial.scone)": [[56, "topomodelx.nn.simplicial.scone.SCoNe", false]], "sconelayer (class in topomodelx.nn.simplicial.scone_layer)": [[57, "topomodelx.nn.simplicial.scone_layer.SCoNeLayer", false]], "softmax() (in module topomodelx.nn.cell.can_layer)": [[6, "topomodelx.nn.cell.can_layer.softmax", false]], "topomodelx.base.aggregation": [[0, "module-topomodelx.base.aggregation", false]], "topomodelx.base.conv": [[1, "module-topomodelx.base.conv", false]], "topomodelx.base.message_passing": [[3, "module-topomodelx.base.message_passing", false]], "topomodelx.nn.cell.can": [[5, "module-topomodelx.nn.cell.can", false]], "topomodelx.nn.cell.can_layer": [[6, "module-topomodelx.nn.cell.can_layer", false]], "topomodelx.nn.cell.ccxn": [[7, "module-topomodelx.nn.cell.ccxn", false]], "topomodelx.nn.cell.ccxn_layer": [[8, "module-topomodelx.nn.cell.ccxn_layer", false]], "topomodelx.nn.cell.cwn": [[9, "module-topomodelx.nn.cell.cwn", false]], "topomodelx.nn.cell.cwn_layer": [[10, "module-topomodelx.nn.cell.cwn_layer", false]], "topomodelx.nn.hypergraph.allset": [[12, "module-topomodelx.nn.hypergraph.allset", false]], "topomodelx.nn.hypergraph.allset_layer": [[13, "module-topomodelx.nn.hypergraph.allset_layer", false]], "topomodelx.nn.hypergraph.hmpnn": [[18, "module-topomodelx.nn.hypergraph.hmpnn", false]], "topomodelx.nn.hypergraph.hmpnn_layer": [[19, "module-topomodelx.nn.hypergraph.hmpnn_layer", false]], "topomodelx.nn.hypergraph.hnhn": [[20, "module-topomodelx.nn.hypergraph.hnhn", false]], "topomodelx.nn.hypergraph.hnhn_layer": [[21, "module-topomodelx.nn.hypergraph.hnhn_layer", false]], "topomodelx.nn.hypergraph.hypergat": [[23, "module-topomodelx.nn.hypergraph.hypergat", false]], "topomodelx.nn.hypergraph.hypergat_layer": [[24, "module-topomodelx.nn.hypergraph.hypergat_layer", false]], "topomodelx.nn.hypergraph.hypersage": [[25, "module-topomodelx.nn.hypergraph.hypersage", false]], "topomodelx.nn.hypergraph.hypersage_layer": [[26, "module-topomodelx.nn.hypergraph.hypersage_layer", false]], "topomodelx.nn.hypergraph.unigcn": [[28, "module-topomodelx.nn.hypergraph.unigcn", false]], "topomodelx.nn.hypergraph.unigcn_layer": [[29, "module-topomodelx.nn.hypergraph.unigcn_layer", false]], "topomodelx.nn.hypergraph.unigcnii": [[30, "module-topomodelx.nn.hypergraph.unigcnii", false]], "topomodelx.nn.hypergraph.unigcnii_layer": [[31, "module-topomodelx.nn.hypergraph.unigcnii_layer", false]], "topomodelx.nn.hypergraph.unigin": [[32, "module-topomodelx.nn.hypergraph.unigin", false]], "topomodelx.nn.hypergraph.unigin_layer": [[33, "module-topomodelx.nn.hypergraph.unigin_layer", false]], "topomodelx.nn.hypergraph.unisage": [[34, "module-topomodelx.nn.hypergraph.unisage", false]], "topomodelx.nn.hypergraph.unisage_layer": [[35, "module-topomodelx.nn.hypergraph.unisage_layer", false]], "topomodelx.nn.simplicial.dist2cycle": [[37, "module-topomodelx.nn.simplicial.dist2cycle", false]], "topomodelx.nn.simplicial.dist2cycle_layer": [[38, "module-topomodelx.nn.simplicial.dist2cycle_layer", false]], "topomodelx.nn.simplicial.hsn": [[39, "module-topomodelx.nn.simplicial.hsn", false]], "topomodelx.nn.simplicial.hsn_layer": [[40, "module-topomodelx.nn.simplicial.hsn_layer", false]], "topomodelx.nn.simplicial.san": [[42, "module-topomodelx.nn.simplicial.san", false]], "topomodelx.nn.simplicial.san_layer": [[43, "module-topomodelx.nn.simplicial.san_layer", false]], "topomodelx.nn.simplicial.sca_cmps": [[44, "module-topomodelx.nn.simplicial.sca_cmps", false]], "topomodelx.nn.simplicial.sca_cmps_layer": [[45, "module-topomodelx.nn.simplicial.sca_cmps_layer", false]], "topomodelx.nn.simplicial.sccn": [[46, "module-topomodelx.nn.simplicial.sccn", false]], "topomodelx.nn.simplicial.sccn_layer": [[47, "module-topomodelx.nn.simplicial.sccn_layer", false]], "topomodelx.nn.simplicial.sccnn": [[48, "module-topomodelx.nn.simplicial.sccnn", false]], "topomodelx.nn.simplicial.sccnn_layer": [[49, "module-topomodelx.nn.simplicial.sccnn_layer", false]], "topomodelx.nn.simplicial.scconv": [[50, "module-topomodelx.nn.simplicial.scconv", false]], "topomodelx.nn.simplicial.scconv_layer": [[51, "module-topomodelx.nn.simplicial.scconv_layer", false]], "topomodelx.nn.simplicial.scn2": [[52, "module-topomodelx.nn.simplicial.scn2", false]], "topomodelx.nn.simplicial.scn2_layer": [[53, "module-topomodelx.nn.simplicial.scn2_layer", false]], "topomodelx.nn.simplicial.scnn": [[54, "module-topomodelx.nn.simplicial.scnn", false]], "topomodelx.nn.simplicial.scnn_layer": [[55, "module-topomodelx.nn.simplicial.scnn_layer", false]], "topomodelx.nn.simplicial.scone": [[56, "module-topomodelx.nn.simplicial.scone", false]], "topomodelx.nn.simplicial.scone_layer": [[57, "module-topomodelx.nn.simplicial.scone_layer", false]], "topomodelx.utils.scatter": [[58, "module-topomodelx.utils.scatter", false]], "trajectoriesdataset (class in topomodelx.nn.simplicial.scone)": [[56, "topomodelx.nn.simplicial.scone.TrajectoriesDataset", false]], "unigcn (class in topomodelx.nn.hypergraph.unigcn)": [[28, "topomodelx.nn.hypergraph.unigcn.UniGCN", false]], "unigcnii (class in topomodelx.nn.hypergraph.unigcnii)": [[30, "topomodelx.nn.hypergraph.unigcnii.UniGCNII", false]], "unigcniilayer (class in topomodelx.nn.hypergraph.unigcnii_layer)": [[31, "topomodelx.nn.hypergraph.unigcnii_layer.UniGCNIILayer", false]], "unigcnlayer (class in topomodelx.nn.hypergraph.unigcn_layer)": [[29, "topomodelx.nn.hypergraph.unigcn_layer.UniGCNLayer", false]], "unigin (class in topomodelx.nn.hypergraph.unigin)": [[32, "topomodelx.nn.hypergraph.unigin.UniGIN", false]], "uniginlayer (class in topomodelx.nn.hypergraph.unigin_layer)": [[33, "topomodelx.nn.hypergraph.unigin_layer.UniGINLayer", false]], "unisage (class in topomodelx.nn.hypergraph.unisage)": [[34, "topomodelx.nn.hypergraph.unisage.UniSAGE", false]], "unisagelayer (class in topomodelx.nn.hypergraph.unisage_layer)": [[35, "topomodelx.nn.hypergraph.unisage_layer.UniSAGELayer", false]], "update() (topomodelx.base.aggregation.aggregation method)": [[0, "topomodelx.base.aggregation.Aggregation.update", false]], "update() (topomodelx.base.conv.conv method)": [[1, "topomodelx.base.conv.Conv.update", false]], "update() (topomodelx.nn.hypergraph.hypergat_layer.hypergatlayer method)": [[24, "topomodelx.nn.hypergraph.hypergat_layer.HyperGATLayer.update", false]], "update() (topomodelx.nn.hypergraph.hypersage_layer.hypersagelayer method)": [[26, "topomodelx.nn.hypergraph.hypersage_layer.HyperSAGELayer.update", false]], "update() (topomodelx.nn.simplicial.sccnn_layer.sccnnlayer method)": [[49, "topomodelx.nn.simplicial.sccnn_layer.SCCNNLayer.update", false]], "update() (topomodelx.nn.simplicial.scnn_layer.scnnlayer method)": [[55, "topomodelx.nn.simplicial.scnn_layer.SCNNLayer.update", false]], "vectorize_path() (topomodelx.nn.simplicial.scone.trajectoriesdataset method)": [[56, "topomodelx.nn.simplicial.scone.TrajectoriesDataset.vectorize_path", false]], "weight_func() (topomodelx.nn.simplicial.sca_cmps_layer.scacmpslayer method)": [[45, "topomodelx.nn.simplicial.sca_cmps_layer.SCACMPSLayer.weight_func", false]]}, "objects": {"topomodelx.base": [[0, 0, 0, "-", "aggregation"], [1, 0, 0, "-", "conv"], [3, 0, 0, "-", "message_passing"]], "topomodelx.base.aggregation": [[0, 1, 1, "", "Aggregation"]], "topomodelx.base.aggregation.Aggregation": [[0, 2, 1, "", "forward"], [0, 2, 1, "", "update"]], "topomodelx.base.conv": [[1, 1, 1, "", "Conv"]], "topomodelx.base.conv.Conv": [[1, 2, 1, "", "forward"], [1, 2, 1, "", "update"]], "topomodelx.base.message_passing": [[3, 1, 1, "", "MessagePassing"]], "topomodelx.base.message_passing.MessagePassing": [[3, 2, 1, "", "aggregate"], [3, 2, 1, "", "attention"], [3, 2, 1, "", "forward"], [3, 2, 1, "", "message"], [3, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell": [[5, 0, 0, "-", "can"], [6, 0, 0, "-", "can_layer"], [7, 0, 0, "-", "ccxn"], [8, 0, 0, "-", "ccxn_layer"], [9, 0, 0, "-", "cwn"], [10, 0, 0, "-", "cwn_layer"]], "topomodelx.nn.cell.can": [[5, 1, 1, "", "CAN"]], "topomodelx.nn.cell.can.CAN": [[5, 2, 1, "", "forward"]], "topomodelx.nn.cell.can_layer": [[6, 1, 1, "", "CANLayer"], [6, 1, 1, "", "LiftLayer"], [6, 1, 1, "", "MultiHeadCellAttention"], [6, 1, 1, "", "MultiHeadCellAttention_v2"], [6, 1, 1, "", "MultiHeadLiftLayer"], [6, 1, 1, "", "PoolLayer"], [6, 3, 1, "", "add_self_loops"], [6, 3, 1, "", "softmax"]], "topomodelx.nn.cell.can_layer.CANLayer": [[6, 2, 1, "", "forward"], [6, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell.can_layer.LiftLayer": [[6, 2, 1, "", "forward"], [6, 2, 1, "", "message"], [6, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell.can_layer.MultiHeadCellAttention": [[6, 2, 1, "", "attention"], [6, 2, 1, "", "forward"], [6, 2, 1, "", "message"], [6, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell.can_layer.MultiHeadCellAttention_v2": [[6, 2, 1, "", "attention"], [6, 2, 1, "", "forward"], [6, 2, 1, "", "message"], [6, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell.can_layer.MultiHeadLiftLayer": [[6, 2, 1, "", "forward"], [6, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell.can_layer.PoolLayer": [[6, 2, 1, "", "forward"], [6, 2, 1, "", "reset_parameters"]], "topomodelx.nn.cell.ccxn": [[7, 1, 1, "", "CCXN"]], "topomodelx.nn.cell.ccxn.CCXN": [[7, 2, 1, "", "forward"]], "topomodelx.nn.cell.ccxn_layer": [[8, 1, 1, "", "CCXNLayer"]], "topomodelx.nn.cell.ccxn_layer.CCXNLayer": [[8, 2, 1, "", "forward"]], "topomodelx.nn.cell.cwn": [[9, 1, 1, "", "CWN"]], "topomodelx.nn.cell.cwn.CWN": [[9, 2, 1, "", "forward"]], "topomodelx.nn.cell.cwn_layer": [[10, 1, 1, "", "CWNLayer"]], "topomodelx.nn.cell.cwn_layer.CWNLayer": [[10, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph": [[12, 0, 0, "-", "allset"], [13, 0, 0, "-", "allset_layer"], [18, 0, 0, "-", "hmpnn"], [19, 0, 0, "-", "hmpnn_layer"], [20, 0, 0, "-", "hnhn"], [21, 0, 0, "-", "hnhn_layer"], [23, 0, 0, "-", "hypergat"], [24, 0, 0, "-", "hypergat_layer"], [25, 0, 0, "-", "hypersage"], [26, 0, 0, "-", "hypersage_layer"], [28, 0, 0, "-", "unigcn"], [29, 0, 0, "-", "unigcn_layer"], [30, 0, 0, "-", "unigcnii"], [31, 0, 0, "-", "unigcnii_layer"], [32, 0, 0, "-", "unigin"], [33, 0, 0, "-", "unigin_layer"], [34, 0, 0, "-", "unisage"], [35, 0, 0, "-", "unisage_layer"]], "topomodelx.nn.hypergraph.allset": [[12, 1, 1, "", "AllSet"]], "topomodelx.nn.hypergraph.allset.AllSet": [[12, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.allset_layer": [[13, 1, 1, "", "AllSetBlock"], [13, 1, 1, "", "AllSetLayer"], [13, 1, 1, "", "MLP"]], "topomodelx.nn.hypergraph.allset_layer.AllSetBlock": [[13, 2, 1, "", "forward"], [13, 2, 1, "", "reset_parameters"]], "topomodelx.nn.hypergraph.allset_layer.AllSetLayer": [[13, 2, 1, "", "forward"], [13, 2, 1, "", "reset_parameters"]], "topomodelx.nn.hypergraph.hmpnn": [[18, 1, 1, "", "HMPNN"]], "topomodelx.nn.hypergraph.hmpnn.HMPNN": [[18, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.hmpnn_layer": [[19, 1, 1, "", "HMPNNLayer"]], "topomodelx.nn.hypergraph.hmpnn_layer.HMPNNLayer": [[19, 2, 1, "", "apply_regular_dropout"], [19, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.hnhn": [[20, 1, 1, "", "HNHN"]], "topomodelx.nn.hypergraph.hnhn.HNHN": [[20, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.hnhn_layer": [[21, 1, 1, "", "HNHNLayer"]], "topomodelx.nn.hypergraph.hnhn_layer.HNHNLayer": [[21, 2, 1, "", "compute_normalization_matrices"], [21, 2, 1, "", "forward"], [21, 2, 1, "", "init_biases"], [21, 2, 1, "", "normalize_incidence_matrices"], [21, 2, 1, "", "reset_parameters"]], "topomodelx.nn.hypergraph.hypergat": [[23, 1, 1, "", "HyperGAT"]], "topomodelx.nn.hypergraph.hypergat.HyperGAT": [[23, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.hypergat_layer": [[24, 1, 1, "", "HyperGATLayer"]], "topomodelx.nn.hypergraph.hypergat_layer.HyperGATLayer": [[24, 2, 1, "", "attention"], [24, 2, 1, "", "forward"], [24, 2, 1, "", "reset_parameters"], [24, 2, 1, "", "update"]], "topomodelx.nn.hypergraph.hypersage": [[25, 1, 1, "", "HyperSAGE"]], "topomodelx.nn.hypergraph.hypersage.HyperSAGE": [[25, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.hypersage_layer": [[26, 1, 1, "", "GeneralizedMean"], [26, 1, 1, "", "HyperSAGELayer"]], "topomodelx.nn.hypergraph.hypersage_layer.GeneralizedMean": [[26, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.hypersage_layer.HyperSAGELayer": [[26, 2, 1, "", "aggregate"], [26, 2, 1, "", "forward"], [26, 2, 1, "", "update"]], "topomodelx.nn.hypergraph.unigcn": [[28, 1, 1, "", "UniGCN"]], "topomodelx.nn.hypergraph.unigcn.UniGCN": [[28, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.unigcn_layer": [[29, 1, 1, "", "UniGCNLayer"]], "topomodelx.nn.hypergraph.unigcn_layer.UniGCNLayer": [[29, 2, 1, "", "forward"], [29, 2, 1, "", "reset_parameters"]], "topomodelx.nn.hypergraph.unigcnii": [[30, 1, 1, "", "UniGCNII"]], "topomodelx.nn.hypergraph.unigcnii.UniGCNII": [[30, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.unigcnii_layer": [[31, 1, 1, "", "UniGCNIILayer"]], "topomodelx.nn.hypergraph.unigcnii_layer.UniGCNIILayer": [[31, 2, 1, "", "forward"], [31, 2, 1, "", "reset_parameters"]], "topomodelx.nn.hypergraph.unigin": [[32, 1, 1, "", "UniGIN"]], "topomodelx.nn.hypergraph.unigin.UniGIN": [[32, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.unigin_layer": [[33, 1, 1, "", "UniGINLayer"]], "topomodelx.nn.hypergraph.unigin_layer.UniGINLayer": [[33, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.unisage": [[34, 1, 1, "", "UniSAGE"]], "topomodelx.nn.hypergraph.unisage.UniSAGE": [[34, 2, 1, "", "forward"]], "topomodelx.nn.hypergraph.unisage_layer": [[35, 1, 1, "", "UniSAGELayer"]], "topomodelx.nn.hypergraph.unisage_layer.UniSAGELayer": [[35, 2, 1, "", "forward"], [35, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial": [[37, 0, 0, "-", "dist2cycle"], [38, 0, 0, "-", "dist2cycle_layer"], [39, 0, 0, "-", "hsn"], [40, 0, 0, "-", "hsn_layer"], [42, 0, 0, "-", "san"], [43, 0, 0, "-", "san_layer"], [44, 0, 0, "-", "sca_cmps"], [45, 0, 0, "-", "sca_cmps_layer"], [46, 0, 0, "-", "sccn"], [47, 0, 0, "-", "sccn_layer"], [48, 0, 0, "-", "sccnn"], [49, 0, 0, "-", "sccnn_layer"], [50, 0, 0, "-", "scconv"], [51, 0, 0, "-", "scconv_layer"], [52, 0, 0, "-", "scn2"], [53, 0, 0, "-", "scn2_layer"], [54, 0, 0, "-", "scnn"], [55, 0, 0, "-", "scnn_layer"], [56, 0, 0, "-", "scone"], [57, 0, 0, "-", "scone_layer"]], "topomodelx.nn.simplicial.dist2cycle": [[37, 1, 1, "", "Dist2Cycle"]], "topomodelx.nn.simplicial.dist2cycle.Dist2Cycle": [[37, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.dist2cycle_layer": [[38, 1, 1, "", "Dist2CycleLayer"]], "topomodelx.nn.simplicial.dist2cycle_layer.Dist2CycleLayer": [[38, 2, 1, "", "forward"], [38, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial.hsn": [[39, 1, 1, "", "HSN"]], "topomodelx.nn.simplicial.hsn.HSN": [[39, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.hsn_layer": [[40, 1, 1, "", "HSNLayer"]], "topomodelx.nn.simplicial.hsn_layer.HSNLayer": [[40, 2, 1, "", "forward"], [40, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial.san": [[42, 1, 1, "", "SAN"]], "topomodelx.nn.simplicial.san.SAN": [[42, 2, 1, "", "compute_projection_matrix"], [42, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.san_layer": [[43, 1, 1, "", "SANConv"], [43, 1, 1, "", "SANLayer"]], "topomodelx.nn.simplicial.san_layer.SANConv": [[43, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.san_layer.SANLayer": [[43, 2, 1, "", "forward"], [43, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial.sca_cmps": [[44, 1, 1, "", "SCACMPS"]], "topomodelx.nn.simplicial.sca_cmps.SCACMPS": [[44, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.sca_cmps_layer": [[45, 1, 1, "", "SCACMPSLayer"]], "topomodelx.nn.simplicial.sca_cmps_layer.SCACMPSLayer": [[45, 2, 1, "", "forward"], [45, 2, 1, "", "intra_aggr"], [45, 2, 1, "", "reset_parameters"], [45, 2, 1, "", "weight_func"]], "topomodelx.nn.simplicial.sccn": [[46, 1, 1, "", "SCCN"]], "topomodelx.nn.simplicial.sccn.SCCN": [[46, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.sccn_layer": [[47, 1, 1, "", "SCCNLayer"]], "topomodelx.nn.simplicial.sccn_layer.SCCNLayer": [[47, 2, 1, "", "forward"], [47, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial.sccnn": [[48, 1, 1, "", "SCCNN"]], "topomodelx.nn.simplicial.sccnn.SCCNN": [[48, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.sccnn_layer": [[49, 1, 1, "", "SCCNNLayer"]], "topomodelx.nn.simplicial.sccnn_layer.SCCNNLayer": [[49, 2, 1, "", "aggr_norm_func"], [49, 2, 1, "", "chebyshev_conv"], [49, 2, 1, "", "forward"], [49, 2, 1, "", "reset_parameters"], [49, 2, 1, "", "update"]], "topomodelx.nn.simplicial.scconv": [[50, 1, 1, "", "SCConv"]], "topomodelx.nn.simplicial.scconv.SCConv": [[50, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.scconv_layer": [[51, 1, 1, "", "SCConvLayer"]], "topomodelx.nn.simplicial.scconv_layer.SCConvLayer": [[51, 2, 1, "", "forward"], [51, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial.scn2": [[52, 1, 1, "", "SCN2"]], "topomodelx.nn.simplicial.scn2.SCN2": [[52, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.scn2_layer": [[53, 1, 1, "", "SCN2Layer"]], "topomodelx.nn.simplicial.scn2_layer.SCN2Layer": [[53, 2, 1, "", "forward"], [53, 2, 1, "", "reset_parameters"]], "topomodelx.nn.simplicial.scnn": [[54, 1, 1, "", "SCNN"]], "topomodelx.nn.simplicial.scnn.SCNN": [[54, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.scnn_layer": [[55, 1, 1, "", "SCNNLayer"]], "topomodelx.nn.simplicial.scnn_layer.SCNNLayer": [[55, 2, 1, "", "aggr_norm_func"], [55, 2, 1, "", "chebyshev_conv"], [55, 2, 1, "", "forward"], [55, 2, 1, "", "reset_parameters"], [55, 2, 1, "", "update"]], "topomodelx.nn.simplicial.scone": [[56, 1, 1, "", "SCoNe"], [56, 1, 1, "", "TrajectoriesDataset"], [56, 3, 1, "", "generate_complex"], [56, 3, 1, "", "generate_trajectories"]], "topomodelx.nn.simplicial.scone.SCoNe": [[56, 2, 1, "", "forward"]], "topomodelx.nn.simplicial.scone.TrajectoriesDataset": [[56, 2, 1, "", "vectorize_path"]], "topomodelx.nn.simplicial.scone_layer": [[57, 1, 1, "", "SCoNeLayer"]], "topomodelx.nn.simplicial.scone_layer.SCoNeLayer": [[57, 2, 1, "", "forward"], [57, 2, 1, "", "reset_parameters"]], "topomodelx.utils": [[58, 0, 0, "-", "scatter"]], "topomodelx.utils.scatter": [[58, 3, 1, "", "broadcast"], [58, 3, 1, "", "scatter"], [58, 3, 1, "", "scatter_add"], [58, 3, 1, "", "scatter_mean"], [58, 3, 1, "", "scatter_sum"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function"}, "terms": {"": [1, 3, 18, 19, 26, 43, 56, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 77, 78, 80, 81, 82, 83, 86], "0": [5, 6, 7, 8, 9, 12, 13, 18, 19, 20, 21, 23, 24, 26, 29, 30, 31, 32, 33, 34, 35, 39, 40, 42, 43, 45, 49, 50, 51, 53, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "00": 69, "0000": [66, 67, 70, 72, 76, 78, 80, 81, 83], "0005": 63, "001": [62, 65], "003099573808601": [66, 70, 72, 74, 76], "0032": 66, "0047": 69, "00477600097656": 75, "0051": 69, "0060": 69, "00606": [3, 61], "0064": 69, "00650188e": 77, "0066": 69, "0072": 69, "00743": [7, 8], "0078": 69, "00956": [28, 29, 30, 31, 32, 33, 34, 35], "0097": 69, "01": [63, 64, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 85, 86], "0123": 69, "0149": 69, "0160": 69, "02": [77, 86], "0214": 69, "02294368e": 77, "025209426879883": 73, "02585": 55, "02689916e": 77, "0274": 66, "0287": 71, "0289": 84, "0292": 65, "0298": [69, 84], "03": [77, 86], "0300": 70, "0319": 84, "0359": 76, "04": 86, "04046": 45, "0425": 84, "0434": 68, "0446": 84, "0454": 84, "04558": [25, 26], "0466": 84, "046907424926758": 73, "0471": 66, "0478": 69, "05": 86, "0519": [76, 84], "05313901e": 77, "0537": 77, "05412391e": 77, "0546": 77, "0553": 77, "0576": 77, "0580": 77, "0596": 84, "06": 86, "0607": 77, "0650": 77, "0663": 77, "0667": 65, "0685": 77, "0687": 77, "0688": 65, "0693": 77, "0699": 77, "07": 86, "0701": 77, "0702": 84, "07190537e": 77, "0720": 77, "0721": 77, "0724": 77, "0725": 77, "07279651e": 77, "0731": 77, "0746": 77, "07485": 43, "0749": 77, "0754": 77, "0758": 68, "0759": 77, "0761": 84, "0762": 77, "0789": 77, "08": [77, 86], "0803": 77, "0804": 77, "0816": 69, "08179": [5, 6], "0819": 77, "0844": 66, "0864": 77, "0891": 77, "0892": 77, "0897": 77, "09": [77, 84, 86], "09101162e": 77, "09105867e": 77, "0920": 77, "0923": 77, "0927": 77, "0930": [77, 82], "0937": 77, "0943": [77, 84], "0948": 77, "0954": 77, "0959": 77, "0960": 77, "0968": 77, "0969": 84, "0971": 77, "0982": 85, "0988": 84, "0992": 77, "0996": 77, "0998": 77, "0d": [63, 64, 82, 84], "0th": 62, "0x11971c5d0": 62, "0x13507d2d0": 86, "0x16d07b750": 64, "1": [1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86], "10": [62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "100": [56, 73, 75, 77, 78, 80, 81, 82, 83, 84, 85, 86], "1000": [56, 86], "10031": [3, 8, 10, 21, 26, 29, 33, 35, 40, 45, 47, 51, 53, 55, 57, 61], "1006": [76, 77], "1009": 77, "101": [69, 80, 83], "1011": 84, "1012": 77, "10169996e": 77, "1019": 77, "102": [80, 83], "1023": 77, "1025": 68, "103": [80, 83], "104": [80, 83], "1046": 77, "105": [80, 83], "106": [80, 83, 84], "107": [80, 83], "108": [80, 83], "1080": 77, "1082": 85, "109": [80, 83], "10903": 6, "11": [47, 53, 59, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "110": [80, 83, 85], "1106": 77, "11062303": 68, "111": [80, 83], "112": [80, 83], "1125": 65, "1126": 84, "113": [80, 83], "11335017e": 77, "114": [80, 83], "11494370e": 77, "115": [80, 83], "116": [80, 83, 85], "117": [80, 83, 85], "11719538e": 77, "117366790771484": 75, "1179": 77, "118": [80, 83], "119": [80, 83], "1194": 63, "11998310e": 77, "12": [63, 67, 68, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "120": [80, 83], "1200": 86, "120x1": 65, "121": [80, 83], "1216": 70, "122": [80, 83], "123": [80, 83], "124": [80, 83], "125": [80, 83], "1250": 71, "1255": 77, "12575": [9, 10], "126": [80, 83], "12601468e": 77, "1261": 75, "127": [80, 83], "12746": 68, "128": [62, 66, 67, 69, 70, 72, 74, 76, 80, 83], "1288": 77, "129": [80, 83], "1293": 77, "1294": 77, "13": [59, 63, 67, 68, 73, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "130": [80, 83], "131": [80, 83], "1316": 77, "132": [80, 83], "13264": [12, 13], "133": [80, 83], "1332": 77, "134": [80, 83], "1343": 77, "135": [80, 83], "135039": 68, "1356": 77, "136": [80, 83], "137": [80, 83], "138": [80, 83], "1380": 77, "139": [80, 83], "14": [63, 67, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "140": [80, 83], "141": [80, 83], "14116156e": 77, "1417": 65, "142": [80, 83], "1422611997": [66, 70, 72, 74, 76], "1426": 77, "1429": [74, 77], "143": [77, 80, 81, 83], "1430": 74, "1433": 69, "144": [80, 83], "1447": 71, "14491": 6, "145": [80, 83], "1457": 77, "146": [80, 83], "1465": 84, "147": [80, 82, 83], "1473": 77, "1474": 77, "1475": 77, "1477": 68, "148": [80, 83], "1484": 77, "1487": 77, "149": [80, 83, 85], "1495": 77, "15": [66, 67, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "150": [80, 83, 86], "151": [80, 83], "1511": 77, "1518": 77, "1519": 77, "152": [80, 83], "1529": 66, "153": [80, 83], "15316376e": 77, "154": [80, 83], "1545": 77, "155": [80, 83], "1551": 84, "156": [80, 83], "1560": 77, "157": [80, 83], "1571": 69, "1575": 77, "158": [80, 83, 85], "1580": 84, "1583": 65, "159": [80, 83], "16": [59, 62, 63, 64, 65, 67, 68, 69, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "160": [80, 83], "161": [80, 83], "162": [80, 83], "1627": 84, "1628": 77, "16282904e": 77, "163": [80, 83], "164": [80, 83], "165": [80, 83], "1654": 77, "166": [80, 83], "167": [80, 83], "16733590e": 77, "16733608e": 77, "16733683e": 77, "16733944e": 77, "16734018e": 77, "168": [66, 70, 72, 74, 76, 80, 83], "169": [80, 83], "16995": [18, 19], "17": [62, 67, 77, 78, 79, 80, 81, 82, 83, 84, 85], "170": [80, 83], "1705": 71, "171": [80, 83], "1710": 6, "1711": 84, "1712": 82, "172": [80, 83, 85], "1724": 77, "1725": 77, "173": [80, 83], "1730": 77, "1734": [77, 85], "1738": 77, "174": [80, 83], "17499000e": 77, "175": [80, 83], "176": [80, 83], "1763": 77, "177": [80, 83], "1770": 71, "1773": 84, "178": [80, 83, 85], "1780": 77, "179": [80, 83], "1792": 65, "1793": 84, "1796569824219": 73, "18": [67, 73, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "180": [80, 83], "1804": 77, "181": [80, 83], "1812": 77, "18122974e": 77, "182": [80, 83], "1821": 77, "183": [80, 83], "1831": 77, "18312198e": 77, "18312794e": 77, "1836": 77, "184": [80, 83], "185": [80, 83], "1851": 77, "186": [80, 83], "187": [80, 83], "188": [62, 80, 83], "189": [80, 83], "1890": 84, "19": [67, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "190": [80, 83], "191": [80, 83], "1917": 70, "192": [80, 83], "19283": 71, "193": [80, 83], "194": [80, 83], "195": [80, 83], "196": [80, 83], "1962": 77, "1969": 70, "197": [80, 83], "198": [80, 83, 84], "199": [80, 83], "1d": [60, 63, 64, 82, 84], "1e": [42, 86], "2": [1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 20, 21, 23, 25, 26, 28, 29, 30, 32, 33, 34, 35, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 86], "20": [66, 67, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "200": [80, 83], "2010": [7, 8, 25, 26], "2016": [65, 67], "2017": [6, 67, 77], "202": 82, "2020": [7, 8, 20, 21, 23, 24, 25, 26, 51, 59, 63, 70, 71, 72, 83], "2021": [9, 10, 28, 29, 30, 31, 32, 33, 34, 35, 55, 57, 59, 64, 66, 67, 86], "2022": [5, 6, 12, 13, 18, 19, 40, 43, 45, 47, 53, 59, 62, 69, 77, 78, 79, 81, 85], "2022a": 84, "2023": [3, 8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 61, 62, 63, 64, 65, 70, 77, 78, 79, 80, 81, 82, 83, 85, 86], "20385019e": 77, "20385038e": 77, "20385336e": 77, "20385485e": 77, "204": 82, "2046": 74, "2056": 77, "2060": 71, "20638106e": 77, "2069": 77, "2077": 77, "20998740e": 77, "21": [67, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "2103": 45, "2105": [6, 28, 29, 30, 31, 32, 33, 34, 35], "2106": [9, 10, 12, 13], "2110": 55, "2113": 76, "2124": 63, "21251035e": 77, "2140": 77, "21484074e": 77, "2153": 84, "21695511e": 77, "21695530e": 77, "21695651e": 77, "21695669e": 77, "21695707e": 77, "21695725e": 77, "22": [67, 77, 78, 79, 80, 81, 82, 83, 84, 85], "2203": [18, 19, 43], "2206": [3, 61, 77], "2209": [5, 6], "22131526e": 77, "2270": 69, "228": 68, "22967193e": 77, "23": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "2301": 70, "2304": [3, 8, 10, 21, 26, 29, 33, 35, 40, 45, 47, 51, 53, 55, 57, 61], "2309": 77, "23110419e": 77, "23143601e": 77, "23208503e": 77, "23212508e": 77, "2352": 84, "2363": 84, "23841551e": 77, "2390": 84, "24": [73, 77, 78, 79, 80, 81, 82, 83, 84, 85], "24033478e": 77, "243": 82, "2460": 72, "2496": 84, "25": [65, 66, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "2500": [77, 78, 79], "25182593e": 77, "252": [63, 64, 68, 71, 84], "2532": 76, "2551": 84, "2581": [66, 70, 72, 74, 76], "2583": 65, "2596": 63, "26": [69, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "2620": 72, "2624": 71, "2665": 69, "2671": 84, "2672": 84, "2678": 77, "26969576e": 77, "27": [77, 78, 79, 80, 81, 82, 83, 84, 85], "270": 77, "2701": 84, "2708": 69, "2717": 69, "2721": 84, "276484184": 67, "2776": 84, "2781": 64, "27834606e": 77, "27835426e": 77, "2788": 84, "28": [77, 78, 79, 80, 81, 82, 83, 84, 85], "2807": 65, "2813": 77, "28155053e": 77, "284": [70, 72, 74, 76], "2843": 84, "285": 66, "2858": 70, "2876": 70, "28915999e": 77, "29": [77, 78, 79, 80, 81, 82, 83, 84, 85], "29043306e": 77, "2914": 68, "2927": 77, "29361625e": 77, "2958": 68, "299": 82, "2d": [60, 63, 64, 82, 84], "2f": 69, "2f_0": 62, "2i": [53, 81], "2p": [43, 79], "3": [1, 6, 8, 10, 21, 26, 29, 33, 35, 40, 45, 47, 51, 53, 55, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "30": [65, 66, 70, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "3000": [79, 85], "3018": 77, "302": 82, "3029": 85, "3052": 76, "3090": 77, "30901868e": 77, "30902189e": 77, "31": [65, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "311": 82, "3125": 75, "31365804e": 77, "3142": 85, "3154": 68, "3155": 84, "3157": 76, "32": [62, 65, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "32374076e": 77, "3240": 84, "3250": 65, "3256": 84, "32742967e": 77, "327622607829558": [66, 70, 72, 74, 76], "3278": 84, "32841964e": 77, "33": [65, 77, 78, 79, 80, 81, 82, 83, 84, 85], "33008221e": 77, "3311": 74, "34": [77, 78, 79, 80, 81, 82, 83, 84, 85], "3427": 84, "3450": 84, "3453": 63, "3474": 65, "35": [65, 77, 78, 79, 80, 81, 82, 83, 84, 85], "3506": 63, "3517": 71, "3558": 84, "3560": 66, "3567": 84, "36": [62, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "3629752": [77, 78, 79, 80, 81, 82, 83], "36992298e": 77, "37": [75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "3715": 84, "37488726e": 77, "3768": 70, "3779": 84, "38": [62, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "38155320e": 77, "3835": 70, "3838": 64, "3844": 71, "3874": 84, "389": 73, "39": [66, 69, 70, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "39397243e": 77, "39617124e": 77, "3970": 69, "3973": 66, "399": [23, 24], "399008": 82, "3991": 64, "3d": [63, 64, 65, 66, 67, 68, 71, 72, 84], "3f": 86, "4": [0, 1, 10, 24, 26, 49, 55, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "40": [20, 21, 64, 68, 69, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "4044": 84, "40563001e": 77, "40770523e": 77, "40789945e": 77, "4079": 71, "4080": 66, "4091": 84, "41": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "4115": 82, "412": [66, 70, 72, 74, 76], "4123": 76, "412574768066406": 75, "414": [1, 3, 21, 24, 49, 55], "4160": 69, "41898049e": 77, "42": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "4219": 74, "4230": 69, "4266": 85, "42880568e": 77, "4291": 84, "43": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "4333": [80, 81, 84], "43391562e": 77, "4344": 76, "43603450e": 77, "4375": [73, 75], "4395": 84, "43989541e": 77, "44": [77, 78, 79, 80, 81, 82, 83, 84, 85], "4428": 76, "4460": 74, "44727693e": 77, "4479": 71, "4490": 69, "44989747e": 77, "45": [64, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "4500": 69, "4505": 84, "45243965e": 77, "45874349e": 77, "46": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "46084312e": 77, "4630": 69, "46390563e": 77, "46499884e": 77, "4650": 74, "4667": [81, 82, 84], "4670": 69, "4695": 71, "47": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "4720": 69, "4742": 84, "4743": 84, "4752": 74, "477": 82, "4779": 74, "48": [69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "480": 65, "4806": 84, "4830": 69, "4839": 82, "48587048e": 77, "49": [64, 69, 77, 78, 79, 80, 81, 82, 83, 84, 85], "4900": 69, "49070593e": 77, "4920": 69, "49207789e": 77, "4922": 66, "4929": 66, "4970": [69, 71], "4979": 84, "49792436e": 77, "4982": 82, "4989": 82, "49915427e": 77, "4994": 82, "4f": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "5": [5, 18, 19, 21, 30, 42, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "50": [64, 69, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "500": [63, 64, 65, 68, 71, 84], "5000": [78, 80, 81, 82, 83, 85], "5005": 82, "5011": 82, "5016": 82, "50192329e": 77, "5022": 82, "5027": 82, "5030": 69, "5032": [82, 84], "50366411e": 77, "50366500e": 77, "5037": 82, "5041": 82, "5046": 82, "5051": 82, "50549929e": 77, "50550078e": 77, "5056": 82, "5060": 82, "5064": 82, "5068": 82, "5069": 84, "5071": 82, "5075": 82, "5078": 82, "5080": 74, "5082": 82, "5085": 82, "5089": 82, "5092": 82, "5094": 82, "5096": 82, "5098": 82, "5099": 82, "51": [69, 77, 78, 80, 81, 82, 83, 84, 85], "5100": 69, "5101": [68, 82], "5103": 82, "5105": 82, "5107": 82, "5109": 82, "5110": 69, "5111": 82, "5113": 82, "5115": 82, "5116": 82, "5118": 82, "5119": [69, 82], "5120": 82, "5121": 82, "5122": 82, "5123": 82, "5124": 82, "5125": 82, "5126": 82, "5127": 82, "5128": 82, "5129": 82, "5130": 82, "5131": 82, "5132": 82, "5133": 82, "5134": 82, "5135": 82, "5136": 82, "5137": 82, "5138": 82, "5139": 82, "5140": 82, "5142": 82, "5144": 82, "5147": 82, "5150": 69, "5151": 82, "5152": 63, "5156": 82, "5160": 66, "5162": 82, "5170": 82, "5174": 76, "5182": 82, "51894227e": 77, "5190": 69, "5192": 74, "5198": 82, "52": [69, 77, 78, 80, 81, 82, 83, 84, 85], "5216": 81, "5217": 81, "5218": 81, "5219": 81, "5220": 81, "5221": 81, "5222": 81, "5223": [81, 82], "5224": 81, "5225": 81, "5226": 81, "5227": 81, "5228": 81, "5229": 81, "5230": 81, "5231": 81, "5232": 81, "5234": 81, "5235": 81, "5236": 81, "5238": 81, "5240": 81, "5242": [81, 84], "5244": 81, "5246": 81, "5249": 81, "5252": 81, "5256": 81, "5257": 82, "5260": 81, "5264": 81, "5269": 81, "5274": 81, "5278": 81, "5283": 81, "5287": 81, "5292": 81, "5298": 81, "53": [77, 78, 80, 81, 82, 83, 84, 85], "5305": 81, "5306": 82, "5316": 81, "5323": 83, "5324": 83, "5325": 83, "5326": 83, "5327": 83, "5328": 83, "5329": [81, 83], "5330": 83, "5331": 83, "5332": 83, "5333": [78, 83], "5334": 83, "5335": 83, "5336": 83, "5337": 83, "5338": 83, "5339": 83, "5340": 83, "5341": 83, "5342": [81, 83], "5343": 83, "5344": [83, 84], "5345": 83, "5346": 83, "5347": 83, "5348": 83, "5349": 83, "5350": 83, "5351": [81, 83], "5352": 83, "5354": 83, "5355": 83, "5356": 83, "5357": 83, "5358": [81, 83], "5359": 83, "536": [63, 68, 71, 82, 85], "5361": 83, "5362": 83, "5363": 83, "5364": 83, "53657054e": 77, "5366": 83, "53667741e": 77, "5367": 83, "5368": 81, "5369": 83, "5370": 83, "5371": 83, "5373": 83, "5374": 83, "5376": 83, "5378": 83, "5379": 83, "5380": 66, "5381": [82, 83], "5383": 83, "5384": [63, 83], "5386": 83, "5388": 83, "5390": [81, 83], "5392": 83, "5393": 83, "5395": 83, "5398": 83, "54": [77, 78, 80, 81, 82, 83, 84, 85], "5400": 83, "54005478e": 77, "5402": 83, "5404": 83, "5406": 83, "5408": 83, "5411": 83, "5413": 83, "5416": 83, "5418": 83, "5421": 83, "5422": 81, "5423": 83, "5426": 83, "5429": [69, 83], "5432": [83, 84], "5435": 83, "5437": 84, "5438": 83, "5441": 83, "5443": 81, "5444": 83, "5445": 84, "5448": [81, 83], "5451": 83, "5455": 83, "5458": 83, "5462": 83, "5466": 83, "5470": 83, "5474": 83, "5478": 83, "5479": 84, "5483": 83, "5487": 83, "5492": 83, "5496": 82, "5497": 83, "55": [77, 78, 80, 81, 82, 83, 84, 85], "5500": 81, "5502": 83, "5507": 83, "5512": 83, "5518": 83, "5523": 83, "55232428e": 77, "5529": [81, 83], "55317712e": 77, "5535": 83, "5538": 85, "55389528e": 77, "5539": 85, "55398457e": 77, "5540": 85, "55402555e": 77, "5541": 85, "5542": [83, 85], "5543": 85, "5544": 85, "5545": 85, "5546": 85, "5547": 85, "5548": [70, 83, 85], "5549": 85, "5551": 85, "5552": 85, "5553": 85, "5554": [81, 85], "5555": [83, 85], "5558": 85, "5562": [83, 85], "5563": 85, "5564": 85, "5565": 85, "5566": 64, "5569": [65, 83], "5570": 85, "5576": 85, "5577": 83, "5579": 85, "5580": 72, "5581": 85, "5582": 85, "5584": [83, 85], "5590": 85, "5592": [83, 85], "5594": 85, "56": [65, 69, 77, 78, 80, 81, 82, 83, 84, 85], "5601": 83, "5603": 85, "5605": 85, "5607": 85, "5609": 83, "5618": 83, "5622": 85, "5625": [73, 75], "5627": 83, "5635": 80, "5637": 83, "5638": 80, "5639": 85, "5640": 80, "5642": 80, "5644": 80, "5647": [80, 83], "5649": 80, "5651": 80, "5653": 80, "5655": 85, "5656": 80, "5657": 83, "5658": 80, "5660": 80, "5663": 80, "5665": 80, "5666": 82, "5667": [78, 80, 81, 83], "5668": [80, 83], "5669": 85, "5670": 80, "5673": 80, "5675": 80, "5678": 80, "5679": [83, 85], "5680": [72, 80], "5683": 80, "5685": 80, "5686": 85, "5688": 80, "5690": 80, "5691": 83, "5693": [80, 85], "5696": 80, "5698": 80, "57": [77, 78, 80, 81, 82, 83, 84, 85], "5701": 80, "5703": 83, "5704": [63, 80], "5705": 84, "5706": [81, 84], "5707": 80, "5709": 80, "5712": 80, "5715": [80, 83], "5716": 84, "5718": 80, "5721": [80, 85], "5724": 80, "5727": 80, "5728": 83, "5730": 80, "5733": 80, "5736": 80, "5739": 80, "5742": [80, 83], "5745": [70, 80], "5748": 80, "57507989e": 77, "5751": [70, 80], "5755": 80, "5756": 83, "5758": 80, "5761": 80, "5764": 80, "5768": 80, "5770": 83, "5771": 80, "5774": 80, "5778": 80, "5781": 80, "5785": [80, 83], "5788": 80, "57889747619629": 75, "5790": 74, "5792": 80, "5795": 80, "5796": 85, "5799": 80, "58": [77, 78, 80, 81, 82, 83, 84, 85], "5801": 83, "5803": [63, 80], "58042466e": 77, "5806": 80, "5810": 80, "5814": 80, "5817": 83, "5818": 80, "5820": 66, "5822": 80, "5826": [62, 80], "5830": 80, "5833": 83, "5834": 80, "5838": 80, "5839": 62, "5840": 84, "5842": 80, "5846": 80, "5850": 80, "5851": 83, "5854": 80, "5859": 80, "5860": 81, "5863": 80, "5867": [76, 80], "5869": 83, "5872": [69, 80], "5876": 80, "5880": 85, "5881": 80, "588314056396484": 75, "5885": 80, "5887": 83, "5890": 80, "5894": [69, 80], "5899": 80, "59": [59, 77, 78, 80, 81, 82, 83, 84, 85], "5903": 82, "5904": 80, "5905": 81, "5907": 83, "5908": 62, "5909": 80, "5911": 62, "5914": 80, "5915": 82, "591552734375": 75, "5919": 80, "5924": 80, "5927": 83, "5929": [72, 80], "5934": [80, 82], "5939": 80, "59393880e": 77, "5942": 81, "5944": 80, "5948": 83, "5950": [66, 80], "5951": 85, "5955": 80, "5961": 80, "5965": 62, "5966": 80, "5969": 83, "5972": 80, "5974": 62, "5975": 81, "5977": 80, "5979": 62, "5983": 80, "5989": 80, "5991": 83, "5995": 80, "5e": 86, "6": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "60": [65, 73, 75, 77, 78, 80, 81, 82, 83, 84, 85, 86], "600": 86, "6000": [74, 78, 83], "6001": 80, "6007": [80, 81], "6013": 80, "6014": 83, "6019": 80, "6020": 69, "6023": 85, "6026": 80, "6027": 62, "6032": [70, 80], "6035": 81, "6038": [80, 83], "6045": 80, "6052": 80, "6057": 84, "6058": 80, "6061": 81, "6062": 83, "6065": 80, "6071": 62, "6072": 80, "6078": 84, "6079": 80, "6080": 82, "6084": 81, "6086": 80, "6087": 83, "6094": 80, "60x60": 65, "61": [69, 77, 78, 80, 81, 82, 83, 84, 85], "6100": 85, "6101": 80, "6106": 81, "6108": 80, "6113": 83, "6116": [62, 80], "6124": 80, "6125": 81, "6131": 80, "6139": 80, "6140": [62, 83], "6142": 81, "6143": 69, "6147": 80, "6153": 69, "6155": 80, "6158": 81, "6164": 80, "6167": 83, "6172": 80, "6173": 81, "6180": 80, "6184": 85, "6188": 81, "6189": 80, "6195": 83, "6198": 80, "62": [77, 78, 80, 81, 82, 83, 84, 85], "6203": [81, 85], "6207": 80, "62092721e": 77, "6216": 80, "62186569e": 77, "6220": 81, "6223": 83, "6225": 80, "6234": 80, "6235": 74, "6238": 81, "6244": 80, "6245": 79, "6248": 82, "6249": 79, "625": [73, 75], "6252": 79, "6253": [80, 83], "6255": 79, "6258": 79, "6259": 79, "6260": [79, 81], "6261": 79, "6262": 79, "6263": 80, "6265": 79, "6267": 79, "6272": 79, "6273": 80, "6282": [79, 83], "6283": 80, "6286": 81, "6288": 85, "6294": 80, "6298": 79, "63": [77, 78, 80, 81, 82, 83, 84, 85], "6304": 80, "6313": 83, "6314": 80, "6316": [62, 81], "6317": 79, "6325": 80, "6326": 74, "6330": 62, "6333": [77, 79, 83], "6336": 80, "6343": 83, "6347": [79, 80], "6350": 74, "6351": 81, "6358": 80, "6360": 79, "6369": 79, "6370": 80, "6374": 83, "6378": 69, "6379": 79, "6381": 76, "6382": 80, "6384": 70, "6391": 79, "6392": 81, "6393": 80, "6397": 79, "64": [73, 77, 78, 80, 81, 82, 83, 84, 85], "6405": 80, "6406": 83, "6412": [69, 79], "6414": 84, "6417": 80, "6419": 79, "6429": 80, "6431": 85, "6433": 79, "6437": [81, 83], "6438": 79, "6441": 80, "6446": 85, "6452": [63, 79], "6455": 80, "6463": 79, "64641943e": 77, "6468": 80, "6469": 83, "6479": 79, "6481": 80, "6484": 69, "6486": 81, "6490": 72, "6491": [62, 79], "6494": 80, "6499": 69, "65": [77, 78, 80, 81, 82, 83, 84, 85], "6501": 83, "6507": [69, 80], "6508": 79, "6520": 80, "6528": 79, "6533": [80, 83], "6538": 81, "6547": [69, 80], "6551": 79, "6560": 72, "6562": 80, "6564": 83, "6567": 65, "6577": 80, "6586": 79, "6590": 85, "6592": 81, "6593": 80, "6596": 83, "66": [69, 77, 78, 80, 81, 82, 83, 84, 85], "6608": 80, "6623": 80, "6624": 79, "6626": 83, "66296689e": 77, "6630": 84, "6637": 80, "6645": 81, "6651": 80, "6657": 83, "6664": 80, "66642778e": 77, "6667": [77, 79, 83, 84], "6669": 79, "6670": 69, "6673": 85, "6677": 82, "6679": 80, "6682": 69, "6687": 83, "6688": 77, "6689": 77, "6691": 77, "6694": 77, "6695": 80, "6696": 81, "67": [77, 78, 80, 81, 82, 83, 84, 85], "6700": 74, "6701": 77, "67087543e": 77, "6709": 84, "6712": 80, "6714": 74, "6716": [79, 83], "6718": [62, 77], "672311782836914": 73, "6731": 80, "6745": [69, 81, 83], "6746": 70, "6750": 80, "6752": 84, "6754": 71, "6760": 79, "6764": 69, "6768": 80, "6769": 77, "6770": 84, "6772": 83, "6773": 85, "6784": 80, "6788": 82, "6789": 81, "6798": 80, "6799": 83, "68": [77, 78, 80, 81, 82, 83, 84, 85], "6810": 80, "6814": 79, "6815": 84, "6820": 66, "6822": 80, "6824": 83, "6829": 81, "683": 65, "6831": 84, "6836": 80, "6846": 69, "6849": 83, "6852": 80, "6857": 66, "6860": [78, 84], "6861": 78, "6862": [78, 84, 85], "6863": 78, "6864": 78, "6865": 78, "6866": 78, "6867": [78, 81], "6868": 78, "6869": 78, "6870": [78, 80], "6871": 78, "6872": [78, 83], "6873": [66, 78], "6874": [78, 79], "6875": 78, "6876": 78, "6878": 78, "6879": 78, "6880": 78, "6881": 78, "6883": 78, "6884": 78, "6885": 78, "6887": 78, "6888": [69, 78], "6890": 78, "6891": 80, "6892": 78, "6893": 78, "6894": 83, "6895": 78, "6897": 78, "6899": 78, "69": [77, 78, 80, 81, 82, 83, 84, 85], "6901": 78, "6903": 78, "6905": 78, "6906": 81, "6907": 78, "6909": 78, "6911": 78, "6913": 80, "6914": 78, "69150501e": 77, "6916": [78, 83], "6919": 78, "6921": 78, "6924": 78, "6927": 78, "6929": 78, "6930": 77, "6931": 79, "6932": 78, "6934": 80, "6935": [78, 83], "6938": 78, "6940": 66, "6942": 78, "6945": 78, "6947": 62, "6948": 78, "6951": 78, "6953": 81, "6954": 83, "6955": [78, 80], "6958": 78, "6960": 66, "6962": 78, "6966": 78, "6969": 78, "6971": 83, "6973": 78, "6974": 80, "6976": 68, "6977": 78, "6981": 78, "6984": 85, "6985": 78, "6986": 69, "6988": 83, "6989": 78, "6990": 72, "6991": 80, "6993": 78, "6997": 78, "6999": 79, "6th": [63, 64, 68, 71, 84], "6x60": 65, "7": [18, 19, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "70": [77, 78, 80, 81, 82, 83, 84, 85], "7000": [77, 79, 80, 81, 83], "7001": 78, "7003": 83, "7005": 78, "7006": 80, "7009": 78, "70098506e": 77, "7010": 66, "7013": [78, 81], "7017": [78, 83], "7018": 80, "702": 68, "7021": 78, "7025": 78, "7028": 80, "7029": 78, "7030": 83, "7033": 78, "7037": [78, 80], "7040": 66, "7042": [78, 83], "70438008e": 77, "7044": 80, "7046": 78, "7050": 78, "7052": [80, 83], "7054": 78, "7057": 79, "7058": 78, "70586307e": 77, "7061": 78, "7062": [80, 83], "7066": 78, "7067": 72, "7070": [78, 83], "7076": [78, 80], "7079": 83, "7081": 78, "7086": 83, "7087": 78, "7089": 81, "7093": [78, 83], "7097": 80, "7099": [62, 78, 83], "71": [69, 77, 78, 80, 81, 82, 83, 84, 85], "7103": 72, "7105": [76, 78, 83], "71080101e": 77, "7109": 83, "7111": 78, "7113": 83, "7115": 79, "7117": 83, "7118": 78, "7120": [70, 83], "7125": [78, 83], "7126": 80, "7128": 83, "7131": 83, "7132": 83, "7133": [78, 83], "7134": 83, "7140": 70, "7142": 78, "7153": 78, "7160": 70, "7166": 80, "7167": [78, 79], "7171": 85, "7176": [62, 81], "7183": 78, "7194": 84, "7195": 71, "7197": 64, "72": [63, 77, 78, 80, 81, 82, 83, 84, 85], "7200": 78, "7203": 79, "7206": 63, "7210": 72, "7215": 80, "7220": 72, "7226": 79, "7231": 63, "7234": 77, "7246": 84, "7247": 79, "7252": 62, "7255": 74, "7257": 84, "7260": 72, "72664091e": 77, "7267": 81, "7272": 80, "72971559e": 77, "73": [63, 64, 77, 78, 80, 81, 82, 83, 84, 85], "7310": 70, "7320": 70, "7327": 85, "7333": [79, 83, 85], "7340": 70, "7360": 72, "7370": 70, "7377": 66, "7379": 66, "7380": 67, "74": [63, 64, 77, 78, 80, 81, 82, 83, 84, 85], "7412": 84, "7420": 72, "7426": 63, "7440": 76, "7460": 76, "74787247e": 77, "7480": 76, "7494": 63, "7498": 76, "75": [63, 64, 77, 78, 80, 81, 82, 83, 84, 85], "750": [63, 64, 68, 71, 84], "7500": [80, 81, 85], "75156136e": 77, "7517": 64, "7520": 76, "75315768e": 77, "7555": 66, "7560": 76, "7569": 69, "7570": [70, 76], "7596": 84, "76": [63, 69, 77, 78, 80, 81, 82, 83, 84, 85], "76038641e": 77, "7610": 76, "7620": 76, "7667": [79, 81, 82, 83, 85], "77": [63, 77, 78, 80, 81, 82, 83, 84, 85], "7740": 67, "7774": 84, "7786": 74, "78": [63, 64, 77, 78, 79, 80, 81, 82, 83, 84, 85], "7831": 72, "7840": 76, "7857": 72, "7860": 84, "7865": 84, "7868": 76, "78961600e": 77, "79": [60, 63, 77, 78, 80, 81, 82, 83, 84, 85], "7905": 72, "7909": 74, "7911": 68, "7918": 84, "7970": 76, "7978": 84, "8": [59, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "80": [60, 63, 77, 78, 80, 81, 82, 83, 84, 85], "8000": [79, 81, 82, 85], "8030": 70, "8053": 64, "80642232e": 77, "81": [63, 64, 69, 77, 78, 80, 81, 82, 83, 84, 85], "8110": 64, "8124": 85, "8130": 68, "82": [69, 77, 78, 80, 81, 82, 83, 84, 85], "8225": 84, "8233": 66, "83": [63, 64, 77, 78, 80, 81, 82, 83, 84, 85], "8307": 66, "8325": 82, "8333": [81, 85], "83463633e": 77, "83463678e": 77, "8358": 84, "83606968e": 77, "83955252e": 77, "84": [77, 78, 80, 81, 82, 83, 84, 85], "8412": 72, "8421": 71, "84309315e": 77, "84373805e": 77, "8439": 69, "8450": 72, "8463": 63, "8466": 72, "85": [63, 77, 78, 80, 81, 82, 83, 84, 85], "8500": 74, "8572": 84, "86": [63, 69, 77, 78, 80, 81, 82, 83, 84, 85], "8615": 84, "86156419e": 77, "8618": 74, "8625": 66, "8643": 74, "8667": [81, 85], "8693": 70, "8696": 66, "87": [63, 77, 78, 80, 81, 82, 83, 84, 85], "8708": 66, "8713": 67, "8715": 84, "8717": 63, "872": 68, "873802185058594": 73, "8750": 68, "8797": 85, "88": [63, 77, 78, 80, 81, 82, 83, 84, 85], "8803": 63, "8811": 72, "888": 85, "8899": 72, "89": [63, 77, 78, 80, 81, 82, 83, 84, 85], "8904": 72, "89420712e": 77, "8944": 76, "8954": 84, "9": [60, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "90": [77, 78, 80, 81, 82, 83, 84, 85], "9000": [80, 85], "9002": 82, "90156896e": 77, "90342903137207": 75, "9035": 64, "9096": 84, "91": [69, 77, 78, 80, 81, 82, 83, 84, 85], "9105": 72, "91588592529297": 73, "92": [77, 78, 80, 81, 82, 83, 84, 85], "92070971e": 77, "9214": 66, "9220": 72, "9221": 72, "9241": 84, "9258": 84, "926": 82, "93": [77, 78, 80, 81, 82, 83, 84, 85], "9305": 72, "93094122e": 77, "93099503e": 77, "93280513e": 77, "9333": [80, 81, 83], "9356": 84, "9357": 72, "94": [77, 78, 80, 81, 82, 83, 84, 85], "9401": 72, "9405": 72, "9424": 72, "9490": 84, "9496": 70, "9497": 82, "95": [77, 78, 80, 81, 82, 83, 84, 85], "95071507e": 77, "9551": 64, "95849722e": 77, "96": [69, 77, 78, 80, 81, 82, 83, 84, 85], "9616": 84, "9618": 85, "9647": 84, "96564454e": 77, "9667": [80, 81, 83], "9684": 63, "9690": 85, "97": [77, 78, 80, 81, 82, 83, 84, 85], "9714": 72, "9724": 85, "97262095e": 77, "973644256591797": 73, "97384816e": 77, "9747": 63, "97473222e": 77, "97473371e": 77, "97473520e": 77, "9786": [66, 72, 76], "9799": 76, "98": [77, 78, 80, 81, 82, 83, 84, 85], "98071399e": 77, "98118326e": 77, "9816": 84, "9825": 67, "9831": 84, "9848": 69, "9895": 67, "9899": 65, "99": [69, 77, 78, 80, 81, 82, 83, 84, 85, 86], "9918": 84, "9929": [70, 72, 76], "9950": 68, "9983": 66, "A": [0, 3, 8, 10, 12, 13, 18, 21, 26, 38, 51, 59, 60, 61, 62, 63, 64, 65, 70, 77, 78, 79, 80, 81, 82, 83, 85, 86], "And": 60, "As": 71, "At": [54, 82, 85], "For": [51, 54, 57, 60, 61, 65, 72, 77, 78, 82, 85, 86], "If": [1, 3, 6, 10, 19, 24, 25, 26, 31, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 79, 80, 82, 84], "In": [1, 3, 19, 43, 48, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "It": [19, 30, 31, 59, 66, 69, 70, 72, 74, 76], "Its": [8, 10, 21, 29, 33, 35, 40, 45, 47, 57], "No": 79, "Not": [60, 83], "Of": 60, "On": 60, "One": [3, 26, 59, 81, 85, 86], "Or": 86, "That": 86, "The": [2, 3, 4, 5, 6, 8, 10, 11, 19, 21, 26, 27, 29, 31, 33, 35, 36, 40, 41, 42, 43, 45, 47, 49, 53, 55, 56, 57, 59, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86], "Their": 67, "Then": [10, 60, 63, 64], "There": [6, 59, 60, 69, 77, 78, 79, 80, 81, 82, 83, 85], "These": 60, "To": [49, 54, 61, 65, 66, 67, 70, 72, 74, 76, 77, 78, 80, 82, 83, 84, 85, 86], "With": [59, 71], "_": [3, 6, 8, 10, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 63, 64, 65, 66, 67, 68, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "_0": 82, "_1": [50, 51, 82, 83, 85], "_2": [50, 51, 82], "__": [62, 65], "__call__": [0, 1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57], "__doc__": 60, "__getitem__": [65, 86], "__init__": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "__len__": [65, 86], "_c": [62, 64, 86], "_cell": 10, "_compute_loss_and_upd": 65, "_cwndefaultaggreg": 10, "_cwndefaultfirstconv": 10, "_cwndefaultsecondconv": 10, "_cwndefaultupd": 10, "_data": [66, 70, 72, 74, 76], "_get_neighborhood_matrix": 65, "_index": [77, 81], "_j": 79, "_k": [6, 10, 43, 45, 62, 64, 79, 80], "_layer": 59, "_m": 86, "_pred_test": [77, 81], "_r": 62, "_reduct": 82, "_set_arrayxarrai": [77, 81], "_t": [82, 85], "_to_devic": 65, "_train": 59, "_train_epoch": 65, "_weight_boost": 60, "_x": [3, 38, 51, 53, 62, 77, 79, 83], "_y": [3, 31, 40, 47, 78, 81], "a0": [65, 77, 78], "a1": 65, "a_": [6, 10, 40, 43, 62, 63, 64, 65, 71, 77, 78, 79], "a_0": [38, 40], "a_0_up": 8, "a_1": 86, "a_2": 86, "a_j": 86, "a_k": [6, 43, 62, 79, 86], "a_k_low": 6, "a_k_up": 6, "a_opt": 83, "a_opt_to": 83, "a_p": 65, "ab": [3, 8, 9, 10, 12, 13, 18, 19, 21, 25, 26, 29, 33, 35, 40, 43, 45, 47, 51, 53, 55, 57, 83], "abc": 6, "abl": [62, 79], "about": [61, 65], "abov": [47, 53, 59, 60, 85, 86], "absolut": [59, 66, 70, 72, 74, 76], "academ": 69, "acc": [66, 67, 69, 70, 72, 76], "acc_fn": [66, 67, 70, 72, 74, 76], "accept": 59, "access": [66, 70, 72, 74, 76], "accompani": 59, "accord": [19, 45, 84], "accordingli": 79, "account": 82, "accur": 59, "accuraci": [59, 65, 66, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "accuracy_scor": 69, "achiev": [62, 65, 67, 86], "aclanthologi": [23, 24], "across": 3, "action": 59, "activ": [5, 6, 12, 13, 46, 47, 49, 50, 65, 67], "activation_lay": 13, "actual": 65, "ad": [6, 19, 59, 60, 65], "adaboost": 60, "adam": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "adapt": [6, 58], "add": [3, 6, 13, 19, 58, 60, 66, 67, 70, 72, 74, 76, 85], "add_patch": 86, "add_self_loop": [6, 11], "addit": [5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 59, 65, 68, 69, 70, 71, 73, 74, 75, 76, 79], "addition": [6, 66, 67, 70, 72, 74, 76, 81], "address": [59, 65], "adjac": [6, 7, 8, 9, 10, 18, 19, 37, 38, 39, 40, 46, 47, 49, 50, 51, 55, 62, 63, 64, 65, 69, 77, 78, 79, 81, 82, 86], "adjacency_0": [5, 6, 7, 8, 9, 10, 38, 39, 40, 62, 63, 65, 77, 78, 83], "adjacency_0_list": [62, 63], "adjacency_0_test": [62, 63], "adjacency_0_train": [62, 63], "adjacency_1": [64, 65], "adjacency_1_down": 83, "adjacency_1_list": 64, "adjacency_1_test": 64, "adjacency_1_train": 64, "adjacency_1_up": 83, "adjacency_2": 83, "adjacency_down_1_norm": [50, 51, 83], "adjacency_down_2_norm": [50, 51, 83], "adjacency_dropout": 19, "adjacency_dropout_r": 18, "adjacency_matrix": [62, 63, 64, 65, 77, 78, 81, 86], "adjacency_up_0_norm": [50, 51, 83], "adjacency_up_1_norm": [50, 51, 83], "affect": 86, "affin": 79, "after": [5, 6, 29, 30, 31, 32, 33, 34, 35, 60, 62], "again": [71, 79, 80], "agerberg": 59, "agg": [3, 8, 10, 19, 45, 80], "agg_": [10, 13, 19, 45, 63, 64, 66, 67, 80], "aggr": [54, 65], "aggr_func": [0, 3, 6, 19, 47], "aggr_func_int": 26, "aggr_func_intra": 26, "aggr_norm": [1, 29, 48, 49, 54, 55], "aggr_norm_func": [41, 49, 55], "aggreg": [1, 2, 3, 4, 6, 10, 19, 26, 29, 34, 35, 45, 46, 47, 48, 49, 50, 54, 55, 59, 62, 65, 71, 72, 79, 85], "aggregate_fn": 10, "ahead": 86, "aiden": 59, "aim": [60, 62, 79], "al": [8, 9, 10, 29, 33, 35, 53, 59, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 85, 86], "aldo": [59, 61], "alessandro": 59, "alexand": 59, "alexandro": 77, "algorithm": [62, 79], "align": [6, 8, 10, 13, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 62, 79, 85], "all": [1, 3, 6, 24, 25, 26, 30, 31, 43, 48, 58, 59, 60, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "all_triplet": 86, "alli": 66, "allow": [59, 81], "allset": [13, 27, 66, 67, 71, 72], "allset_lay": 27, "allset_transform": [27, 67], "allset_transformer_lay": 27, "allsetblock": [13, 27], "allsetlay": [13, 27], "allsettransform": [59, 67], "allx": 66, "almost": 65, "alon": 6, "along": [59, 62, 79], "alpha": [6, 21, 25, 26, 30, 31, 55, 62, 72, 79, 86], "alpha_": 71, "alpha_k": [6, 43, 62, 79], "alreadi": [65, 80, 82, 83, 84], "also": [19, 55, 60, 62, 63, 64, 65, 68, 71, 73, 75, 77, 78, 79, 80, 83, 84], "altern": [3, 59, 66, 70, 72, 74, 76], "although": 65, "alzamzmi": 59, "amend": 48, "among": 62, "amount": [23, 25, 28, 32, 34, 37, 39, 44, 52, 59, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 82], "amp": [8, 63], "amtric": [68, 71], "an": [1, 4, 6, 8, 10, 49, 55, 59, 60, 62, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "analysi": [7, 8], "angl": [65, 86], "ani": [47, 48, 60, 62, 63, 66, 67, 70, 72, 74, 76, 86], "announc": 59, "annual": 59, "anoth": 71, "anti": 86, "api": [59, 60], "append": [62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "appli": [0, 1, 3, 5, 6, 10, 12, 18, 19, 24, 26, 30, 31, 32, 33, 34, 35, 47, 57, 67, 71, 77, 79, 85, 86], "apply_regular_dropout": 19, "approach": 62, "appropri": [59, 60, 65], "approxim": [42, 43, 86], "ar": [3, 6, 8, 10, 12, 13, 19, 21, 29, 33, 35, 40, 43, 45, 47, 49, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "arbitrari": 81, "arbitrarili": 81, "architectur": [3, 8, 10, 21, 26, 29, 33, 35, 40, 43, 45, 47, 51, 53, 55, 57, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 83, 85, 86], "archiveprefix": 61, "area": 65, "arg": [82, 83], "argmax": [62, 65, 66, 67, 69, 70, 72, 73, 74, 75, 76, 86], "argsort": 86, "argument": [5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 60, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79], "around": 86, "arrai": [60, 66, 67, 70, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "arrow": 86, "articl": 65, "arxiv": [3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 21, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 40, 43, 45, 47, 51, 53, 55, 57, 61], "arya": [25, 26, 72], "ask": 59, "assert": [60, 66, 67, 70, 72, 74, 76, 86], "assign": [25, 44, 50, 60, 77, 78, 79, 80, 81, 82, 83, 86], "associ": [3, 26, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83], "assum": [1, 3, 24, 26, 43], "aten": 65, "att": [1, 3, 7, 8, 24, 43, 44, 45, 49, 63, 65, 71, 80], "att_activ": [5, 6, 62], "att_lift": [5, 62], "att_weight": 65, "attent": [1, 2, 3, 5, 6, 7, 8, 24, 42, 43, 44, 45, 59, 67, 71], "attet": 6, "attr_nam": [66, 70, 72, 74, 76], "attribut": [60, 66, 70, 72, 74, 76], "audun": 59, "author": [59, 61, 66, 67, 70, 72, 86], "autoencod": [45, 59], "autom": 60, "automat": [59, 79], "autoreload": [63, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "avail": [61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 79, 80], "averag": [6, 9, 54, 63, 64, 82, 84, 86], "avg": 44, "avoid": [6, 49, 55], "awesom": [8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 61, 67, 72], "ax": 86, "axi": [60, 86], "b": [10, 13, 19, 21, 24, 26, 29, 31, 33, 35, 45, 47, 49, 50, 51, 60, 64, 65, 66, 67, 70, 71, 72, 80, 81, 82, 83], "b1": [18, 48, 49, 65, 77, 78, 81, 82, 85], "b2": [48, 49, 65, 81, 82, 85], "b3": 81, "b_": [10, 47, 64, 65, 80, 81], "b_1": [13, 19, 20, 21, 24, 26, 29, 31, 33, 35, 38, 40, 49, 50, 51, 57, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 83], "b_2": [8, 49, 50, 51, 57, 63, 79, 83], "b_2b_2": 79, "b_r": [46, 47, 64, 81], "ba": 67, "back": 19, "backpropag": 65, "backward": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "ballest": 59, "barbarossa": [5, 6, 43], "barikbin": 59, "base": [0, 1, 3, 4, 10, 11, 26, 27, 41, 45, 59, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 82, 85, 86], "base_model": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "bastian": [59, 84], "batch": [6, 86], "batch_siz": [65, 86], "bathnorm": 29, "battiloro": [5, 6, 43, 59, 79], "bazhenov": 59, "becaus": [77, 78, 82, 85], "becom": [68, 71, 79], "been": [62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "befor": [57, 59, 60, 86], "beforehand": 19, "begin": [6, 8, 10, 13, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 60, 62, 79], "being": [44, 59, 79], "belong": [3, 60, 65, 77, 78, 79, 80, 81, 82, 83], "below": [47, 53, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "benchmark": [59, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 82, 84, 85], "bengio": [6, 20, 21], "bernardez": 59, "best": [59, 67], "beta": [21, 30, 31, 65, 86], "beta_": 71, "better": 86, "between": [3, 6, 8, 10, 13, 19, 24, 26, 47, 53, 62, 65, 79, 81], "beyond": [3, 7, 8, 20, 21, 51, 61, 62, 65, 79], "bia": [13, 21, 62, 63, 65, 79, 82, 85], "bias_gain": 21, "bias_init": 21, "big": 60, "bigcup": [47, 81], "bigg": [62, 79, 82, 85], "bigoplus_": [6, 43, 62, 79], "bigotimes_": [6, 43, 62, 79], "binari": [37, 39, 42, 46, 50, 52, 62, 69, 70, 73, 75, 79], "binary_cross_entropi": 82, "binary_cross_entropy_with_logit": [77, 78, 79, 80, 81, 83, 85], "bipartit": 13, "birdal": [3, 59, 61], "black": [59, 86], "blank": 60, "block": [13, 59], "blue": 61, "blueprint": 61, "bodnar": [9, 10, 59, 64], "bogdan": [47, 53, 84], "bool": [1, 3, 5, 6, 7, 8, 12, 13, 21, 29, 30, 31, 32, 33, 34, 35, 44, 45, 48, 49, 54, 55, 60], "boolean": 60, "both": [60, 62, 65, 79, 86], "boundari": [7, 9, 10, 20, 23, 25, 28, 32, 34, 39, 57, 64, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 81, 86], "bracket": 60, "branch": 60, "break": 60, "brent": 59, "broadcast": [4, 58, 63, 68, 71, 82, 85], "brodi": 6, "build": [1, 2, 56, 59, 60, 86], "built": [6, 59, 60], "bunch": [51, 83], "b\u00f6kman": 59, "c": [8, 13, 19, 21, 24, 26, 29, 31, 33, 35, 40, 47, 49, 51, 61, 62, 63, 65, 66, 67, 70, 71, 72, 78, 81, 83, 86], "c0": 86, "c_0": 86, "c_1": 86, "c_r": [6, 62], "cai": 45, "calcul": [42, 60, 66, 67, 70, 72, 74, 76], "call": [3, 19, 49, 55, 60, 67, 86], "callabl": [6, 13, 19, 26], "can": [1, 3, 6, 8, 11, 21, 43, 47, 48, 55, 57, 59, 60, 61, 65, 66, 70, 71, 72, 74, 76, 77, 78, 79, 81, 83, 85, 86], "can_lay": 11, "canlay": [5, 6, 11, 62], "capabl": 86, "capit": 60, "captur": 62, "cardin": 21, "casanova": 6, "case": [10, 59, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 83, 84, 86], "case_bas": 69, "cat": 6, "categori": [66, 67, 69, 70, 72, 74, 76], "cc": 65, "cc_list": [62, 63, 64], "ccxn": [8, 11], "ccxn_layer": 11, "ccxnlayer": [7, 8, 11, 63], "cdist": 86, "cdot": [6, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 47, 49, 51, 53, 55, 57, 62, 65, 70, 71, 72, 77, 78, 79, 81, 83, 85, 86], "cell": [1, 3, 5, 6, 7, 8, 9, 10, 24, 26, 36, 40, 43, 46, 47, 49, 50, 53, 54, 55, 59, 64, 65, 66, 67, 68, 70, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "cell_complex": [62, 63, 64], "cellcomplex": 62, "cellular": [9, 10, 59, 64], "center": [60, 86], "centroid": 86, "certain": [65, 66, 67, 70, 72, 74, 76, 85], "chain": [45, 57, 86], "challeng": 54, "chang": [77, 81, 86], "channel": [0, 5, 6, 8, 13, 37, 38, 39, 40, 43, 46, 47, 48, 50, 51, 52, 53, 54, 55, 65, 77, 78, 79, 80, 81, 83], "channel_fac": 85, "channels_dim": 65, "channels_edg": [21, 28, 34], "channels_in": 42, "channels_list": 45, "channels_nod": [20, 21, 23, 77, 78, 79, 80, 81, 82, 83, 85], "channels_per_lay": 65, "channels_x": 85, "char": 60, "charact": 60, "chebyshev": [49, 55], "chebyshev_conv": [41, 49, 55], "check": [10, 59, 60, 61, 77, 78], "checkout": 60, "chemic": 62, "chennel_edg": 85, "chien": [12, 13, 59, 66, 67], "choic": [59, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76], "choos": [81, 86], "chose": 84, "chosen": [59, 81], "cicitationcora": 74, "citat": [66, 67, 69, 70, 72, 74, 76], "cite": 60, "class": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "classif": [5, 20, 21, 23, 25, 28, 30, 32, 34, 37, 39, 40, 42, 43, 45, 46, 48, 50, 52, 53, 54, 56, 59, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84], "classifi": 65, "classm": 85, "claudio": 59, "clean": 59, "clear": [62, 79], "clearli": 59, "clone": [66, 67, 70, 72, 74, 76], "close": 81, "cloud": 86, "club": [59, 77, 78, 79, 80, 81, 82, 83], "cluster": 60, "cmp": [44, 45], "co": [10, 59], "coa2": 65, "coadjac": [45, 65], "coadjacency_2": 65, "coadjacency_matrix": 81, "coars": 62, "coboundari": [8, 9, 63, 64], "cochain": 83, "code": [59, 60, 86], "coeffici": [6, 62, 71], "cohomologi": [8, 63], "coincidence_matrix": 83, "col": [66, 67, 70, 72, 74, 76], "collabor": 59, "collect": [6, 66, 67, 68, 69, 71, 72, 85], "colon": 60, "color": 86, "column": 65, "com": [62, 65, 66], "combin": [12, 31, 62, 65], "combinatori": 59, "come": 3, "command": 79, "commit": 60, "common": [60, 62, 65], "commun": 60, "compact": 62, "compar": [77, 78, 79, 81, 83, 85], "comparison": [66, 67, 70, 72, 74, 76], "complex": [6, 7, 8, 25, 38, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 62, 64, 68, 71, 77, 78, 79, 84], "complex_dim": [44, 45, 80], "complex_typ": [77, 78, 79, 80, 81, 82, 83, 85], "compli": 59, "complic": [40, 43], "compon": [42, 60, 79], "compos": [2, 8, 10, 11, 21, 27, 29, 33, 35, 41, 65], "compound": 62, "compris": 19, "comput": [3, 4, 6, 7, 9, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 31, 32, 34, 37, 39, 42, 44, 46, 48, 49, 50, 52, 54, 55, 58, 59, 60, 62, 65, 71, 79, 86], "compute_normalization_matric": 21, "compute_projection_matrix": [41, 42], "concat": [5, 6, 49, 55], "concaten": [5, 6, 19, 62, 67, 71, 86], "concept": 4, "condorcet": 59, "confer": 84, "confirm": 86, "connect": [5, 6, 31, 40, 56, 65, 71, 78, 82, 86], "consid": [6, 25, 26, 48, 49, 54, 55, 62, 65, 77, 78, 79, 81, 82, 83], "consider": 59, "consist": [4, 31, 36, 58, 59, 60, 66, 67, 70, 72, 74, 76, 86], "constant": [32, 33], "constitu": [29, 31, 33, 35], "construct": [3, 6, 66, 67, 69, 70, 72, 74, 76, 86], "constructor": 86, "contact": 59, "contain": [30, 31, 56, 59, 62, 65, 66, 67, 69, 70, 72, 82, 86], "context": 71, "contirbut": 59, "contribut": [59, 71, 82], "contributor": [59, 60], "control": 21, "conv": [2, 4, 21, 63, 79], "conv_0_to_0": 63, "conv_0_to_1": 10, "conv_1_to_1": 10, "conv_1_to_2": 63, "conv_down": 79, "conv_harmon": 79, "conv_oper": [49, 55], "conv_ord": [48, 49, 55, 82], "conv_order_down": [54, 55, 85], "conv_order_up": [54, 55, 85], "conv_up": 79, "conveni": 60, "convent": [60, 62], "convert": [62, 63, 64, 65, 73, 75, 77, 78, 79, 80, 82, 83, 84], "convolut": [1, 6, 8, 9, 10, 21, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 59, 79], "convolv": 10, "coo_matrix": 83, "coord": [56, 86], "coordin": [65, 86], "copi": [66, 67, 70, 72, 74, 76], "cora": [66, 67, 69, 70, 72, 74, 76], "core": 4, "corner": [56, 86], "correct": [60, 62, 65, 73, 75, 86], "correctli": 59, "correspond": [3, 10, 26, 47, 53, 55, 62, 65, 67, 69, 74], "could": [19, 62, 65, 79, 81], "cours": [48, 60], "cpp": 65, "cpu": [26, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 83, 84], "creat": [3, 10, 56, 59, 60, 69, 71], "crit": [62, 63, 65, 73, 75], "criteria": 59, "criterion": 64, "cross": [65, 66, 67, 70, 72, 74, 76], "crossentropyloss": [62, 63, 65, 66, 67, 69, 70, 72, 73, 74, 75, 76], "crowdsourc": 59, "csr": 65, "csr_matrix": [77, 81], "cucurul": 6, "cuda": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 83, 84], "current": [66, 67, 70, 72, 74, 76, 79, 82, 85], "custom": [62, 79], "cw": [9, 10, 59], "cwn": [10, 11, 59], "cwn_layer": 11, "cwnlayer": [9, 10, 11, 64], "d": [19, 43, 55, 60, 71, 77, 83], "d_x": 31, "d_z": 31, "data": [3, 7, 8, 47, 53, 60, 61, 62, 66, 67, 72, 79, 81, 84], "datafram": 60, "dataload": 65, "datas": [66, 67, 70, 72, 74, 76], "dataset": [56, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79], "date": 59, "debug": [59, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "dec": 84, "decid": [59, 79], "decompos": 3, "deep": [3, 8, 10, 21, 26, 29, 33, 35, 40, 45, 47, 51, 53, 55, 57, 61, 62, 63, 64, 65, 67, 70, 77, 78, 79, 80, 81, 83, 85, 86], "def": [60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "default": [0, 1, 3, 5, 6, 8, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 42, 43, 44, 45, 47, 49, 54, 56, 60], "default_rng": 86, "default_valu": 60, "defin": [1, 2, 3, 43, 56, 59, 60, 62, 63, 64, 65, 66, 67, 69, 72, 73, 75, 79, 86], "definit": [65, 85], "defub": 65, "degre": 31, "dei": [3, 59, 61], "delaunai": [56, 86], "delet": [56, 86], "delta": 67, "demonstr": [77, 78], "denot": [3, 66, 67, 71, 72, 85, 86], "depend": 59, "depict": 59, "deprec": 82, "deriv": 79, "describ": [47, 56, 60, 67], "descript": [60, 65, 86], "design": 62, "detach": [66, 67, 70, 72, 74, 76], "detail": [3, 10, 59, 60, 62, 67, 79], "detect": [66, 67, 70, 72, 74, 76], "determin": [31, 86], "dev": 60, "develop": [59, 60], "devic": [26, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 83, 84], "dhgcn": 27, "dhgcn_layer": 27, "di": [5, 6, 43], "diag": 83, "diagon": 86, "diagram": [47, 53, 59, 65], "dict": [46, 47, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "dictionari": 81, "didact": [62, 79], "differ": [3, 47, 53, 60, 63, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "dihedr": 65, "dim": [58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "dim_siz": 58, "dimens": [1, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "dimension": [54, 65, 67, 86], "ding": [23, 24, 71], "dir": 68, "direct": 65, "directli": [3, 66, 70, 72, 74, 76], "directori": [59, 60], "discard": 86, "discret": 62, "discuss": 60, "disk": [56, 86], "disk_cent": 86, "disk_radiu": 86, "dist2cycl": [37, 38, 41], "dist2cycle_lay": 38, "dist2cyclelay": [38, 41], "distanc": 86, "distance_matrix": 86, "distinct": 65, "dive": 67, "diverg": 79, "divid": 72, "dmitrii": 59, "do": [13, 59, 66, 69, 70, 72, 74, 76, 77, 78, 81, 86], "doc": 60, "docstr": [10, 59], "document": [62, 63, 65, 69, 77, 79, 81, 82, 85], "doe": [3, 59, 60, 82, 85, 86], "domain": [4, 59, 61, 62, 63, 64, 66, 67, 69, 72, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "done": [60, 63, 64, 65, 66, 68, 71, 82, 84, 85, 86], "dong": [20, 21, 59, 70], "doster": 59, "dot": 83, "down": [6, 42, 43, 44, 45, 48, 50, 51, 54, 55, 79], "down_lap_list": 45, "down_laplacian": 62, "down_laplacian_1": [5, 6], "down_laplacian_list": 62, "down_laplacian_matrix": [62, 77, 79, 80, 82, 83, 85], "down_laplacian_t": 62, "down_laplacian_test": 62, "down_laplacian_train": 62, "downarrow": [6, 38, 43, 45, 47, 51, 53, 55, 57, 62, 65, 77, 79, 80, 81, 82, 83, 85, 86], "download": [66, 69], "downstream": [66, 67, 68, 70, 71, 72, 73, 74, 75, 76], "drifter": 86, "dropout": [5, 6, 12, 13, 18, 19, 20, 23, 30, 32, 34, 62], "dtype": [62, 66, 67, 68, 69, 70, 71, 72, 74, 76, 82, 85], "due": [63, 68, 71, 81, 82, 85], "duplic": [66, 67, 70, 72, 74, 76], "e": [1, 3, 5, 6, 12, 19, 49, 54, 55, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 82, 84, 85, 86], "e_": [66, 67], "e_aggr": [34, 35], "each": [0, 1, 3, 6, 24, 26, 40, 44, 45, 47, 48, 49, 55, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86], "earli": 59, "earlier": [59, 81], "eas": 60, "edg": [5, 6, 7, 8, 9, 10, 12, 13, 20, 21, 24, 25, 28, 29, 31, 32, 33, 34, 35, 38, 40, 42, 44, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "edge_attr": 62, "edge_channel": [50, 51], "edge_feat": [63, 64, 65, 68, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85], "edge_featur": 53, "edge_index": [62, 66, 67, 69, 70, 71, 72, 74, 76], "edge_lookup_t": 86, "edit": [59, 60], "editor": 84, "edu": [59, 65], "effect": [3, 19, 65], "effici": [47, 53, 77, 81, 84], "effort": 60, "einsum": [49, 55], "either": [26, 59, 60, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 86], "el": 65, "element": [6, 60, 65, 67], "elif": [82, 85], "elimin": [66, 67, 70, 72, 74, 76], "els": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 82, 83, 84, 85], "email": 59, "embed": [1, 24, 26, 49, 55, 65], "emerg": [77, 78, 79, 80, 81, 82, 83], "emerson": 59, "emnlp": [23, 24], "emploi": 65, "empti": [6, 66, 67, 70, 72, 74, 76], "encod": [62, 77, 78, 79, 80, 82, 83, 86], "encourag": 59, "end": [6, 8, 10, 13, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 60, 62, 77, 78, 79, 81, 83, 86], "end_nod": 86, "ensur": [63, 66, 67, 68, 70, 71, 72, 74, 76, 82, 85], "entir": [8, 62, 63, 64, 65], "entiti": 65, "entri": [48, 79], "entropi": [65, 66, 67, 70, 72, 74, 76], "enumer": [66, 67, 70, 72, 74, 76, 86], "ep": [32, 33], "epoch": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "epoch_i": [62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "epoch_loss": [62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "eprint": 61, "epsilon": 42, "epsilon_harmon": 42, "eq": [77, 78, 79, 80, 81, 82, 83, 85], "equal": [1, 60, 66, 67, 70, 71, 72, 74, 76, 86], "equat": [8, 10, 21, 26, 29, 32, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 60, 61, 62, 63, 64, 70, 77, 78, 79, 81, 83, 86], "equival": [59, 60, 65], "escalera": 59, "esp": 60, "essenti": 82, "estim": 79, "et": [8, 9, 10, 19, 29, 33, 35, 53, 59, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 85, 86], "etc": [44, 55, 60], "euclidean": [65, 86], "eval": [65, 66, 67, 69, 70, 72, 73, 74, 75, 76, 86], "evalu": [60, 62, 74], "even": 59, "everi": [29, 30, 31, 32, 33, 34, 35, 59, 66, 70, 72, 74, 76], "everyon": [59, 60], "everyth": 86, "ex": 59, "exampl": [49, 55, 59, 79, 82, 85, 86], "except": [60, 62, 79], "exist": 59, "exp": 71, "expect": [30, 31, 81, 83], "expens": [77, 81], "experienc": 60, "explain": 59, "explan": 60, "explicit": 19, "explicitli": 60, "exploit": [10, 62], "express": [59, 71], "extend": [13, 61, 82], "extens": [80, 82, 83, 84], "extract": [62, 66, 67, 70, 71, 72, 76], "ey": [77, 81], "f": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "f_": [66, 67], "f_0": 62, "face": [7, 8, 9, 10, 44, 48, 49, 50, 51, 52, 53, 54, 59, 63, 64, 65, 68, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85], "face_channel": [50, 51], "face_feat": [63, 64, 65, 68, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85], "face_featur": 53, "facilit": [62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "fail": 59, "fals": [1, 3, 5, 6, 7, 8, 12, 13, 29, 30, 31, 32, 33, 34, 35, 44, 45, 48, 49, 54, 55, 62, 63, 64, 68, 71, 73, 75, 82, 84, 85], "fashion": 79, "feat_dim": 81, "featur": [0, 1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86], "features_nod": 25, "feed": [62, 68, 71, 73, 75, 86], "feel": [59, 86], "field": 59, "fig": [59, 86], "figsiz": 86, "figur": [47, 53, 65], "file": [6, 59, 60, 65], "filenam": 60, "fill": 60, "filter": [42, 43, 49, 82], "final": [5, 7, 9, 10, 19, 37, 39, 42, 46, 48, 52, 54, 57, 59, 65, 77, 79, 85, 86], "final_channel": 65, "find": [59, 62, 86], "fiorellino": 59, "first": [10, 29, 31, 35, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "fit": 60, "fit_predict": 60, "flag": 21, "flake8": 59, "flatten": 83, "float": [1, 3, 5, 6, 12, 13, 19, 20, 21, 23, 24, 30, 31, 32, 33, 34, 42, 49, 55, 57, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "float32": 65, "floattensor": 65, "florian": 59, "flush": [62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "fn": [77, 79, 85], "folder": 60, "follow": [3, 6, 10, 56, 59, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "foral": [6, 43, 62, 71, 79], "fork": 60, "form": [12, 56, 59, 77, 78, 81, 82, 86], "formal": [71, 79], "format": [59, 60, 66, 70, 72, 74, 76, 82], "formul": 81, "forum": 51, "forward": [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "foster": 59, "found": [3, 65], "four": [77, 78, 79, 80, 81, 82, 83], "foward": 62, "frac": [26, 31, 49, 71, 72], "fraction": [5, 6], "framework": [12, 13, 28, 29, 30, 31, 32, 33, 34, 35, 66, 67], "frantzen": 59, "freder": 84, "free": [59, 86], "from": [1, 3, 5, 6, 8, 10, 18, 19, 21, 26, 29, 33, 35, 43, 45, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "from_numpi": [62, 65, 77, 78, 79, 80, 81, 82, 83, 85], "from_numpy_arrai": 86, "from_spars": [62, 63, 64, 68, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "full": 65, "fulli": [62, 65], "function": [1, 3, 5, 6, 12, 13, 19, 26, 31, 34, 35, 45, 46, 47, 48, 49, 50, 51, 55, 57, 58, 59, 60, 62, 64, 65, 66, 67, 72, 74, 77, 78, 79, 80, 81, 82, 83, 85, 86], "fung": 51, "further": [59, 62, 79], "g": [49, 54, 55, 60, 66, 67, 71, 79, 86], "gain": [1, 3, 21, 24, 49, 55, 57], "gamma": [6, 62], "gardaa": 59, "gat": [6, 62, 79], "gatv2": [6, 62], "gavrilev": 59, "gbg141": [63, 65, 77, 81, 82, 85], "gca": 86, "ge": [77, 81], "gener": [25, 26, 40, 56, 60, 62, 64, 65, 66, 67, 74, 78, 79, 82], "generalizedmean": [26, 27], "generate_complex": [41, 56, 86], "generate_trajectori": [41, 56, 86], "genetic_algorithm": 69, "geom_dataset": [66, 67, 69, 70, 72, 74, 76], "geometr": [40, 59], "geometri": 59, "georg": 59, "get": [19, 57, 59, 66, 67, 70, 72, 74, 76, 77, 79, 82, 85, 86], "get_simplex_attribut": [77, 78, 79, 80, 81, 82, 83, 85], "get_simplicial_featur": [82, 85], "ghada": [59, 61], "gin": [32, 33], "git": 60, "github": [20, 21, 59, 65, 66, 67, 72], "giusti": [5, 6, 43, 59, 62, 79], "give": [4, 62, 65, 67, 79], "given": [1, 3, 8, 10, 19, 21, 29, 33, 35, 40, 45, 47, 57, 59, 62, 63, 64, 65, 66, 67, 70, 71, 72, 77, 78, 79, 81, 82, 83, 85, 86], "glaze": 57, "gleb": 59, "global": [23, 25, 28, 32, 34], "go": [3, 9, 10, 61, 62, 64, 65, 79, 86], "goal": 59, "good": [60, 84], "googl": [59, 60], "gpu": [62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 80], "gradient": 79, "gradual": 18, "grand": 59, "graph": [3, 5, 6, 13, 20, 21, 28, 29, 30, 31, 32, 33, 34, 35, 48, 49, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "graphic": [8, 10, 21, 29, 33, 35, 40, 45, 47, 57, 61], "great": 60, "green": 86, "grlplu": [20, 21], "ground": [65, 86], "group": [77, 78, 79, 80, 81, 82, 83], "gt": [62, 64, 86], "guess": 86, "guid": 60, "guillermo": 59, "gupta": [25, 26], "guzm\u00e1n": [3, 40, 59, 61], "h": [3, 24, 31, 40, 47, 51, 62, 67, 71, 72, 78, 79, 81, 82, 83, 85], "h0": 81, "h1": 81, "h2": 81, "h3": 81, "h_": [8, 24, 38, 45, 47, 53, 63, 71, 77, 80, 81], "h_r": [46, 47, 53, 81], "h_x": [6, 8, 10, 13, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 53, 55, 57, 62, 63, 64, 65, 66, 67, 70, 71, 72, 77, 78, 79, 80, 81, 85, 86], "h_y": [6, 8, 10, 13, 19, 21, 26, 29, 33, 35, 40, 43, 49, 51, 55, 57, 62, 63, 64, 65, 66, 67, 70, 72, 78, 79, 83, 85, 86], "h_z": [6, 10, 13, 19, 43, 62, 64, 66, 67], "ha": [0, 1, 6, 60, 63, 64, 68, 71, 77, 78, 79, 81, 82, 84, 85], "hajij": [3, 7, 8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 62, 63, 65, 78, 79], "hajij2023topolog": 61, "harmon": 42, "hat": 86, "have": [1, 3, 19, 24, 26, 43, 49, 55, 59, 60, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86], "hb": 65, "hbn": 65, "hbns_0_1_level1": 65, "hbns_0_1_level2": 65, "hbns_1_2_level1": 65, "hbns_1_2_level2": 65, "hbs_0_level1": 65, "hbs_0_level2": 65, "hbs_1_level2": 65, "hbs_2_level2": 65, "he": [66, 67, 70, 72, 74, 76], "head": [5, 6, 62, 67], "helen": 59, "help": [59, 60], "helper": 51, "henc": 79, "henri": 59, "here": [49, 51, 55, 59, 60, 62, 69, 77, 78, 80, 81, 82, 83, 86], "heydari": [18, 19, 59, 69], "hf_": 67, "hg": [68, 71, 73, 75], "hg_list": [68, 71, 73, 75], "hgnn": 74, "hid_channel": [9, 64], "hidden": [5, 7, 9, 12, 13, 18, 20, 21, 23, 25, 28, 29, 30, 31, 32, 34, 37, 39, 42, 46, 48, 52, 54, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 86], "hidden_channel": [12, 13, 18, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 34, 35, 42, 54, 56, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 85, 86], "hidden_channels_al": [48, 82], "hierarch": [62, 65], "high": [37, 39, 40, 65], "higher": [40, 47, 53, 59, 62, 65, 78, 81, 84, 85], "highest": [44, 45, 86], "highli": 59, "highlight": 71, "hing": 79, "hmc": 65, "hmc_layer": 65, "hmclayer": 65, "hmpnn": [19, 27, 59], "hmpnn_layer": 27, "hmpnnlayer": [18, 19, 27], "hnhn": [21, 27, 59], "hnhn_layer": 27, "hnhn_layer_bi": 27, "hnhnlayer": [21, 27], "hoan": [59, 65], "hoanmeshclassifi": 65, "hodg": [42, 49, 53, 55, 79, 81, 82], "hodge_laplacian_matrix": [82, 85], "hoff": 59, "hold": [45, 60], "honor": 59, "hop": [66, 67, 70, 72, 74, 76, 79, 85], "hopp": 59, "host": 59, "hot": [77, 78, 79, 80, 82, 83], "how": [6, 60, 67, 77, 78, 79], "howev": [62, 82, 85], "hsn": [39, 40, 41, 59], "hsn_layer": [40, 59], "hsn_train": 59, "hsnlayer": [40, 41, 59], "html": [47, 53, 57, 84], "http": [3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 40, 43, 45, 47, 51, 53, 55, 57, 62, 65, 66, 77, 78, 79, 80, 81, 82, 83, 84], "huan": [23, 24], "huang": [28, 29, 30, 31, 32, 33, 34, 35, 59], "hy": 79, "hyper": [29, 31, 33, 35, 86], "hyperedg": [12, 13, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 59, 66, 67, 68, 71, 72, 74, 76], "hyperedge_in_channel": 19, "hyperedge_s": [66, 67, 70, 72, 74, 76], "hyperedge_to_node_messaging_func": 19, "hypergat": [24, 27, 71], "hypergat_lay": 27, "hypergatlay": [24, 27], "hypergraph": [12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 59, 66, 67, 72, 73, 75], "hypergraph_modular": 79, "hypernetx": 79, "hypernod": [20, 21], "hyperparamet": [21, 31, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "hypersag": [26, 27], "hypersage_lay": 27, "hypersagelay": [26, 27], "i": [1, 2, 3, 5, 6, 8, 10, 11, 19, 21, 26, 27, 29, 30, 31, 33, 35, 38, 40, 41, 42, 45, 47, 53, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "i_": 86, "i_1": 86, "i_2": 86, "i_cc": 62, "i_complex": [63, 64, 68, 71, 84], "i_i": 65, "i_j": 86, "i_m": 86, "i_n": 86, "i_x": 65, "icann": [18, 19], "iclr": [12, 13, 40], "icml": [20, 21, 57], "id": [40, 51, 60], "ident": [59, 65, 67, 77, 78], "identifi": 59, "idx": [65, 86], "idx_dict": 86, "ignor": 60, "igraph": 79, "ii": 62, "iii": 62, "ij": 71, "ijcai": [28, 29, 30, 31, 32, 33, 34, 35], "illustr": [8, 10, 21, 29, 33, 35, 40, 45, 47, 57, 84], "immedi": 60, "imper": 60, "implement": [1, 3, 4, 6, 8, 9, 10, 18, 20, 21, 23, 24, 25, 26, 28, 29, 31, 32, 33, 34, 35, 37, 39, 40, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 65, 66, 67, 70, 72, 79, 81, 86], "import": [21, 31, 59, 60, 62, 63, 64, 66, 67, 69, 72, 79, 86], "in_channel": [1, 3, 6, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 42, 43, 49, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "in_channels_": 10, "in_channels_0": [5, 6, 7, 8, 9, 10, 49, 52, 53, 62, 63, 64, 82, 84, 85], "in_channels_1": [5, 6, 7, 8, 9, 10, 49, 52, 53, 62, 63, 64, 82, 84, 85], "in_channels_2": [7, 8, 9, 10, 49, 52, 53, 63, 64, 82, 84, 85], "in_channels_al": [44, 48, 80, 82], "in_channels_nod": 32, "in_channels_r": 6, "in_featur": [18, 62, 63, 65, 79, 82, 85], "in_linear_0": 82, "in_linear_1": 82, "in_linear_2": 82, "in_memory_dataset": [66, 70, 72, 74, 76], "incid": [13, 18, 19, 20, 21, 24, 26, 29, 30, 31, 33, 35, 38, 40, 44, 45, 46, 47, 48, 49, 50, 51, 57, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 85], "incidence_0_1": [77, 79, 83], "incidence_1": [12, 13, 18, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 50, 51, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 82, 83, 85, 86], "incidence_1_0": 83, "incidence_1_2": 83, "incidence_1_list": [68, 71, 73, 75, 82, 85], "incidence_1_norm": [50, 51, 83], "incidence_1_t": [9, 10, 64, 80], "incidence_1_t_list": 64, "incidence_1_t_test": 64, "incidence_1_t_train": 64, "incidence_1_test": [71, 73, 75, 82], "incidence_1_train": [71, 73, 75, 82], "incidence_1_v": [73, 75], "incidence_2": [9, 10, 50, 51, 56, 57, 64, 65, 82, 83, 85, 86], "incidence_2_1": 83, "incidence_2_list": [64, 82, 85], "incidence_2_norm": [50, 51, 83], "incidence_2_t": [7, 8, 63, 80], "incidence_2_t_list": 63, "incidence_2_t_test": 63, "incidence_2_t_train": 63, "incidence_2_test": [64, 82], "incidence_2_train": [64, 82], "incidence_al": [48, 49, 82], "incidence_matrix": [63, 64, 65, 68, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 85, 86], "incidence_t_list": [44, 80], "incidencet_list": 45, "includ": [1, 59, 60, 65, 86], "inclus": 60, "incorpor": 62, "incorrect": [63, 68, 71, 82, 85], "increas": 86, "ind": 66, "indent": 60, "independ": [62, 67], "index": [6, 58, 60, 65, 66, 81, 86], "indic": [6, 58, 77, 78, 79, 80, 81, 82, 83, 86], "indices_includ": 86, "individu": [66, 70, 72, 74, 76], "indro": 59, "induct": [25, 26], "inf": 86, "inform": [60, 65, 66, 67, 69, 71, 72, 85], "infrastructur": 59, "inherit": [3, 59], "init": 86, "init_bias": 21, "initi": [1, 3, 6, 8, 10, 21, 24, 26, 29, 33, 35, 40, 43, 45, 47, 49, 55, 57, 62, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 82], "initial_x_1": 69, "initialization_gain": [1, 3, 24], "inmemorydataset": [66, 70, 72, 74, 76], "inner": [12, 18, 20, 23, 25, 28, 30, 32, 34], "inplac": 13, "input": [0, 1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85], "input_drop": [30, 32, 34, 74, 75, 76], "insert": 13, "insid": 86, "instal": [60, 79], "instanc": 86, "instanti": [3, 64], "instead": [60, 66, 70, 72, 74, 76, 82], "instruct": 60, "int": [1, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 53, 54, 55, 56, 57, 58, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "integr": 65, "inter": [0, 26, 72, 82], "interact": 62, "interc": 64, "intermedi": 65, "intermediate_channel": 65, "intermediate_channels_al": 82, "intern": [65, 66, 70, 72, 74, 76], "interpret": 72, "interv": 65, "intra": [26, 45, 72], "intra_aggr": [41, 45], "introduc": [19, 62, 65, 69, 71, 79], "introduct": 62, "invari": [66, 67], "invers": 77, "invit": 59, "involv": [62, 79], "io": [20, 21], "ipykernel_1791": 66, "ipykernel_20995": 76, "ipykernel_33450": 72, "ipykernel_7355": 74, "ipykernel_909051": 67, "ipykernel_96287": 70, "ipynb": 59, "is_avail": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 80, 83, 84], "isinf": 83, "isnan": [63, 64, 82, 84, 85], "isort": 59, "issu": [59, 65], "istvan": [7, 8], "isufi": 55, "item": [18, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "iter": 67, "itertool": 86, "its": [3, 19, 29, 31, 33, 35, 59, 60, 65, 69, 71], "itself": 85, "j": [71, 72, 77, 81, 83, 86], "jan": 59, "jen": 59, "jenn": 59, "jk": 71, "johan": 59, "josef": 59, "journal": 59, "jstor": [77, 78, 79, 80, 81, 82, 83], "juli": 59, "just": [79, 81, 86], "k": [6, 10, 19, 43, 45, 49, 61, 62, 64, 67, 71, 79, 80, 83, 86], "k6e9": 40, "k_pool": [5, 6], "karat": [59, 77, 78, 79, 80, 81, 82, 83], "karate_club": [77, 78, 79, 80, 81, 82, 83, 85], "karateclub": [70, 77, 78, 79, 80, 81, 82, 83], "karthikeyan": [59, 61], "keep": [5, 6, 60, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 76, 77, 78, 79, 80, 81, 82, 83], "kept": [62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "kernel": 79, "kero": 77, "keyword": 26, "kimiyoung": 66, "kving": 59, "kwarg": [5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "l": [8, 10, 18, 19, 38, 40, 43, 45, 47, 51, 53, 55, 57, 62, 63, 64, 65, 71, 72, 77, 78, 79, 80, 81, 82, 83, 85, 86], "l0": [48, 65], "l1": 65, "l1_d": 48, "l1_u": 48, "l2": [48, 65], "l_": [43, 55, 57, 79, 80, 85, 86], "l_0": 49, "l_1_down": 49, "l_1_up": 49, "l_2": 49, "l_lower": 53, "l_r": 79, "l_tilde_pinv": 77, "l_upper": 53, "la": 81, "label": [25, 44, 47, 50, 53, 60, 62, 63, 64, 65, 68, 69, 71, 73, 75, 79, 84, 86], "labels_": 60, "laid": 61, "languag": 60, "lap": 49, "lap_down": [49, 55], "lap_up": [49, 55], "laplacian": [42, 43, 44, 45, 48, 49, 53, 54, 55, 79, 80, 81, 82, 84], "laplacian_0": [49, 52, 53, 82, 84, 85], "laplacian_0_list": [82, 85], "laplacian_0_test": 82, "laplacian_0_train": 82, "laplacian_0s_test": 84, "laplacian_0s_train": 84, "laplacian_1": [52, 53, 84], "laplacian_1s_test": 84, "laplacian_1s_train": 84, "laplacian_2": [49, 52, 53, 82, 84, 85], "laplacian_2_list": [82, 85], "laplacian_2_test": 82, "laplacian_2_train": 82, "laplacian_2s_test": 84, "laplacian_2s_train": 84, "laplacian_al": [48, 49, 82], "laplacian_down": [42, 43, 54, 55, 79, 85], "laplacian_down_1": [49, 80, 82, 85], "laplacian_down_1_list": [82, 85], "laplacian_down_1_test": 82, "laplacian_down_1_train": 82, "laplacian_down_2": [80, 82, 85], "laplacian_down_list": [44, 80], "laplacian_down_test": 85, "laplacian_down_train": 85, "laplacian_up": [42, 43, 54, 55, 79, 85], "laplacian_up_1": [49, 82, 85], "laplacian_up_1_list": [82, 85], "laplacian_up_1_test": 82, "laplacian_up_1_train": 82, "laplacian_up_2": [82, 85], "laplacian_up_test": 85, "laplacian_up_train": 85, "larger": 85, "last": [18, 54, 57, 65, 81, 86], "last_nod": 86, "later": 86, "latex": 60, "latter": 65, "layer": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "layer_drop": [20, 23, 30, 32, 34, 75, 76], "layer_dropout": 12, "layout": 77, "ld": 77, "ldot": 86, "lead": [63, 68, 71, 82, 85], "leaki": 65, "leakyrelu": [5, 6, 62, 65, 71, 79], "learn": [3, 8, 10, 20, 21, 25, 26, 29, 31, 33, 35, 40, 45, 47, 51, 53, 55, 57, 60, 61, 62, 63, 64, 65, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "learnabl": [1, 3, 6, 13, 21, 29, 35, 38, 40, 43, 47, 49, 53, 55, 57, 62, 65, 67, 79, 85], "learning_r": 65, "learnt": [66, 67], "lecha": 59, "left": [3, 10, 26, 45, 56, 60, 64, 65, 71, 72, 86], "leftarrow": [3, 72], "leftmost": 47, "legend": 86, "lehman": [9, 10, 64], "len": [0, 65, 66, 67, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "length": [46, 47, 60, 69], "leq": [81, 86], "less": 86, "let": [65, 66, 67, 71, 72, 86], "letter": 60, "leu": 55, "lev": 59, "level": [5, 24, 30, 45, 59, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85], "leverag": [59, 79], "lg": 61, "li": [23, 24], "lib": [63, 66, 68, 70, 71, 72, 74, 76, 77, 81, 82, 85], "librari": 58, "lift": [5, 6, 59, 62, 63, 64, 65, 66, 67, 72, 73, 75, 77, 78, 79, 80, 81, 82, 83, 85], "lift_lay": 62, "liftlay": [6, 11, 62], "like": [49, 55, 57, 60, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 79, 81, 82, 85, 86], "likelihood": 86, "likewis": 82, "lil_matrix": [77, 81], "limits_": 71, "lin": 62, "lin0": 80, "lin_0": [62, 63, 64, 84], "lin_1": [62, 63, 64, 84], "lin_2": [63, 64, 84], "linalg": 77, "line": 60, "linear": [1, 6, 9, 19, 23, 25, 28, 29, 31, 32, 34, 44, 54, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "linear_x0": 83, "linear_x1": 83, "linear_x2": 83, "link": [59, 60], "lint": 59, "linv": [37, 38, 77], "list": [0, 12, 13, 44, 45, 56, 60, 65, 66, 67, 68, 70, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "liter": [0, 1, 3, 6, 19, 21, 24, 26, 34, 35, 43, 47, 57], "literatur": [59, 61], "liu": [23, 24], "livesai": [3, 59, 61], "livi": [18, 19, 69], "li\u00f2": 6, "ln": 67, "load": [59, 63, 64, 65, 68, 71, 74, 77, 78, 80, 81, 82, 83, 84, 85], "load_ext": [63, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "loader": 86, "local": [66, 68, 70, 71, 72, 74, 76], "locat": [59, 60], "log": [53, 60, 81, 86], "log_softmax": 86, "logit": [82, 86], "long": [62, 65, 66, 67, 69, 70, 72, 74, 76], "longer": 65, "look": [49, 55, 60, 86], "lookup": 86, "loop": [6, 30, 31, 59, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86], "lorenzo": [5, 6, 43], "loss": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "loss_fn": [63, 66, 67, 68, 69, 70, 71, 72, 74, 76, 82, 84, 85], "loss_funct": 86, "low": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "lower": [5, 6, 46, 47, 49, 54, 55, 56, 62, 79, 80, 82, 85, 86], "lower_att": 62, "lr": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "lrnzgiusti": [5, 6], "lt": [62, 64, 86], "luca": 59, "lvert": [26, 72], "m": [6, 8, 38, 43, 45, 51, 53, 55, 57, 60, 63, 65, 71, 77, 80, 83, 85, 86], "m_": [3, 6, 8, 10, 13, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 62, 63, 64, 66, 67, 70, 71, 72, 77, 78, 79, 80, 81, 83, 85, 86], "m_x": [3, 6, 8, 10, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 63, 64, 65, 70, 71, 72, 77, 78, 80, 81, 83, 85, 86], "m_z": [19, 24, 26, 29, 31, 33, 35, 49, 71, 72], "machin": [59, 84], "made": [62, 77, 79, 82, 84, 85], "mai": [51, 59], "main": [23, 24, 60, 74], "maintain": 59, "make": [19, 32, 33, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 80, 86], "mani": [49, 60, 62], "manipul": 59, "manual_se": [62, 63, 64, 66, 67, 69, 70, 72, 73, 74, 75, 76, 86], "manuel": 59, "map": [6, 8, 10, 13, 19, 20, 21, 29, 33, 35, 38, 40, 46, 47, 57, 65, 83, 86], "markdown": 60, "maroula": 45, "mask": [19, 62, 69, 79, 86], "master": 66, "match": 59, "math": [59, 60, 62, 67, 71, 72, 85, 86], "mathbb": [62, 65, 66, 67, 71, 86], "mathbf": [3, 82, 85], "mathbin": 67, "mathcal": [3, 6, 8, 10, 13, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 62, 63, 64, 66, 67, 70, 71, 72, 77, 78, 79, 80, 81, 83, 85, 86], "mathemat": 4, "mathild": [59, 61], "mathrm": 81, "matplotlib": 86, "matric": [21, 44, 45, 46, 47, 48, 51, 59, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 81, 82, 84, 85], "matrix": [1, 3, 5, 6, 7, 8, 9, 10, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 42, 43, 44, 49, 50, 51, 53, 55, 57, 60, 63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86], "max": [23, 25, 26, 28, 32, 34, 62, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 81], "max_edg": [66, 67, 70, 72, 74, 76], "max_rank": [46, 47, 81, 82, 85], "max_siz": [66, 67, 70, 72, 74, 76], "maxim": 85, "maximum": [6, 46, 47, 81, 86], "maxium": 79, "mean": [0, 3, 6, 19, 26, 34, 35, 47, 49, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "mean_siz": [66, 67, 70, 72, 74, 76], "meaning": 62, "measur": 71, "mechan": [3, 5, 6, 8, 24, 62, 63, 65, 67, 71, 79], "median": [66, 67, 70, 72, 74, 76], "median_s": [66, 67, 70, 72, 74, 76], "meissner": 59, "melnyk": 59, "member": 59, "mention": 59, "merg": 0, "mesh": [63, 64, 66, 67, 68, 71, 72, 84], "messag": [0, 1, 2, 4, 6, 8, 10, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 39, 42, 43, 44, 45, 46, 47, 49, 50, 52, 53, 59, 62, 63, 64, 65, 66, 67, 68, 71, 72, 79, 81], "message_pass": 3, "messagepass": [2, 3, 49, 55], "messg": [63, 66, 67, 70, 71, 72, 74, 76, 77, 78, 84], "method": [0, 1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 65, 69], "metric": 69, "mh": 67, "michael": [59, 61], "mid": 86, "mid_nod": 86, "middl": [56, 86], "might": [66, 67, 68, 70, 71, 72, 73, 74, 75, 76], "milenkov": [12, 13], "min": [66, 67, 70, 72, 74, 76], "min_siz": [66, 67, 70, 72, 74, 76], "mind": 60, "minim": [63, 64, 65, 66, 67, 69, 70, 71, 72, 76, 82], "miolan": [3, 8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61], "misc": 61, "miss": 65, "mitchel": 57, "mlp": [12, 13, 27, 67], "mlp_activ": [12, 13], "mlp_dropout": [12, 13], "mlp_norm": [12, 13], "mlp_num_lay": [12, 13, 66, 67, 70, 72, 73, 74, 75], "mlr": [47, 53, 57, 84], "mm": [65, 77, 79, 85], "mode": [26, 74], "model": [6, 30, 37, 39, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84], "model_select": [62, 63, 64, 68, 71, 73, 75, 82, 84, 85], "modelo": 75, "modif": 59, "modifi": [59, 60, 80], "modified_fil": 60, "modul": [0, 3, 5, 6, 8, 10, 12, 13, 19, 21, 24, 26, 29, 31, 33, 35, 36, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "modulelist": [62, 63, 65, 79, 82, 85], "mood": 60, "more": [10, 19, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 81, 86], "moreov": 65, "most": [59, 60, 79, 81], "move": 65, "mse_loss": [63, 68, 71, 82, 85], "mseloss": [63, 64, 68, 71, 82, 84, 85], "msg": [66, 70, 72, 74, 76], "mukherje": [3, 59, 61], "multi": [6, 13, 60, 67], "multiclass": 20, "multihead": 67, "multiheadcellattent": [6, 11, 62], "multiheadcellattention_v2": [6, 11], "multiheadliftlay": [6, 11, 62], "multinomi": 60, "multipl": [12, 59, 60, 86], "multipli": 79, "multiset": [12, 13, 66, 67], "must": [59, 68, 71, 77, 78, 79, 80, 81, 82, 83, 85], "mustafa": [59, 61], "mutag": [62, 73, 75], "mutagen": 62, "my": 60, "my_method": 60, "my_param_1": 60, "my_param_2": 60, "my_result": 60, "myer": 59, "n": [3, 6, 10, 43, 45, 56, 59, 60, 61, 62, 64, 65, 71, 72, 79, 80, 86], "n_": [10, 43, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85], "n_0_cell": 8, "n_1": [6, 43, 62, 79], "n_1_cell": 8, "n_2": [6, 43, 62, 79], "n_2_cell": 8, "n_cell": 43, "n_class": 50, "n_edg": [5, 7, 9, 19, 20, 21, 23, 25, 28, 29, 32, 33, 34, 35, 38, 39, 40, 42, 48, 49, 50, 51, 52, 53, 54, 55, 57], "n_f": 65, "n_face": [7, 9, 48, 49, 50, 51, 52, 53], "n_featur": 60, "n_filter": [42, 43], "n_hyperedg": [13, 18], "n_k": [6, 43, 62, 79], "n_k_cell": 6, "n_layer": [5, 7, 9, 12, 18, 20, 23, 25, 28, 30, 32, 34, 37, 39, 42, 44, 46, 48, 50, 52, 54, 56, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "n_max": [56, 86], "n_messag": [3, 24, 26], "n_messages_to_merg": 0, "n_node": [5, 7, 9, 13, 18, 19, 20, 21, 23, 25, 28, 29, 32, 33, 34, 35, 37, 38, 39, 40, 42, 48, 49, 50, 51, 52, 53, 54, 57], "n_r_cell": 6, "n_rank_r_cel": [46, 47], "n_rank_r_minus_1_cel": [46, 47], "n_simplex": 55, "n_simplic": [48, 49, 54, 55], "n_skeleton_in": 0, "n_source_cel": [1, 3, 24, 43], "n_target_cel": [1, 3, 24, 26, 43, 49, 55], "n_target_nod": 26, "n_triangl": [49, 57], "n_v": 65, "name": [26, 59, 60, 62, 66, 67, 69, 70, 72, 73, 74, 75, 76, 79], "name_of_model": 59, "nan": [63, 64, 82, 84], "nanmean": [63, 64, 65, 82, 84, 85], "natesan": [59, 61], "nb": 1, "nbsphinx": [62, 67, 71, 72, 85], "ncol": 86, "ndarrai": [56, 60, 86], "neal": [59, 61], "neccessari": 74, "necessari": [6, 58, 59, 62, 65, 79], "need": [59, 62, 63, 64, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 83, 84, 86], "neg": [65, 86], "negative_slop": [62, 65], "neigborood": 83, "neigbors_mask": 86, "neighbor": [10, 19, 62, 66, 67, 70, 72, 74, 76, 85, 86], "neighborhood": [0, 1, 2, 3, 5, 6, 8, 10, 25, 26, 29, 43, 49, 59, 62, 63, 64, 65, 66, 67, 72, 79, 86], "neighborhood_0_to_0": 65, "neighborhood_0_to_1": 65, "neighborhood_1_to_1": 65, "neighborhood_1_to_2": 65, "neighborhood_2_to_2": 65, "neighbors_mask": 86, "neighbour": [57, 86], "neighbourhood": [5, 6, 66, 67, 70, 72, 74, 76], "neighibourhood": [66, 67, 70, 72, 74, 76], "neq": [79, 86], "net": [40, 51, 57, 59], "network": [3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 61], "networkx": 86, "neural": [3, 4, 7, 8, 10, 12, 13, 18, 19, 21, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 43, 45, 47, 49, 51, 53, 54, 55, 56, 57, 59, 61], "neural_network": 69, "neurip": [7, 8, 9, 10, 51], "neuron": [20, 21, 59], "new": [19, 59, 60, 63], "next": [57, 60, 71, 74, 86], "nikitin": 59, "nina": [59, 61], "nll": 86, "nllloss": 86, "nn": [4, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "nnz": 77, "no_grad": [62, 63, 64, 65, 68, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "nodal": 65, "node": [5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86], "node_channel": [50, 51, 83], "node_feat": [63, 64, 65, 68, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85], "node_featur": 53, "node_in_channel": 19, "node_to_hyperedge_messaging_func": 19, "non": [6, 62, 65, 79, 86], "none": [0, 1, 3, 5, 6, 8, 10, 12, 13, 19, 20, 21, 24, 26, 29, 31, 35, 38, 40, 42, 43, 45, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 60, 65, 82, 85, 86], "nonlinear": [71, 85], "nor": 59, "norm_lay": 13, "normal": [1, 6, 12, 13, 21, 29, 30, 31, 32, 33, 34, 35, 47, 48, 49, 50, 51, 53, 55, 65, 67, 81, 84], "normalize_higher_order_adj": 83, "normalize_incidence_matric": 21, "normalized_laplacian_matrix": 84, "notat": [60, 62, 63, 64, 65, 70, 77, 78, 79, 80, 81, 83, 85, 86], "note": [3, 6, 21, 40, 43, 45, 48, 49, 51, 53, 54, 55, 57, 59, 60, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 82, 86], "notebook": [62, 65, 66, 67, 68, 69, 70, 71, 72, 77, 78, 79, 82, 83, 84, 85, 86], "notic": 79, "novel": 79, "novic": 60, "now": [59, 62, 63, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 84, 86], "np": [56, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "npla": 77, "npz": 65, "num": [82, 85], "num_cel": 6, "num_channel": [49, 55], "num_class": [8, 62, 63, 64, 65], "num_edg": [6, 30, 31], "num_epoch": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "num_lay": [82, 85], "num_nod": [6, 30, 31, 66, 67, 70, 72, 74, 76], "num_of_j_simplic": 83, "num_of_k_simplic": 83, "num_pooled_edg": 5, "num_sampl": 62, "num_single_node_hyperedg": [66, 67, 70, 72, 74, 76], "number": [5, 6, 7, 9, 12, 13, 18, 19, 20, 25, 26, 30, 42, 43, 46, 48, 50, 54, 56, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86], "numpi": [56, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "nx": 86, "o": [60, 67, 79], "object": [6, 19, 60], "observ": 60, "obtain": [10, 54, 66, 67, 70, 72, 74, 76, 79, 82, 85, 86], "ocean": 86, "odin": 59, "odot": [24, 38, 43, 49, 71, 77], "offici": 6, "often": [66, 67, 70, 72, 74, 76], "olga": 59, "omega": 67, "onc": [59, 68, 71], "one": [1, 3, 21, 24, 47, 53, 54, 57, 59, 60, 63, 65, 66, 67, 70, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86], "one_dimensional_cells_mean": [63, 64, 82, 84, 85], "one_hop_neighborhood": [66, 67, 70, 72, 74, 76], "ones": [60, 69], "onli": [6, 8, 19, 53, 59, 60, 62, 65, 79, 82, 84, 86], "onto": [3, 79], "open": 59, "openreview": [40, 51], "oper": [5, 6, 13, 49, 55, 57, 62, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 79, 81, 82, 86], "operatornam": [35, 43, 71], "opportun": 59, "oppos": 60, "opt": [62, 63, 65, 66, 67, 68, 70, 71, 72, 76, 83], "optim": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "option": [1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 56, 59, 60, 66, 67, 70, 72, 74, 76], "optit": [66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "order": [3, 40, 42, 43, 47, 48, 49, 53, 54, 55, 57, 59, 62, 65, 78, 79, 81, 82, 84, 85, 86], "order_harmon": 42, "org": [3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 40, 43, 45, 47, 51, 53, 55, 57, 77, 78, 79, 80, 81, 82, 83], "organ": [4, 59, 81], "orient": 79, "origin": [6, 31, 59, 60, 62, 63, 64, 79, 81, 82, 84, 85, 86], "other": [58, 60, 86], "otherwis": [6, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 80, 86], "our": [59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "out": [58, 59, 60, 61, 62], "out_channel": [1, 3, 5, 6, 10, 26, 42, 43, 49, 54, 55, 57, 62, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "out_channels_0": 82, "out_channels_1": 82, "out_channels_2": 82, "out_dim": 71, "out_featur": [62, 63, 65, 79, 82, 85], "out_linear_0": 82, "out_linear_1": 82, "out_linear_2": 82, "out_pool": [66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "outlin": 65, "output": [1, 3, 5, 6, 8, 10, 12, 13, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 42, 43, 45, 47, 48, 49, 51, 53, 54, 55, 57, 59, 60, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "outstand": [62, 65], "over": [59, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86], "overflow": 6, "overset": [67, 79], "overview": 4, "overwrit": 3, "own": 3, "p": [26, 43, 55, 71, 72, 79], "p_d": [82, 85], "p_u": [82, 85], "p_v": 65, "pacif": 59, "packag": [59, 61, 63, 66, 68, 70, 71, 72, 74, 76, 77, 79, 81, 82, 85], "page": [60, 84], "pairwis": [62, 68, 71, 86], "pan": [12, 13], "papamark": [3, 45, 59, 61], "paper": [5, 6, 19, 20, 21, 59, 62, 65, 69, 70, 77, 78, 79, 82, 83, 84, 85, 86], "paperswithcod": 62, "papillon": [3, 8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 62, 63, 64, 65, 70, 77, 78, 79, 80, 81, 83, 85, 86], "papillon2023architectur": 61, "paramet": [0, 1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "parameter": 62, "parameterlist": 65, "parametr": [66, 67], "pars": 60, "part": [49, 55, 62, 77, 78, 79, 80, 81, 82, 83], "partial_1": 86, "particular": 62, "pascanu": 84, "pass": [0, 1, 2, 4, 5, 6, 8, 10, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 50, 51, 52, 53, 54, 56, 57, 59, 62, 63, 65, 66, 67, 68, 71, 72, 79, 81, 82, 85, 86], "path": [56, 86], "path_1": 86, "path_2": 86, "pattern": 79, "paul": [59, 61, 84], "pavlo": 59, "pdf": [5, 6, 7, 8, 20, 21, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 40, 45, 55, 60], "pdist": 86, "penal": 86, "peng": [12, 13], "per": [3, 24, 26, 59, 60, 65], "perceptron": [13, 67], "perfect": 65, "perform": [49, 54, 55, 59, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 83, 84, 86], "period": 60, "permut": [66, 67], "phi": [6, 43, 62, 65, 79], "phi_a": 65, "phi_u": 65, "pick": 86, "pinv": 77, "pip": [60, 79], "place": [13, 59, 60, 66, 67], "plane": 86, "planetoid": [66, 67, 69, 70, 72, 74, 76], "pleas": [59, 60, 62, 63, 65, 68, 71, 79, 82, 85], "plot": 86, "plot_complex": 86, "plot_path": 86, "plt": 86, "plu": [19, 79], "pmlr": 84, "point": [56, 86], "poli": 86, "polygon": 86, "pool": [5, 6, 9, 23, 25, 28, 32, 34, 44, 62, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "poollay": [6, 11], "pop": 13, "posit": 65, "possibl": 60, "potenti": 59, "power": [26, 83], "pr": 60, "practic": [1, 3, 43, 66, 67], "pre": [56, 59, 86], "pred": [73, 75, 86], "predict": [8, 57, 60, 62, 65, 86], "prefer": [6, 59, 60], "preprocess": 6, "presenc": 69, "present": [60, 62, 65], "press": [47, 53, 57, 84], "previou": 65, "previous": 59, "primarili": [2, 11, 27, 36, 41], "primaryclass": 61, "primit": 59, "princip": 59, "principl": [57, 86], "print": [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "prioriti": 59, "probabilistic_method": 69, "probabl": [5, 6, 12, 13, 65, 82], "problem": [66, 67, 70, 72], "procedur": [66, 67, 68, 70, 71, 72, 73, 74, 75, 76], "proceed": [47, 53, 57, 84], "process": [59, 60], "produc": [77, 78, 79, 81, 83, 85], "product": 86, "project": [9, 42, 43, 60, 63, 65, 77, 79, 82, 85], "projection_mat": 43, "propag": 72, "proper": 79, "propos": [6, 8, 10, 21, 24, 26, 29, 33, 35, 40, 43, 45, 47, 51, 53, 57, 62, 63, 64, 70, 72, 77, 78, 79, 82, 83, 84, 85, 86], "provid": [1, 3, 6, 31, 49, 55, 59, 60, 82, 85], "pseudocod": [49, 55], "pshm23": 53, "psi_k": [6, 43, 62, 79], "pt": 86, "publish": 59, "pull": [59, 60], "purpos": [59, 60, 63, 64, 65, 66, 67, 69, 70, 71, 72, 76, 77, 78, 79, 80, 81, 82, 83], "push": 60, "put": [66, 67, 81], "py": [58, 59, 60, 63, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 81, 82, 85], "pyplot": 86, "pyt": 51, "pytest": [59, 60], "python": [59, 60, 61], "python3": [63, 66, 68, 70, 71, 72, 74, 76, 77, 81, 82, 85], "pytorch": 65, "pytorch_scatt": 58, "q_": 79, "q_r": [43, 79], "qquad": [45, 49, 80], "quad": [6, 8, 10, 13, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 62, 63, 64, 65, 66, 67, 70, 71, 72, 77, 78, 79, 80, 81, 83, 85, 86], "qualifi": 59, "qualiti": 59, "quick": 86, "quit": 81, "quiver": 86, "r": [1, 3, 5, 6, 8, 10, 24, 43, 45, 46, 47, 53, 60, 62, 63, 64, 65, 66, 67, 71, 79, 80, 81, 86], "r_": 81, "r_cell": 6, "r_inv_sqrt": 83, "r_mat_inv_sqrt": 83, "rais": [60, 82, 85], "ramamurthi": [3, 40, 59, 61], "random": [56, 86], "random_split": 86, "randomli": 86, "rang": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "rank": [1, 3, 7, 9, 20, 23, 24, 25, 26, 28, 32, 34, 39, 42, 43, 46, 47, 50, 51, 53, 59, 62, 63, 64, 65, 68, 71, 77, 78, 79, 80, 81, 82, 85], "rank_": 81, "rank_0": [46, 81], "rank_1": [46, 81], "rank_2": [46, 81], "rank_3": [46, 81], "rapid": [63, 64, 65, 66, 67, 69, 70, 71, 72, 76, 82], "rate": [6, 18, 19, 20, 23, 30, 32, 34, 65], "rather": [3, 59, 60, 66, 67, 70, 72, 74, 76], "ratio": [5, 6, 65], "raw": 66, "razvan": 84, "re": [60, 77, 86], "readabl": [59, 60], "readi": [74, 86], "readout": [6, 48, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "real": [62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "reason": 86, "receiv": [3, 10, 19, 26, 59], "reciev": 19, "reciproc": 62, "recognit": 59, "recommend": [66, 67, 70, 72, 74, 76], "record": [59, 60, 68, 71], "red": 86, "reduc": [18, 19, 82], "reduct": [63, 68, 71, 82, 85], "refer": [3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 60, 62, 72, 79], "refrain": 81, "region": 86, "regular": [18, 19], "regular_dropout_r": 18, "regularli": 59, "reinforcement_learn": 69, "reiniti": 6, "relat": [60, 69], "relationship": 62, "relev": 60, "reload": [80, 82, 83, 84], "reload_ext": [80, 82, 83, 84], "relu": [0, 1, 6, 13, 24, 26, 47, 57, 62, 65, 71, 86], "remain": [59, 86], "remark": [62, 79], "remov": 86, "repeat": 60, "replac": 3, "repo": [67, 72], "repositori": [5, 6, 59, 60], "repres": [49, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 84, 86], "represent": [5, 10, 18, 19, 20, 21, 25, 26, 37, 39, 40, 42, 46, 47, 53, 54, 56, 59, 62, 65, 66, 67, 69, 71, 81, 84, 86], "reproduc": [59, 61], "reprsent": 19, "reqir": [66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "request": [59, 60, 65, 86], "requir": [8, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 80, 86], "requires_grad_": [66, 67, 70, 72, 74, 76], "research": [59, 84], "reset": [3, 6, 13, 21, 24, 29, 31, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57], "reset_paramet": [2, 3, 6, 13, 21, 24, 27, 29, 31, 35, 38, 40, 41, 43, 45, 47, 49, 51, 53, 55, 57], "reshap": 84, "resort": 59, "respect": [44, 59, 64, 65, 66, 67, 71, 72, 79, 82, 85, 86], "respons": 62, "rest": 60, "restrict": 59, "restructuredtext": 60, "result": [3, 60, 62, 63, 67, 68, 71, 82, 85], "ret": 82, "retriev": [19, 62, 63, 64, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84], "return": [0, 1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "revers": 86, "review": [59, 60, 61, 83], "reward": 59, "rgs21": 86, "rieck": [59, 84], "right": [3, 10, 26, 56, 60, 64, 65, 71, 72, 86], "rightarrow": [3, 6, 8, 10, 13, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 62, 63, 64, 65, 66, 67, 70, 71, 72, 77, 78, 79, 80, 81, 83, 85, 86], "rightarrow0": [19, 24, 29, 31, 33, 35, 49, 51, 71, 83], "rightarrow1": [19, 31, 49, 51, 83], "rightmost": 53, "rise": 67, "rm": 85, "rng": 56, "robin": [59, 61], "robust": 59, "roddenberri": [57, 59, 86], "roddenberry21a": 57, "role": 60, "romero": 6, "root": [62, 66, 67, 69, 70, 72, 73, 74, 75, 76], "rosen": [3, 59, 61], "round": 62, "rout": 1, "row": [30, 31, 32, 33, 34, 35, 65, 66, 67, 70, 72, 74, 76], "rowsum": 83, "rst": 60, "rub\u00e9n": 59, "rudinac": [25, 26], "rule": [66, 67], "rule_learn": 69, "run": [62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 79, 81, 86], "runner": 65, "ruochen": 84, "rusty1": 58, "rvert": [26, 72], "sadrodin": 59, "sage": 35, "said": 59, "sala": [47, 53, 84], "salatiello": 59, "salmonella": 62, "samaga": [3, 59, 61], "same": [0, 1, 3, 6, 24, 26, 43, 47, 48, 49, 53, 59, 60, 62, 63, 65, 68, 71, 79, 82, 85, 86], "sampl": [56, 60, 62, 65, 86], "sample_weight": 60, "san": [41, 42, 43, 59, 62, 77, 81, 83], "san_lay": 43, "sanborn": [3, 8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61], "sanconv": [41, 43, 79], "sanlay": [41, 43, 79], "santii": [77, 78], "sardellitti": [5, 6, 43], "sawin": [20, 21], "sc": [49, 56, 82, 85, 86], "sc8glb": 40, "sc_order": [48, 49, 82], "sca": [44, 45, 59], "sca_cmp": [44, 80], "sca_cmps_lay": 45, "scacmp": [41, 44, 80], "scacmpslay": [41, 45, 80], "scalar": [3, 21, 24, 63, 64, 86], "scale": [19, 86], "scale_unit": 86, "scardapan": 59, "scatter": [4, 58, 86], "scatter_add": [4, 58], "scatter_mean": [4, 58], "scatter_sum": [4, 58], "sccn": [41, 46, 47, 53, 59], "sccn_layer": [47, 53], "sccnlayer": [41, 47, 53, 81], "sccnn": [41, 48, 49], "sccnn_layer": 49, "sccnnlayer": [41, 49, 82], "scconv": [41, 50, 51], "scconv_lay": 51, "scconvlay": [41, 51], "schaub": [3, 59, 61], "scheme": [3, 6, 8, 45, 59, 63, 65, 79], "scholkemp": 59, "scikit": 60, "scipi": [77, 81, 83, 86], "scn": [47, 53], "scn2": [41, 52, 84], "scn2_layer": [47, 53], "scn2layer": [41, 47, 53], "scnn": [41, 54, 55, 82], "scnn_layer": 55, "scnnlayer": [41, 55, 85], "scofano": 59, "scone": [41, 56, 57, 59], "scone_lay": 57, "sconelay": [41, 57, 86], "score": [62, 86], "script": 60, "second": [10, 29, 31, 35, 59, 65, 66, 67, 80], "secret": 59, "section": [60, 65, 86], "see": [24, 26, 49, 51, 53, 59, 60, 61, 65, 86], "seed": 86, "seen": 79, "select": [59, 81, 85], "self": [6, 30, 31, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "send": [1, 3, 8, 10, 21, 59, 62, 63, 64, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 84], "sent": [3, 26], "separ": 60, "sequenc": 65, "sergio": 59, "serv": [77, 78], "set": [24, 26, 68, 70, 71, 72, 73, 74, 75, 76, 79, 81, 86], "set_titl": 86, "setdiag": 65, "setup": 86, "sever": [3, 4, 26, 59], "shape": [0, 1, 3, 5, 6, 7, 8, 9, 10, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "shapenet": 65, "share": [6, 19, 59, 62, 65], "share_weight": 6, "short": 60, "shortest": 86, "shortest_path": 86, "should": [3, 6, 59, 60, 62, 63, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 86], "show": [60, 77, 78, 86], "shrec": [63, 64, 65, 68, 71, 84, 85], "shrec16": [59, 63, 64, 65, 66, 67, 68, 71, 72, 82, 85], "shrec_16": [63, 64, 65, 68, 71, 82, 84, 85], "shrec_test": 65, "shrec_train": 65, "shrecdataset": 65, "shreya": [59, 61], "shuffl": [62, 63, 64, 65, 68, 71, 73, 75, 82, 84, 85, 86], "side": 60, "sigma": [13, 21, 24, 26, 38, 40, 43, 47, 51, 53, 55, 57, 66, 70, 71, 72, 77, 78, 81, 82, 83, 85, 86], "sigmoid": [0, 1, 6, 19, 26, 46, 47, 57, 62, 79, 81, 82, 86], "sign": [68, 71, 86], "signal": [5, 6, 62, 63, 64, 65, 68, 71, 73, 75, 79], "signal_lift_activ": 6, "signal_lift_dropout": 6, "signal_lift_readout": 6, "signal_pool_activ": 6, "similar": [59, 81], "similarli": [77, 78, 81], "simon": 59, "simpl": [59, 85], "simplci": 54, "simplciial": [68, 71], "simplex": [43, 44, 52, 53, 63, 64, 68, 71, 77, 78, 79, 80, 81, 82, 83, 85, 86], "simplex_order_k": 79, "simplex_order_select": 85, "simpli": [77, 78, 86], "simplic": [45, 48, 55, 79, 81, 82, 85, 86], "simplici": [36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 63, 64, 65, 68, 71, 84], "simplicialcomplex": [56, 73, 75, 86], "simplifi": [8, 21, 63], "sinc": [62, 77, 78, 81, 86], "singh": [51, 59], "singl": [3, 26, 59, 64], "singular": [77, 78, 79, 80, 81, 82, 83], "site": [63, 66, 68, 70, 71, 72, 74, 76, 77, 81, 82, 85], "six": 11, "size": [1, 12, 29, 49, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 81, 82, 84, 85, 86], "size_averag": 82, "skeleton": [45, 62, 86], "skip": [5, 6, 31, 37, 39, 40, 86], "skip_connect": [5, 6], "sklearn": [62, 63, 64, 68, 69, 71, 73, 75, 82, 84, 85], "slack": 59, "slope": 65, "small": [63, 64, 68, 71, 81, 82, 84, 85], "snippet": 60, "so": [67, 77, 78, 79, 80, 81, 82, 83, 85, 86], "social": [77, 78, 79, 80, 81, 82, 83], "softmax": [6, 11, 57, 65, 77, 78, 79, 80, 81, 82, 83, 85, 86], "softwar": [59, 60], "soham": [59, 61], "solv": [66, 67, 70, 72], "some": [56, 60, 66, 67, 70, 72, 74, 76, 81, 86], "sophia": [59, 61], "sort": [66, 67, 70, 72, 74, 76, 86], "sourc": [0, 1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59], "sourcetensor": [66, 67, 70, 72, 74, 76], "space": [60, 65, 82, 86], "span": 65, "spars": [1, 3, 4, 6, 8, 10, 13, 18, 19, 20, 21, 24, 29, 33, 35, 38, 40, 43, 46, 47, 49, 53, 55, 57, 60, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "sparse_coo": 77, "sparse_coo_tensor": [6, 69], "sparse_matrix": 60, "sparse_to_torch": 81, "sparsecsrtensorimpl": 65, "sparseefficiencywarn": [77, 81], "sparsiti": [77, 81], "spatial": 86, "special": 59, "specif": [1, 9, 59, 60, 64, 66, 67, 70, 71, 72], "specifi": [62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 82, 84, 85], "speed": 86, "spend": 86, "spinelli": 59, "split": [62, 63, 64, 68, 73, 75, 86], "sqrt": 31, "squar": [56, 60, 65, 86], "squareform": 86, "squeez": 86, "src": [6, 58, 65], "ssconv": 83, "stabl": [77, 78, 79, 80, 81, 82, 83], "stack": [57, 62, 63, 64, 66, 70, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "stage": 62, "stand": 69, "standard": [59, 60, 79], "stanford": 65, "start": [44, 59, 60, 86], "start_nod": 86, "state": [7, 9, 48, 52, 60, 65, 72], "statement": 60, "staticti": [66, 67, 70, 72, 74, 76], "statist": [66, 67, 70, 72, 74, 76], "std": [66, 67, 70, 72, 74, 76], "std_size": [66, 67, 70, 72, 74, 76], "stellar": 59, "step": [0, 1, 3, 6, 8, 10, 21, 24, 26, 29, 33, 35, 49, 55, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "storag": [66, 70, 72, 74, 76], "store": 59, "str": [6, 13, 24, 26, 46, 48, 49, 50, 55, 58, 60, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "strategi": [62, 72], "strenght": 21, "strict": [62, 63, 64, 68, 71, 73, 75, 82, 84, 85], "string": 60, "structur": [2, 62, 63, 64, 66, 67, 72, 79, 82, 85], "style": 60, "subclass": [3, 49, 55], "submit": [60, 65], "submodul": 36, "subplot": 86, "subscrib": 59, "subsect": 86, "subset": [60, 62, 69], "subtract": 6, "successfulli": 59, "suffici": 59, "suggest": 81, "suitabl": 59, "sum": [0, 3, 6, 19, 29, 31, 33, 34, 35, 47, 49, 62, 63, 64, 65, 66, 67, 70, 71, 72, 74, 76, 79, 81, 82, 83, 84, 86], "sum_": [21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 47, 49, 51, 53, 55, 57, 65, 70, 71, 72, 77, 78, 81, 82, 83, 85, 86], "summar": 59, "summari": 60, "super": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "supervis": 86, "support": [21, 65, 79, 82, 85], "suppos": 79, "suppress": [66, 70, 72, 74, 76], "suraj": 59, "sure": 60, "survei": [3, 8, 10, 21, 26, 29, 33, 35, 40, 45, 47, 51, 53, 55, 57, 59, 61, 62, 63, 64, 65, 70, 77, 78, 79, 80, 81, 83, 85, 86], "symbol": [62, 79], "synchron": 60, "syntax": 60, "synthet": 86, "s\u00e1enz": [3, 40, 59, 61], "t": [6, 8, 10, 13, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 61, 62, 63, 64, 65, 66, 67, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 85, 86], "t_": [8, 26, 63, 65, 72], "t_1": [24, 31, 71], "t_r": 10, "tabl": 60, "tag": 59, "take": [59, 62, 63, 64, 79, 82, 84, 86], "tamal": [59, 61], "tanh": [0, 6, 47, 57], "target": [1, 3, 6, 24, 26, 43, 49, 55, 63, 68, 71, 82, 85], "task": [48, 54, 59, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 86], "task_level": [66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "tau": [6, 62], "tb_1": 79, "tcdot": 62, "tda": 51, "tdl": 61, "team": [51, 59], "technic": [62, 79], "tegan": 59, "telyatninkov": 59, "templat": [21, 23, 60], "template_lay": 59, "tensor": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "term": [21, 59, 79], "test": [59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83], "test_": [59, 60], "test_acc": [62, 65, 66, 67, 69, 70, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85], "test_accuraci": [65, 77, 78, 79, 80, 81, 82, 83, 85], "test_add": 60, "test_capital_cas": 60, "test_d": 86, "test_dl": 86, "test_epoch_loss": 71, "test_hsn_lay": 59, "test_interv": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "test_loss": [63, 64, 66, 67, 68, 69, 70, 71, 72, 74, 76, 82, 84, 85], "test_mask": [66, 67, 69, 70, 72, 74, 76], "test_sampl": 65, "test_siz": [62, 63, 64, 68, 71, 73, 75, 82, 84, 85, 86], "testa": [5, 6], "testhsnlay": 59, "testing_dataload": 65, "testing_dataset": 65, "tetahedron": 44, "tetrahedra": 46, "tetrahedron": 81, "tetrahedron_feat": 81, "text": [3, 8, 10, 45, 49, 60, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83], "textbf": [62, 66, 67, 72, 79], "textrm": [62, 79], "th": [62, 63, 64, 65, 68, 71, 72, 79, 84], "tha": 81, "than": [59, 66, 67, 70, 72, 74, 76, 85, 86], "thank": 59, "thei": [60, 62, 63, 64, 66, 67, 68, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85], "them": [19, 49, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 79, 80, 81, 82, 84], "themselv": [1, 3, 81], "theodor": [59, 61], "theori": 69, "therefor": 79, "theta": [3, 6, 8, 21, 24, 26, 29, 33, 38, 40, 43, 45, 47, 49, 51, 53, 57, 62, 63, 65, 67, 70, 71, 72, 77, 78, 80, 81, 82, 83, 85, 86], "theta_": 65, "theta_1": 31, "theta_2": 31, "theta_f": 65, "thi": [1, 2, 3, 6, 8, 10, 19, 21, 26, 29, 33, 35, 40, 43, 45, 47, 48, 49, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "third": [29, 31, 35], "those": [71, 79], "though": 6, "three": [2, 29, 33, 35, 36, 41, 59, 60, 74], "through": [3, 7, 9, 10, 18, 23, 25, 28, 30, 32, 34, 44, 56, 59, 85, 86], "thu": [62, 79, 84], "tild": [51, 83], "tim": 59, "time": [59, 62, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "titl": 61, "tlbnskrt6j": 51, "tmp": [62, 66, 67, 69, 70, 72, 73, 74, 75, 76], "tnn": [8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61], "tnx": [62, 63, 64, 65, 68, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "to_cell_complex": [63, 64], "to_combinatorial_complex": 65, "to_edge_index": 71, "to_hypergraph": [68, 71, 73, 75], "to_networkx": [62, 73, 75], "to_rank": 65, "to_spars": [62, 65, 77, 79, 81], "to_sparse_coo": [66, 67, 70, 72, 74, 76], "to_undirect": [66, 67, 70, 72, 74, 76], "toarrai": 86, "todens": [62, 65, 77], "tolga": [59, 61], "too": 49, "tool": 60, "top": [59, 62, 82], "topolog": [3, 4, 7, 8, 10, 21, 26, 29, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 61, 62, 63, 64, 65, 70, 77, 78, 79, 80, 81, 83, 85, 86], "topologi": [59, 79], "topomodelx": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "toponetx": [59, 62, 63, 64, 65, 68, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "toponextx": 60, "topoprojectx": [77, 81, 82, 85], "torch": [0, 1, 3, 5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "torch_geometr": [62, 66, 67, 69, 70, 72, 73, 74, 75, 76], "torch_scatt": 58, "total": [19, 79], "total_loss": 65, "total_ord": 55, "total_order_0": 49, "total_order_1": 49, "total_order_2": 49, "track": 81, "train": [21, 26, 44, 59], "train_acc": [62, 65, 69, 74, 77, 78, 79, 80, 81, 82, 83, 85, 86], "train_d": 86, "train_dl": 86, "train_ep": [32, 33], "train_loss": [66, 67, 69, 70, 71, 72, 74, 76, 86], "train_mask": [66, 67, 69, 70, 72, 74, 76], "train_mean_loss": [63, 64], "train_siz": 86, "train_test_split": [62, 63, 64, 68, 71, 73, 75, 82, 84, 85], "trainabl": [3, 32, 33, 49, 55, 71], "trainer": 65, "training_accuraci": 65, "training_dataload": 65, "training_dataset": 65, "training_histori": 86, "training_loss": 86, "training_sampl": 65, "traj": 86, "trajectori": [56, 57], "trajectoriesdataset": [41, 56, 86], "transform": [1, 6, 29, 31, 60, 65, 79], "transpos": [7, 44, 45, 80, 83], "travel": 3, "tri": 86, "triangl": [46, 49, 55, 56, 57, 65, 79, 82, 86], "triangul": [56, 86], "trigger": 65, "triplet": 86, "true": [1, 5, 6, 21, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "truth": [65, 86], "try": [60, 62, 63, 79, 86], "tudataset": [62, 73, 75], "tupl": [6, 18, 48, 49, 51, 56, 65, 66, 67, 70, 72, 74, 76, 86], "turn": 86, "tutori": [59, 61, 74], "two": [3, 8, 10, 19, 21, 31, 49, 62, 65, 66, 67, 68, 71, 72, 77, 78, 79, 80, 81, 82, 83, 85, 86], "two_dimensional_cells_mean": [63, 64, 82, 84], "tx": 66, "tx_0": 79, "ty": 66, "type": [6, 13, 60, 65, 66, 67, 70, 72], "typhimurium": 62, "u": [8, 10, 19, 43, 45, 55, 59, 63, 64, 66, 67, 71, 80, 86], "u_": 71, "ucsb": 59, "uncertain": 60, "under": 60, "underflow": 6, "underli": 86, "underset": 79, "understand": 60, "undirect": [66, 67, 70, 72, 74, 76], "unifi": [28, 29, 30, 31, 32, 33, 34, 35], "uniform": [3, 6, 26, 86], "uniformli": [56, 86], "unigcn": [27, 29, 59], "unigcn_lay": 27, "unigcnii": [27, 31, 32], "unigcnii_lay": 27, "unigcniilay": [27, 31], "unigcnlay": [27, 29], "unigin": [27, 32, 33], "unigin_lay": 33, "uniginlay": [27, 33], "unignn": [28, 29, 30, 31, 32, 33, 34, 35], "uniqu": [65, 66, 67, 69, 70, 72, 74, 76], "unique_hyperedg": [66, 67, 70, 72, 74, 76], "unisag": [27, 34, 35, 76], "unisage_lay": 35, "unisagelay": [27, 35], "unit": [56, 59, 60, 86], "unittest": 59, "unmask": 19, "unnorm": 47, "unsign": [68, 71], "unsqueez": [73, 75, 86], "until": 59, "untouch": 45, "up": [6, 7, 10, 29, 31, 33, 35, 39, 43, 46, 54, 55, 60, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 79, 81, 86], "up_laplacian": 62, "up_laplacian_1": [5, 6], "up_laplacian_list": 62, "up_laplacian_matrix": [62, 79, 82, 83, 85], "up_laplacian_t": 62, "up_laplacian_test": 62, "up_laplacian_train": 62, "uparrow": [6, 8, 10, 38, 40, 43, 47, 51, 53, 55, 57, 62, 63, 64, 65, 77, 78, 79, 81, 82, 83, 85, 86], "updat": [0, 1, 2, 3, 6, 10, 24, 26, 29, 31, 32, 33, 35, 41, 43, 48, 49, 55, 57, 62, 65, 66, 67, 79, 86], "update_fn": 10, "update_func": [0, 1, 6, 24, 26, 46, 47, 48, 49, 50, 54, 55, 57, 81, 82, 86], "updating_dropout": 19, "updating_func": 19, "upper": [5, 6, 9, 10, 19, 42, 46, 47, 48, 49, 50, 51, 54, 55, 56, 62, 64, 79, 82, 85, 86], "upper_att": 62, "upstream": 60, "us": [1, 3, 5, 6, 7, 8, 10, 19, 21, 29, 31, 33, 35, 42, 43, 44, 45, 46, 47, 49, 50, 51, 56, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "usag": 60, "use_bia": 21, "use_bn": 29, "use_edge_attr": [62, 73, 75], "use_node_attr": 62, "use_norm": [30, 31, 32, 33, 34, 35], "use_normalized_incid": 21, "user": [3, 63, 65, 77, 81, 82, 85], "userwarn": [63, 65, 66, 67, 68, 70, 71, 72, 74, 76, 82, 85], "usign": 21, "usr": [66, 68, 70, 71, 72, 74, 76], "usual": 81, "util": [4, 6, 30, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "utlil": 74, "v": [60, 65, 66, 67, 71, 72], "v1": 6, "v139": 57, "v198": [47, 53, 84], "v2": 6, "v_": [66, 67, 71], "v_aggr": [34, 35], "val": [69, 73, 75, 86], "val_acc": [66, 67, 69, 70, 72, 76, 86], "val_d": 86, "val_dl": 86, "val_loss": [66, 67, 69, 70, 72, 76, 86], "val_mask": [66, 67, 69, 70, 72, 74, 76], "val_siz": 86, "valid": [6, 60, 65, 73, 74, 75, 86], "valu": [6, 42, 58, 65, 69, 77, 78, 79, 80, 81, 82, 83, 85, 86], "valueerror": [62, 79, 82, 85], "vari": 60, "variou": 58, "vaswani": 67, "ve": 60, "vector": [19, 56, 60, 65, 67, 69, 71, 86], "vectorize_path": [41, 56, 86], "vectorized_trajectori": 86, "veli\u010dkovi\u0107": 6, "venv_modelx": [77, 81, 82, 85], "venv_tmx": 63, "verb": 60, "verbos": 60, "veri": 60, "verifi": 60, "version": [6, 8, 9, 21, 63, 64, 65, 82, 85], "vert": [26, 67, 72, 86], "vertex": [13, 66, 67, 86], "vertic": [56, 62, 65, 86], "vi": [71, 72], "via": [1, 3, 38, 40, 43, 46, 47, 66, 70, 72, 74, 76], "vincent": 59, "visual": 86, "volum": 84, "vote": 59, "voter": 59, "vstack": 86, "w": [21, 29, 31, 70, 71, 79], "w_": 79, "w_y": [26, 72], "w_z": [26, 72], "wa": [8, 10, 21, 40, 45, 47, 57, 65], "wai": [19, 60, 79], "walter": [3, 59, 61], "wang": [23, 24], "want": [60, 74, 86], "warn": [66, 70, 72, 74, 76, 82], "we": [48, 49, 54, 55, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 86], "weight": [3, 6, 24, 43, 45, 49, 55, 60, 65, 67, 71, 79, 81, 82, 86], "weight_0": 49, "weight_1": 49, "weight_2": 49, "weight_decai": 86, "weight_func": [41, 45], "weisfeil": [9, 10, 64], "welcom": [59, 60], "well": [59, 60], "wh_1": 43, "what": [66, 68, 70, 71, 72, 73, 74, 75, 76, 81], "when": [57, 59, 60, 62, 79, 86], "where": [1, 3, 43, 45, 49, 55, 59, 60, 62, 63, 64, 65, 67, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 85, 86], "whether": [1, 3, 5, 6, 7, 8, 12, 13, 21, 29, 30, 31, 32, 33, 34, 35, 44, 45, 48, 49, 54], "which": [4, 6, 19, 26, 43, 48, 59, 60, 65, 66, 67, 69, 71, 74, 77, 78, 79, 80, 81, 82, 83, 85, 86], "which_feat": [82, 85], "while": [6, 59, 60, 79], "white": 59, "whole": [25, 44, 50, 54], "whose": [59, 60], "widetild": 79, "wikipedia": 60, "winner": 59, "wise": [67, 68, 71], "with_linear_transform": 1, "within": [3, 60, 62, 65, 69, 79], "without": [62, 63, 66, 67, 70, 72, 74, 76, 85], "wor": [25, 26], "word": 69, "work": [65, 79, 83], "workflow": 59, "workshop": [7, 8, 20, 21, 40, 51, 59], "world": [62, 86], "would": [60, 77, 78], "written": 59, "www": [77, 78, 79, 80, 81, 82, 83], "x": [0, 1, 3, 6, 8, 10, 13, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 42, 43, 44, 45, 47, 49, 51, 53, 54, 55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "x0_out": 51, "x1_out": 51, "x2_out": 51, "x_0": [5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 35, 39, 40, 49, 50, 51, 52, 53, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "x_0_list": 62, "x_0_test": [62, 63, 64, 68, 71, 82], "x_0_train": [62, 63, 64, 68, 71, 82], "x_0s_test": 84, "x_0s_train": 84, "x_1": [5, 6, 7, 8, 9, 10, 12, 13, 18, 19, 20, 21, 23, 24, 28, 29, 30, 31, 32, 33, 34, 35, 49, 50, 51, 52, 53, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "x_1_list": [62, 73, 75], "x_1_test": [62, 63, 64, 73, 75, 82], "x_1_train": [62, 63, 64, 73, 75, 82], "x_1_val": [73, 75], "x_1e": [37, 77], "x_1s_test": 84, "x_1s_train": 84, "x_2": [7, 8, 9, 10, 49, 50, 51, 52, 53, 63, 64, 65, 68, 71, 77, 78, 79, 80, 81, 82, 83, 84, 85], "x_2_test": [64, 82], "x_2_train": [64, 82], "x_2s_test": 84, "x_2s_train": 84, "x_3": 81, "x_all": [48, 49, 82], "x_e": 38, "x_list": 45, "x_messag": [3, 26], "x_message_on_target": [1, 24, 26], "x_skip": 31, "x_sourc": [1, 3, 6, 24, 43], "x_target": [1, 3, 6, 24], "x_test": 85, "x_train": 85, "xavier": 6, "xavier_norm": [1, 3, 6, 21, 24, 26, 43, 49], "xavier_uniform": [1, 3, 6, 21, 24, 26, 43, 55], "xavier_uniform_": 86, "xin": 62, "xy": [21, 38, 40, 43, 47, 51, 53, 55, 57, 65, 70, 77, 78, 81, 83, 85, 86], "xz": [24, 26, 40, 71, 72, 78], "y": [3, 6, 8, 10, 13, 19, 21, 24, 26, 29, 31, 33, 35, 38, 40, 43, 45, 47, 49, 51, 53, 55, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "y_0": 49, "y_1": 49, "y_2": 49, "y_hat": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "y_hat_edg": [77, 79, 85], "y_hat_edge_test": [77, 79, 85], "y_hat_test": [77, 78, 79, 80, 81, 82, 83, 85], "y_list": [62, 73, 75], "y_pred": [69, 77, 78, 79, 80, 81, 82, 83, 85], "y_pred_test": [77, 78, 79, 80, 81, 82, 83, 85], "y_test": [62, 63, 64, 68, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "y_train": [62, 63, 64, 68, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85], "y_true": [77, 78, 79, 80, 81, 82, 83, 85], "y_val": [73, 75], "yahav": 6, "yang": [28, 29, 30, 31, 32, 33, 34, 35, 47, 53, 55, 59, 81, 82, 84, 85], "yang22a": [47, 53, 84], "yang22c": [47, 53, 84], "year": 61, "yet": [82, 85], "yield": 86, "you": [12, 13, 51, 59, 60, 65, 66, 70, 72, 74, 76, 79], "your": [60, 66, 67, 70, 72], "ysb22": 84, "z": [6, 8, 10, 13, 19, 24, 26, 29, 31, 33, 35, 40, 43, 49, 55, 57, 62, 63, 64, 66, 67, 71, 72, 78, 85, 86], "zaghen": 59, "zamzmi": [3, 7, 8, 40, 45, 61], "zero": [6, 62, 65, 66, 67, 70, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "zero_dimensional_cells_mean": [63, 64, 82, 84], "zero_grad": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "zeros_lik": 69, "zip": [62, 63, 64, 68, 71, 73, 75, 82, 84, 85], "zy": [24, 26, 31, 40, 71, 72, 78]}, "titles": ["Aggregation", "Conv", "Base", "Message Passing", "API Reference", "CAN", "Can_Layer", "CCXN", "CCXN_Layer", "CWN", "Cwn_Layer", "Cell", "AllSet", "AllSet_Layer", "AllSet_Transformer", "AllSet_Transformer_Layer", "DHGCN", "DHGCN_Layer", "HMPNN", "HMPNN_Layer", "HNHN", "HNHN_Layer", "HNHN_Layer_Bis", "Hypergat", "Hypergat_Layer", "Hypersage", "Hypersage_Layer", "Hypergraph", "Unigcn", "Unigcn_Layer", "Unigcnii", "Unigcnii_Layer", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "Neural Networks", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "Simplicial", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "&lt;no title&gt;", "Utils", "ICML 2023 Topological Deep Learning Challenge", "Contributing", "\ud83c\udf10 TopoModelX (TMX) \ud83c\udf69", "Train a Cell Attention Network (CAN)", "Train a Convolutional Cell Complex Network (CCXN)", "Train a CW Network (CWN)", "Train a Combinatorial Complex Attention Neural Network for Mesh Classification.", "Train an All-Set TNN", "Train an All-Set-Transformer TNN", "Train a DHGCN TNN", "Train a Hypergraph Message Passing Neural Network (HMPNN)", "Train a Hypergraph Networks with Hyperedge Neurons (HNHN)", "Train a Hypergraph Neural Network", "Train a Hypersage TNN", "Train a UNIGCN TNN", "Train a hypergraph neural network using UniGCNII layers", "Train a UNIGIN TNN", "Train a Uni-sage TNN", "Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)", "Train a Simplicial High-Skip Network (HSN)", "Train a Simplicial Attention Network (SAN)", "Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)", "Train a Simplicial Complex Convolutional Network (SCCN)", "Train a SCCNN", "Train a Simplicial 2-complex convolutional neural network (SCConv)", "Train a Simplex Convolutional Network (SCN) of Rank 2", "Train a Simplicial Convolutional Neural Network (SCNN)", "Train a Simplicial Complex Net (SCoNe)", "Tutorials"], "titleterms": {"1": [82, 85], "2": [82, 83, 84, 85], "2023": 59, "The": [60, 62, 63, 64, 65, 79], "abstract": [62, 79], "addit": [66, 67, 72], "aggreg": 0, "all": [66, 67], "allset": 12, "allset_lay": 13, "allset_transform": 14, "allset_transformer_lay": 15, "an": [66, 67], "anatomi": 60, "api": 4, "attent": [62, 63, 65, 79], "autoencod": 80, "base": 2, "binari": [77, 78, 80, 81, 82, 83, 85], "can": [5, 62], "can_lay": 6, "ccxn": [7, 63], "ccxn_layer": 8, "cell": [11, 62, 63], "cellular": 87, "challeng": 59, "chang": 60, "clarif": [66, 67, 72], "classif": [65, 82, 85], "cmp": 80, "coadjac": 80, "combinatori": 65, "complex": [63, 65, 80, 81, 82, 83, 85, 86, 87], "content": 86, "contribut": 60, "conv": 1, "convolut": [63, 81, 82, 83, 84, 85], "creat": [62, 63, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86], "cw": 64, "cwn": [9, 64], "cwn_layer": 10, "data": [65, 68, 70, 71, 73, 74, 75, 76, 86], "dataload": 86, "dataset": [77, 78, 80, 81, 82, 83, 84, 85, 86], "deadlin": 59, "deep": 59, "defin": [68, 70, 71, 74, 76, 77, 78, 80, 81, 82, 83, 84, 85], "descript": 59, "dhgcn": [16, 68], "dhgcn_layer": 17, "dist2cycl": 77, "docstr": 60, "document": 60, "domain": [68, 70, 71, 74, 76], "evalu": [59, 86], "exampl": 60, "experiment": 86, "featur": 77, "further": 86, "gener": 86, "get": 61, "guidelin": 59, "high": 78, "hmpnn": [18, 69], "hmpnn_layer": 19, "hnhn": [20, 70], "hnhn_layer": 21, "hnhn_layer_bi": 22, "hodg": 85, "homologi": 77, "how": 59, "hsn": 78, "hyperedg": 70, "hypergat": 23, "hypergat_lay": 24, "hypergraph": [27, 68, 69, 70, 71, 74, 76, 87], "hypersag": [25, 72], "hypersage_lay": 26, "icml": 59, "import": [65, 68, 70, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85], "intro": 60, "karat": 85, "label": [77, 78, 80, 81, 82, 83, 85], "laplacian": 85, "layer": 74, "learn": 59, "lift": [68, 70, 71, 74, 76], "local": 77, "make": 60, "mesh": 65, "messag": [3, 69, 80], "model": [82, 85, 86], "modul": 4, "neighborhood": [68, 70, 71, 74, 76, 77, 78, 80, 81, 82, 84, 85], "neighbourhood": 83, "net": [86, 87], "network": [36, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "neural": [36, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87], "neuron": 70, "node": [82, 85], "outcom": 59, "packag": 4, "particip": 59, "pass": [3, 69, 80], "perform": [82, 85], "pre": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "prepar": 85, "process": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85], "public": 59, "pytorch": 86, "question": 59, "rank": 84, "refer": [4, 61, 84], "requir": 59, "run": 60, "sage": 76, "san": 79, "sca": 80, "sccn": 81, "sccnn": 82, "scconv": 83, "scheme": 80, "scn": 84, "scnn": 85, "scone": 86, "set": [62, 63, 64, 65, 66, 67], "shrec": 82, "signal": [77, 78, 80, 81, 82, 83, 85], "simplex": 84, "simplici": [41, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87], "skip": 78, "split": 85, "start": 61, "strcture": [82, 85], "structur": [68, 70, 71, 74, 76, 77, 78, 80, 81, 83, 84], "submiss": 59, "submit": 59, "suggest": 86, "tabl": 86, "task": [62, 63, 64, 65, 79], "test": [60, 85, 86], "theoret": [66, 67, 72], "tmx": 61, "tnn": [66, 67, 68, 72, 73, 75, 76], "topolog": [59, 87], "topomodelx": 61, "train": [62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86], "trajectori": 86, "transform": 67, "tutori": 87, "uni": 76, "unigcn": [28, 73], "unigcn_lay": 29, "unigcnii": [30, 74], "unigcnii_lay": 31, "unigin": 75, "up": [62, 63, 64, 65], "us": 74, "util": 58, "we": [82, 85], "weight": 85, "write": 60}})