
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS) &#8212; TopoModelX latest documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css?v=2aa19091" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=c6e86fd7"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=5ae071a5"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/simplicial/sca_cmps_train';</script>
    <link rel="canonical" href="https://pyt-team.github.io/topomodelx/notebooks/simplicial/sca_cmps_train.html" />
    <link rel="icon" href="../../_static/favicon-48.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Train a Simplicial Complex Convolutional Network (SCCN)" href="sccn_train.html" />
    <link rel="prev" title="Train a Simplicial Attention Network (SAN)" href="san_train.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="latest" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">TopoModelX latest documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contributing/index.html">
    Contributing
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../tutorials/index.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../challenge/index.html">
    ICML 2023 Topological Deep Learning Challenge
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pyt-team/TopoModelX" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contributing/index.html">
    Contributing
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../tutorials/index.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../challenge/index.html">
    ICML 2023 Topological Deep Learning Challenge
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pyt-team/TopoModelX" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../cell/can_train.html">Train a Cell Attention Network (CAN)</a></li>




<li class="toctree-l1"><a class="reference internal" href="../cell/ccxn_train.html">Train a Convolutional Cell Complex Network (CCXN)</a></li>





<li class="toctree-l1"><a class="reference internal" href="../cell/cwn_train.html">Train a CW Network (CWN)</a></li>




</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../hypergraph/allset_train.html">Train an All-Set TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/allset_transformer_train.html">Train an All-Set-Transformer TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/dhgcn_train.html">Train a DHGCN TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hmpnn_train.html">Train a Hypergraph Message Passing Neural Network (HMPNN)</a></li>


<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hnhn_train.html">Train a Hypergraph Networks with Hyperedge Neurons (HNHN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hypergat_train.html">Train a Hypergraph Neural Network</a></li>


<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hypersage_train.html">Train a Hypersage TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unigcn_train.html">Train a UNIGCN TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unigcnii_train.html">Train a hypergraph neural network using UniGCNII layers</a></li>

<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unigin_train.html">Train a UNIGIN TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unisage_train.html">Train a Uni-sage TNN</a></li>



</ul>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dist2cycle_train.html">Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)</a></li>




<li class="toctree-l1"><a class="reference internal" href="hsn_train.html">Train a Simplicial High-Skip Network (HSN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="san_train.html">Train a Simplicial Attention Network (SAN)</a></li>



<li class="toctree-l1 current active"><a class="current reference internal" href="#">Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)</a></li>



<li class="toctree-l1"><a class="reference internal" href="sccn_train.html">Train a Simplicial Complex Convolutional Network (SCCN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="sccnn_train.html">Train a SCCNN</a></li>





<li class="toctree-l1"><a class="reference internal" href="scconv_train.html">Train a Simplicial 2-complex convolutional neural network (SCConv)</a></li>




<li class="toctree-l1"><a class="reference internal" href="scn2_train.html">Train a Simplex Convolutional Network (SCN) of Rank 2</a></li>


<li class="toctree-l1"><a class="reference internal" href="scnn_train.html">Train a Simplicial Convolutional Neural Network (SCNN)</a></li>






<li class="toctree-l1"><a class="reference internal" href="scone_train.html">Train a Simplicial Complex Net (SCoNe)</a></li>






</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../tutorials/index.html" class="nav-link">Tutorials</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="Train-a-Simplicial-Complex-Autoencoder-(SCA)-with-Coadjacency-Message-Passing-Scheme-(CMPS)">
<h1>Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)<a class="headerlink" href="#Train-a-Simplicial-Complex-Autoencoder-(SCA)-with-Coadjacency-Message-Passing-Scheme-(CMPS)" title="Link to this heading">#</a></h1>
<p>🟥 <span class="math notranslate nohighlight">\(\quad m_{y \rightarrow x}^{(r \rightarrow r'' \rightarrow r)} = M(h_{x}^{t, (r)}, h_{y}^{t, (r)},att(h_{x}^{t, (r)}, h_{y}^{t, (r)}),x,y,{\Theta^t}) \qquad \text{where } r'' &lt; r &lt; r'\)</span></p>
<p>🟥 <span class="math notranslate nohighlight">\(\quad m_{y \rightarrow x}^{(r'' \rightarrow r)} = M(h_{x}^{t, (r)}, h_{y}^{t, (r'')},att(h_{x}^{t, (r)}, h_{y}^{t, (r'')}),x,y,{\Theta^t})\)</span></p>
<p>🟧 <span class="math notranslate nohighlight">\(\quad m_x^{(r \rightarrow r)} = AGG_{y \in \mathcal{L}\_\downarrow(x)} m_{y \rightarrow x}^{(r \rightarrow r)}\)</span></p>
<p>🟧 <span class="math notranslate nohighlight">\(\quad m_x^{(r'' \rightarrow r)} = AGG_{y \in \mathcal{B}(x)} m_{y \rightarrow x}^{(r'' \rightarrow r)}\)</span></p>
<p>🟩 <span class="math notranslate nohighlight">\(\quad m_x^{(r)} = \text{AGG}\_{\mathcal{N}\_k \in \mathcal{N}}(m_x^{(k)})\)</span></p>
<p>🟦 <span class="math notranslate nohighlight">\(\quad h_{x}^{t+1, (r)} = U(h_x^{t, (r)}, m_{x}^{(r)})\)</span></p>
<p>Where the notations are defined in <a class="reference external" href="https://arxiv.org/abs/2304.10031">Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)</a>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">toponetx</span> <span class="k">as</span> <span class="nn">tnx</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">topomodelx.nn.simplicial.sca_cmps</span> <span class="kn">import</span> <span class="n">SCACMPS</span>
<span class="kn">from</span> <span class="nn">topomodelx.utils.sparse</span> <span class="kn">import</span> <span class="n">from_sparse</span>

<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
</pre></div></div>
</div>
<p>If GPUs are available we will make use of them. Otherwise, we will use CPU.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
cpu
</pre></div></div>
</div>
</section>
<section id="Pre-processing">
<h1>Pre-processing<a class="headerlink" href="#Pre-processing" title="Link to this heading">#</a></h1>
<section id="Import-dataset">
<h2>Import dataset<a class="headerlink" href="#Import-dataset" title="Link to this heading">#</a></h2>
<p>The first step is to import the Karate Club (<a class="reference external" href="https://www.jstor.org/stable/3629752">https://www.jstor.org/stable/3629752</a>) dataset. This is a singular graph with 34 nodes that belong to two different social groups. We will use these groups for the task of node-level binary classification.</p>
<p>We must first lift our graph dataset into the simplicial complex domain.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">tnx</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">karate_club</span><span class="p">(</span><span class="n">complex_type</span><span class="o">=</span><span class="s2">&quot;simplicial&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Simplicial Complex with shape (34, 78, 45, 11, 2) and dimension 4
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(34, 78, 45, 11, 2)
</pre></div></div>
</div>
</section>
<section id="Define-neighborhood-structures.">
<h2>Define neighborhood structures.<a class="headerlink" href="#Define-neighborhood-structures." title="Link to this heading">#</a></h2>
<section id="Coadjacency-Message-Passing-Scheme-(CMPS):">
<h3>Coadjacency Message Passing Scheme (CMPS):<a class="headerlink" href="#Coadjacency-Message-Passing-Scheme-(CMPS):" title="Link to this heading">#</a></h3>
<p>This will require features from faces, and edges again, but outputs features on the edges. The first neighborhood matrix will be the level 2 lower Laplacian, <span class="math notranslate nohighlight">\(L_{\downarrow, 2}\)</span>, and the second neighborhood matrix will be the transpose of the incidence matrix of the faces, <span class="math notranslate nohighlight">\(B_{2}^T\)</span>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">laplacian_down_1</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">down_laplacian_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">laplacian_down_2</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">down_laplacian_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">incidence_1_t</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">incidence_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">incidence_2_t</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">incidence_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

<span class="n">laplacian_down_1</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">laplacian_down_1</span><span class="p">)</span>
<span class="n">laplacian_down_2</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">laplacian_down_2</span><span class="p">)</span>
<span class="n">incidence_1_t</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">incidence_1_t</span><span class="p">)</span>
<span class="n">incidence_2_t</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">incidence_2_t</span><span class="p">)</span>

<span class="n">laplacian_down_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">laplacian_down_1</span><span class="p">,</span> <span class="n">laplacian_down_2</span><span class="p">]</span>
<span class="n">incidence_t_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">incidence_1_t</span><span class="p">,</span> <span class="n">incidence_2_t</span><span class="p">]</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Import-signal">
<h2>Import signal<a class="headerlink" href="#Import-signal" title="Link to this heading">#</a></h2>
<p>We retrieve an input signal on the nodes, edges and faces. The signal will have shape <span class="math notranslate nohighlight">\(n_\text{simplicial} \times\)</span> in_channels, where in_channels is the dimension of each simplicial’s feature. Here, we have in_channels = channels_nodes $ = 2$.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_0</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_simplex_attributes</span><span class="p">(</span><span class="s2">&quot;node_feat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_0</span><span class="p">))</span>
<span class="n">channels_nodes</span> <span class="o">=</span> <span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> nodes with features of dimension </span><span class="si">{</span><span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

<span class="n">x_1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_simplex_attributes</span><span class="p">(</span><span class="s2">&quot;edge_feat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">x_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> edges with features of dimension </span><span class="si">{</span><span class="n">x_1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

<span class="n">x_2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_simplex_attributes</span><span class="p">(</span><span class="s2">&quot;face_feat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">x_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> faces with features of dimension </span><span class="si">{</span><span class="n">x_2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
There are 34 nodes with features of dimension 2.
There are 78 edges with features of dimension 2.
There are 45 faces with features of dimension 2.
</pre></div></div>
</div>
<p>We also pre-define the number output channels of the model, in this case the number of node classes.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
</section>
<section id="Define-binary-labels">
<h2>Define binary labels<a class="headerlink" href="#Define-binary-labels" title="Link to this heading">#</a></h2>
<p>We retrieve the labels associated to the nodes of each input simplex. In the KarateClub dataset, two social groups emerge. So we assign binary labels to the nodes indicating of which group they are a part.</p>
<p>We convert one-hot encode the binary labels, and keep the first four nodes for the purpose of testing.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">34</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">y_true</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
<span class="n">y_true</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[:</span><span class="mi">30</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">:]</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Create-the-Neural-Networks">
<h1>Create the Neural Networks<a class="headerlink" href="#Create-the-Neural-Networks" title="Link to this heading">#</a></h1>
<p>Using the SCACMPSLayer class, we create a neural network with a modifiable number of layers each following the CMPS at each level.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[41]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels_all</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">complex_dim</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">SCACMPS</span><span class="p">(</span>
            <span class="n">in_channels_all</span><span class="o">=</span><span class="n">in_channels_all</span><span class="p">,</span>
            <span class="n">complex_dim</span><span class="o">=</span><span class="n">complex_dim</span><span class="p">,</span>
            <span class="n">n_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lin0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_channels_all</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">out_channels</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">laplacian_down_list</span><span class="p">,</span> <span class="n">incidence_t_list</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">laplacian_down_list</span><span class="p">,</span> <span class="n">incidence_t_list</span><span class="p">)</span>
        <span class="n">x_0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lin0</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_0</span><span class="p">,</span> <span class="n">x_1</span><span class="p">,</span> <span class="n">x_2</span><span class="p">]</span>
<span class="n">in_channels_all</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_0</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">x_1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">x_2</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">complex_dim</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">n_layers</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span>
    <span class="n">in_channels_all</span><span class="o">=</span><span class="n">in_channels_all</span><span class="p">,</span>
    <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
    <span class="n">complex_dim</span><span class="o">=</span><span class="n">complex_dim</span><span class="p">,</span>
    <span class="n">n_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Train-the-Neural-Network">
<h1>Train the Neural Network<a class="headerlink" href="#Train-the-Neural-Network" title="Link to this heading">#</a></h1>
<p>The following cell performs the training, looping over the network for a low number of epochs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[43]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_interval</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">laplacian_down_list</span><span class="p">,</span> <span class="n">incidence_t_list</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span>
        <span class="n">y_hat</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)]</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">epoch_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_hat</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)]</span> <span class="o">==</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch_i</span><span class="si">}</span><span class="s2"> loss: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> Train_acc: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">epoch_i</span> <span class="o">%</span> <span class="n">test_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">y_hat_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">laplacian_down_list</span><span class="p">,</span> <span class="n">incidence_t_list</span><span class="p">)</span>
            <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">y_hat_test</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">test_accuracy</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y_pred_test</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span> <span class="p">:],</span> <span class="n">y_test</span><span class="p">)</span>
                <span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="o">.</span><span class="n">float</span><span class="p">()</span>
                <span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                <span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test_acc: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch: 1 loss: 0.7272 Train_acc: 0.4333
Epoch: 2 loss: 0.7215 Train_acc: 0.5667
Epoch: 3 loss: 0.7166 Train_acc: 0.5667
Epoch: 4 loss: 0.7126 Train_acc: 0.5667
Epoch: 5 loss: 0.7097 Train_acc: 0.5667
Epoch: 6 loss: 0.7076 Train_acc: 0.5667
Epoch: 7 loss: 0.7062 Train_acc: 0.5667
Epoch: 8 loss: 0.7052 Train_acc: 0.5667
Epoch: 9 loss: 0.7044 Train_acc: 0.5667
Epoch: 10 loss: 0.7037 Train_acc: 0.5667
Test_acc: 0.0000
Epoch: 11 loss: 0.7028 Train_acc: 0.5667
Epoch: 12 loss: 0.7018 Train_acc: 0.5667
Epoch: 13 loss: 0.7006 Train_acc: 0.5667
Epoch: 14 loss: 0.6991 Train_acc: 0.5667
Epoch: 15 loss: 0.6974 Train_acc: 0.5667
Epoch: 16 loss: 0.6955 Train_acc: 0.5667
Epoch: 17 loss: 0.6934 Train_acc: 0.5667
Epoch: 18 loss: 0.6913 Train_acc: 0.5667
Epoch: 19 loss: 0.6891 Train_acc: 0.5667
Epoch: 20 loss: 0.6870 Train_acc: 0.5667
Test_acc: 0.0000
Epoch: 21 loss: 0.6852 Train_acc: 0.5667
Epoch: 22 loss: 0.6836 Train_acc: 0.5667
Epoch: 23 loss: 0.6822 Train_acc: 0.7000
Epoch: 24 loss: 0.6810 Train_acc: 0.9333
Epoch: 25 loss: 0.6798 Train_acc: 0.9667
Epoch: 26 loss: 0.6784 Train_acc: 1.0000
Epoch: 27 loss: 0.6768 Train_acc: 1.0000
Epoch: 28 loss: 0.6750 Train_acc: 1.0000
Epoch: 29 loss: 0.6731 Train_acc: 0.9667
Epoch: 30 loss: 0.6712 Train_acc: 0.9333
Test_acc: 0.5000
Epoch: 31 loss: 0.6695 Train_acc: 0.9333
Epoch: 32 loss: 0.6679 Train_acc: 0.9333
Epoch: 33 loss: 0.6664 Train_acc: 0.9000
Epoch: 34 loss: 0.6651 Train_acc: 0.9000
Epoch: 35 loss: 0.6637 Train_acc: 0.9000
Epoch: 36 loss: 0.6623 Train_acc: 0.9000
Epoch: 37 loss: 0.6608 Train_acc: 0.9000
Epoch: 38 loss: 0.6593 Train_acc: 0.9333
Epoch: 39 loss: 0.6577 Train_acc: 0.9333
Epoch: 40 loss: 0.6562 Train_acc: 0.9333
Test_acc: 0.7500
Epoch: 41 loss: 0.6547 Train_acc: 0.9667
Epoch: 42 loss: 0.6533 Train_acc: 1.0000
Epoch: 43 loss: 0.6520 Train_acc: 1.0000
Epoch: 44 loss: 0.6507 Train_acc: 1.0000
Epoch: 45 loss: 0.6494 Train_acc: 0.9667
Epoch: 46 loss: 0.6481 Train_acc: 0.9667
Epoch: 47 loss: 0.6468 Train_acc: 0.9667
Epoch: 48 loss: 0.6455 Train_acc: 1.0000
Epoch: 49 loss: 0.6441 Train_acc: 1.0000
Epoch: 50 loss: 0.6429 Train_acc: 1.0000
Test_acc: 1.0000
Epoch: 51 loss: 0.6417 Train_acc: 1.0000
Epoch: 52 loss: 0.6405 Train_acc: 1.0000
Epoch: 53 loss: 0.6393 Train_acc: 1.0000
Epoch: 54 loss: 0.6382 Train_acc: 1.0000
Epoch: 55 loss: 0.6370 Train_acc: 1.0000
Epoch: 56 loss: 0.6358 Train_acc: 1.0000
Epoch: 57 loss: 0.6347 Train_acc: 1.0000
Epoch: 58 loss: 0.6336 Train_acc: 1.0000
Epoch: 59 loss: 0.6325 Train_acc: 0.9667
Epoch: 60 loss: 0.6314 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 61 loss: 0.6304 Train_acc: 0.9667
Epoch: 62 loss: 0.6294 Train_acc: 0.9667
Epoch: 63 loss: 0.6283 Train_acc: 0.9667
Epoch: 64 loss: 0.6273 Train_acc: 0.9667
Epoch: 65 loss: 0.6263 Train_acc: 0.9667
Epoch: 66 loss: 0.6253 Train_acc: 0.9667
Epoch: 67 loss: 0.6244 Train_acc: 0.9667
Epoch: 68 loss: 0.6234 Train_acc: 0.9667
Epoch: 69 loss: 0.6225 Train_acc: 0.9667
Epoch: 70 loss: 0.6216 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 71 loss: 0.6207 Train_acc: 0.9667
Epoch: 72 loss: 0.6198 Train_acc: 0.9667
Epoch: 73 loss: 0.6189 Train_acc: 0.9667
Epoch: 74 loss: 0.6180 Train_acc: 0.9667
Epoch: 75 loss: 0.6172 Train_acc: 0.9667
Epoch: 76 loss: 0.6164 Train_acc: 0.9667
Epoch: 77 loss: 0.6155 Train_acc: 0.9667
Epoch: 78 loss: 0.6147 Train_acc: 0.9667
Epoch: 79 loss: 0.6139 Train_acc: 0.9667
Epoch: 80 loss: 0.6131 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 81 loss: 0.6124 Train_acc: 0.9667
Epoch: 82 loss: 0.6116 Train_acc: 0.9667
Epoch: 83 loss: 0.6108 Train_acc: 0.9667
Epoch: 84 loss: 0.6101 Train_acc: 0.9667
Epoch: 85 loss: 0.6094 Train_acc: 0.9667
Epoch: 86 loss: 0.6086 Train_acc: 0.9667
Epoch: 87 loss: 0.6079 Train_acc: 0.9667
Epoch: 88 loss: 0.6072 Train_acc: 0.9667
Epoch: 89 loss: 0.6065 Train_acc: 0.9667
Epoch: 90 loss: 0.6058 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 91 loss: 0.6052 Train_acc: 0.9667
Epoch: 92 loss: 0.6045 Train_acc: 0.9667
Epoch: 93 loss: 0.6038 Train_acc: 0.9667
Epoch: 94 loss: 0.6032 Train_acc: 0.9667
Epoch: 95 loss: 0.6026 Train_acc: 0.9667
Epoch: 96 loss: 0.6019 Train_acc: 0.9667
Epoch: 97 loss: 0.6013 Train_acc: 0.9667
Epoch: 98 loss: 0.6007 Train_acc: 0.9667
Epoch: 99 loss: 0.6001 Train_acc: 0.9667
Epoch: 100 loss: 0.5995 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 101 loss: 0.5989 Train_acc: 0.9667
Epoch: 102 loss: 0.5983 Train_acc: 0.9667
Epoch: 103 loss: 0.5977 Train_acc: 0.9667
Epoch: 104 loss: 0.5972 Train_acc: 0.9667
Epoch: 105 loss: 0.5966 Train_acc: 0.9667
Epoch: 106 loss: 0.5961 Train_acc: 0.9667
Epoch: 107 loss: 0.5955 Train_acc: 0.9667
Epoch: 108 loss: 0.5950 Train_acc: 0.9667
Epoch: 109 loss: 0.5944 Train_acc: 0.9667
Epoch: 110 loss: 0.5939 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 111 loss: 0.5934 Train_acc: 0.9667
Epoch: 112 loss: 0.5929 Train_acc: 0.9667
Epoch: 113 loss: 0.5924 Train_acc: 0.9667
Epoch: 114 loss: 0.5919 Train_acc: 0.9667
Epoch: 115 loss: 0.5914 Train_acc: 0.9667
Epoch: 116 loss: 0.5909 Train_acc: 0.9667
Epoch: 117 loss: 0.5904 Train_acc: 0.9667
Epoch: 118 loss: 0.5899 Train_acc: 0.9667
Epoch: 119 loss: 0.5894 Train_acc: 0.9667
Epoch: 120 loss: 0.5890 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 121 loss: 0.5885 Train_acc: 0.9667
Epoch: 122 loss: 0.5881 Train_acc: 0.9667
Epoch: 123 loss: 0.5876 Train_acc: 0.9667
Epoch: 124 loss: 0.5872 Train_acc: 0.9667
Epoch: 125 loss: 0.5867 Train_acc: 0.9667
Epoch: 126 loss: 0.5863 Train_acc: 0.9667
Epoch: 127 loss: 0.5859 Train_acc: 0.9667
Epoch: 128 loss: 0.5854 Train_acc: 0.9667
Epoch: 129 loss: 0.5850 Train_acc: 0.9667
Epoch: 130 loss: 0.5846 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 131 loss: 0.5842 Train_acc: 0.9667
Epoch: 132 loss: 0.5838 Train_acc: 0.9667
Epoch: 133 loss: 0.5834 Train_acc: 0.9667
Epoch: 134 loss: 0.5830 Train_acc: 0.9667
Epoch: 135 loss: 0.5826 Train_acc: 0.9667
Epoch: 136 loss: 0.5822 Train_acc: 0.9667
Epoch: 137 loss: 0.5818 Train_acc: 0.9667
Epoch: 138 loss: 0.5814 Train_acc: 0.9667
Epoch: 139 loss: 0.5810 Train_acc: 0.9667
Epoch: 140 loss: 0.5806 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 141 loss: 0.5803 Train_acc: 0.9667
Epoch: 142 loss: 0.5799 Train_acc: 0.9667
Epoch: 143 loss: 0.5795 Train_acc: 0.9667
Epoch: 144 loss: 0.5792 Train_acc: 0.9667
Epoch: 145 loss: 0.5788 Train_acc: 0.9667
Epoch: 146 loss: 0.5785 Train_acc: 0.9667
Epoch: 147 loss: 0.5781 Train_acc: 0.9667
Epoch: 148 loss: 0.5778 Train_acc: 0.9667
Epoch: 149 loss: 0.5774 Train_acc: 0.9667
Epoch: 150 loss: 0.5771 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 151 loss: 0.5768 Train_acc: 0.9667
Epoch: 152 loss: 0.5764 Train_acc: 0.9667
Epoch: 153 loss: 0.5761 Train_acc: 0.9667
Epoch: 154 loss: 0.5758 Train_acc: 0.9667
Epoch: 155 loss: 0.5755 Train_acc: 0.9667
Epoch: 156 loss: 0.5751 Train_acc: 0.9667
Epoch: 157 loss: 0.5748 Train_acc: 0.9667
Epoch: 158 loss: 0.5745 Train_acc: 0.9667
Epoch: 159 loss: 0.5742 Train_acc: 0.9667
Epoch: 160 loss: 0.5739 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 161 loss: 0.5736 Train_acc: 0.9667
Epoch: 162 loss: 0.5733 Train_acc: 0.9667
Epoch: 163 loss: 0.5730 Train_acc: 0.9667
Epoch: 164 loss: 0.5727 Train_acc: 0.9667
Epoch: 165 loss: 0.5724 Train_acc: 0.9667
Epoch: 166 loss: 0.5721 Train_acc: 0.9667
Epoch: 167 loss: 0.5718 Train_acc: 0.9667
Epoch: 168 loss: 0.5715 Train_acc: 0.9667
Epoch: 169 loss: 0.5712 Train_acc: 0.9667
Epoch: 170 loss: 0.5709 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 171 loss: 0.5707 Train_acc: 0.9667
Epoch: 172 loss: 0.5704 Train_acc: 0.9667
Epoch: 173 loss: 0.5701 Train_acc: 0.9667
Epoch: 174 loss: 0.5698 Train_acc: 0.9667
Epoch: 175 loss: 0.5696 Train_acc: 0.9667
Epoch: 176 loss: 0.5693 Train_acc: 0.9667
Epoch: 177 loss: 0.5690 Train_acc: 0.9667
Epoch: 178 loss: 0.5688 Train_acc: 0.9667
Epoch: 179 loss: 0.5685 Train_acc: 0.9667
Epoch: 180 loss: 0.5683 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 181 loss: 0.5680 Train_acc: 0.9667
Epoch: 182 loss: 0.5678 Train_acc: 0.9667
Epoch: 183 loss: 0.5675 Train_acc: 0.9667
Epoch: 184 loss: 0.5673 Train_acc: 0.9667
Epoch: 185 loss: 0.5670 Train_acc: 0.9667
Epoch: 186 loss: 0.5668 Train_acc: 0.9667
Epoch: 187 loss: 0.5665 Train_acc: 0.9667
Epoch: 188 loss: 0.5663 Train_acc: 0.9667
Epoch: 189 loss: 0.5660 Train_acc: 0.9667
Epoch: 190 loss: 0.5658 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 191 loss: 0.5656 Train_acc: 0.9667
Epoch: 192 loss: 0.5653 Train_acc: 0.9667
Epoch: 193 loss: 0.5651 Train_acc: 0.9667
Epoch: 194 loss: 0.5649 Train_acc: 0.9667
Epoch: 195 loss: 0.5647 Train_acc: 0.9667
Epoch: 196 loss: 0.5644 Train_acc: 0.9667
Epoch: 197 loss: 0.5642 Train_acc: 0.9667
Epoch: 198 loss: 0.5640 Train_acc: 0.9667
Epoch: 199 loss: 0.5638 Train_acc: 0.9667
Epoch: 200 loss: 0.5635 Train_acc: 0.9667
Test_acc: 1.0000
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="san_train.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Train a Simplicial Attention Network (SAN)</p>
      </div>
    </a>
    <a class="right-next"
       href="sccn_train.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Train a Simplicial Complex Convolutional Network (SCCN)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Pre-processing">Pre-processing</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Import-dataset">Import dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Define-neighborhood-structures.">Define neighborhood structures.</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Coadjacency-Message-Passing-Scheme-(CMPS):">Coadjacency Message Passing Scheme (CMPS):</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Import-signal">Import signal</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Define-binary-labels">Define binary labels</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Create-the-Neural-Networks">Create the Neural Networks</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Train-the-Neural-Network">Train the Neural Network</a></li>
</ul>

  </nav></div>

  <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/pyt-team/TopoModelX/edit/main/docs/notebooks/simplicial/sca_cmps_train.ipynb">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2022-2023, PyT-Team, Inc..
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>