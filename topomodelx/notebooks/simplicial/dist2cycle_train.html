
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Train a Simplicial Neural Network for Homology Localization (Dist2Cycle) &#8212; TopoModelX latest documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css?v=2aa19091" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=c6e86fd7"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=5ae071a5"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/simplicial/dist2cycle_train';</script>
    <link rel="canonical" href="https://pyt-team.github.io/topomodelx/notebooks/simplicial/dist2cycle_train.html" />
    <link rel="icon" href="../../_static/favicon-48.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Train a Simplicial High-Skip Network (HSN)" href="hsn_train.html" />
    <link rel="prev" title="Train a Uni-sage TNN" href="../hypergraph/unisage_train.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="latest" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">TopoModelX latest documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contributing/index.html">
    Contributing
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../tutorials/index.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../challenge/index.html">
    ICML 2023 Topological Deep Learning Challenge
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pyt-team/TopoModelX" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contributing/index.html">
    Contributing
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../tutorials/index.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../challenge/index.html">
    ICML 2023 Topological Deep Learning Challenge
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pyt-team/TopoModelX" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../cell/can_train.html">Train a Cell Attention Network (CAN)</a></li>




<li class="toctree-l1"><a class="reference internal" href="../cell/ccxn_train.html">Train a Convolutional Cell Complex Network (CCXN)</a></li>





<li class="toctree-l1"><a class="reference internal" href="../cell/cwn_train.html">Train a CW Network (CWN)</a></li>




</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../hypergraph/allset_train.html">Train an All-Set TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/allset_transformer_train.html">Train an All-Set-Transformer TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/dhgcn_train.html">Train a DHGCN TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hmpnn_train.html">Train a Hypergraph Message Passing Neural Network (HMPNN)</a></li>


<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hnhn_train.html">Train a Hypergraph Networks with Hyperedge Neurons (HNHN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hypergat_train.html">Train a Hypergraph Neural Network</a></li>


<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hypersage_train.html">Train a Hypersage TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unigcn_train.html">Train a UNIGCN TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unigcnii_train.html">Train a hypergraph neural network using UniGCNII layers</a></li>

<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unigin_train.html">Train a UNIGIN TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unisage_train.html">Train a Uni-sage TNN</a></li>



</ul>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)</a></li>




<li class="toctree-l1"><a class="reference internal" href="hsn_train.html">Train a Simplicial High-Skip Network (HSN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="san_train.html">Train a Simplicial Attention Network (SAN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="sca_cmps_train.html">Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)</a></li>



<li class="toctree-l1"><a class="reference internal" href="sccn_train.html">Train a Simplicial Complex Convolutional Network (SCCN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="sccnn_train.html">Train a SCCNN</a></li>





<li class="toctree-l1"><a class="reference internal" href="scconv_train.html">Train a Simplicial 2-complex convolutional neural network (SCConv)</a></li>




<li class="toctree-l1"><a class="reference internal" href="scn2_train.html">Train a Simplex Convolutional Network (SCN) of Rank 2</a></li>


<li class="toctree-l1"><a class="reference internal" href="scnn_train.html">Train a Simplicial Convolutional Neural Network (SCNN)</a></li>






<li class="toctree-l1"><a class="reference internal" href="scone_train.html">Train a Simplicial Complex Net (SCoNe)</a></li>






</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../tutorials/index.html" class="nav-link">Tutorials</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="Train-a-Simplicial-Neural-Network-for-Homology-Localization-(Dist2Cycle)">
<h1>Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)<a class="headerlink" href="#Train-a-Simplicial-Neural-Network-for-Homology-Localization-(Dist2Cycle)" title="Link to this heading">#</a></h1>
<p>In this notebook, we will create and train a Simplicial Neural Network for Homology Localization, as proposed in the paper by <a class="reference external" href="https://ojs.aaai.org/index.php/AAAI/article/view/20673/20432">Alexandros D. Keros et. al : Dist2Cycle: A Simplicial Neural Network for Homology Localization(2022)</a>.</p>
<p>We train the model to perform binary node classification using the KarateClub benchmark dataset.</p>
<p>The equations of one layer of this neural network are given by:</p>
<p>🟥 <span class="math notranslate nohighlight">\(\quad m^{(1 \rightarrow 1)}\_{y \rightarrow x} = (A \odot (I + L\downarrow)^+{xy}) \cdot h_{y}^{t,(1)}\cdot \Theta^t\)</span></p>
<p>🟧 <span class="math notranslate nohighlight">\(\quad m_x^{(1 \rightarrow 1)} = \sum_{y \in \mathcal{L}\_\downarrow(x)} m_{y \rightarrow x}^{(1 \rightarrow 1)}\)</span></p>
<p>🟩 <span class="math notranslate nohighlight">\(\quad m_x^{(1)} = m^{(1 \rightarrow 1)}_x\)</span></p>
<p>🟦 <span class="math notranslate nohighlight">\(\quad h_x^{t+1,(1)} = \sigma(m_{x}^{(1)})\)</span></p>
<p>Where the notations are defined in <a class="reference external" href="https://arxiv.org/abs/2304.10031">Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">numpy.linalg</span> <span class="k">as</span> <span class="nn">npla</span>
<span class="kn">import</span> <span class="nn">toponetx</span> <span class="k">as</span> <span class="nn">tnx</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="kn">from</span> <span class="nn">topomodelx.nn.simplicial.dist2cycle</span> <span class="kn">import</span> <span class="n">Dist2Cycle</span>
<span class="kn">from</span> <span class="nn">topomodelx.utils.sparse</span> <span class="kn">import</span> <span class="n">from_sparse</span>

<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>
</div>
</div>
</section>
<section id="Pre-processing">
<h1>Pre-processing<a class="headerlink" href="#Pre-processing" title="Link to this heading">#</a></h1>
<section id="Import-dataset">
<h2>Import dataset<a class="headerlink" href="#Import-dataset" title="Link to this heading">#</a></h2>
<p>The first step is to import the Karate Club (<a class="reference external" href="https://www.jstor.org/stable/3629752">https://www.jstor.org/stable/3629752</a>) dataset. This is a singular graph with 34 nodes that belong to two different social groups. We will use these groups for the task of node-level binary classification.</p>
<p>We must first lift our graph dataset into the simplicial complex domain.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">tnx</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">karate_club</span><span class="p">(</span><span class="n">complex_type</span><span class="o">=</span><span class="s2">&quot;simplicial&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Simplicial Complex with shape (34, 78, 45, 11, 2) and dimension 4
</pre></div></div>
</div>
</section>
<section id="Define-neighborhood-structures.">
<h2>Define neighborhood structures.<a class="headerlink" href="#Define-neighborhood-structures." title="Link to this heading">#</a></h2>
<p>Now we retrieve the neighborhood structures (i.e. their representative matrices) that we will use to send messges on the domain. In this case, we need the boundary matrix (or incidence matrix) <span class="math notranslate nohighlight">\(B_1\)</span> and the adjacency matrix <span class="math notranslate nohighlight">\(A_{\uparrow,0}\)</span> on the nodes. For a santiy check, we show that the shape of the <span class="math notranslate nohighlight">\(B_1 = n_\text{nodes} \times n_\text{edges}\)</span> and <span class="math notranslate nohighlight">\(A_{\uparrow,0} = n_\text{nodes} \times n_\text{nodes}\)</span>. We also convert the neighborhood structures to torch tensors.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">incidence_1</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">incidence_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">adjacency_0</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">incidence_1</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">incidence_1</span><span class="p">)</span>
<span class="n">adjacency_0</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">adjacency_0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The incidence matrix B1 has shape: </span><span class="si">{</span><span class="n">incidence_1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The adjacency matrix A0 has shape: </span><span class="si">{</span><span class="n">adjacency_0</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The incidence matrix B1 has shape: torch.Size([34, 78]).
The adjacency matrix A0 has shape: torch.Size([34, 34]).
</pre></div></div>
</div>
</section>
<section id="Import-signal">
<h2>Import signal<a class="headerlink" href="#Import-signal" title="Link to this heading">#</a></h2>
<p>Since our task will be node classification, we must retrieve an input signal on the nodes. The signal will have shape <span class="math notranslate nohighlight">\(n_\text{nodes} \times\)</span> in_channels, where in_channels is the dimension of each cell’s feature. Here, we have in_channels = channels_nodes $ = 34$. This is because the Karate dataset encodes the identity of each of the 34 nodes as a one hot encoder.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_0</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_simplex_attributes</span><span class="p">(</span><span class="s2">&quot;node_feat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_0</span><span class="p">))</span>
<span class="n">channels_nodes</span> <span class="o">=</span> <span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">channels_nodes</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
2
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> nodes with features of dimension </span><span class="si">{</span><span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
There are 34 nodes with features of dimension 2.
</pre></div></div>
</div>
<p>To load edge features, this is how we would do it (note that we will not use these features for this model, and this serves simply as a demonstration).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_1</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_simplex_attributes</span><span class="p">(</span><span class="s2">&quot;edge_feat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">x_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> edges with features of dimension </span><span class="si">{</span><span class="n">x_1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
There are 78 edges with features of dimension 2.
</pre></div></div>
</div>
<p>Similarly for face features:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_2</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_simplex_attributes</span><span class="p">(</span><span class="s2">&quot;face_feat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="n">x_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> faces with features of dimension </span><span class="si">{</span><span class="n">x_2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
There are 45 faces with features of dimension 2.
</pre></div></div>
</div>
</section>
<section id="Define-binary-labels">
<h2>Define binary labels<a class="headerlink" href="#Define-binary-labels" title="Link to this heading">#</a></h2>
<p>We retrieve the labels associated to the nodes of each input simplex. In the KarateClub dataset, two social groups emerge. So we assign binary labels to the nodes indicating of which group they are a part.</p>
<p>We convert the binary labels into one-hot encoder form, and keep the first four nodes’ true labels for the purpose of testing.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">34</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">y_true</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
<span class="n">y_true</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[:</span><span class="mi">30</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">:]</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
torch.Size([30, 2])
</pre></div></div>
</div>
</section>
</section>
<section id="Create-Features">
<h1>Create Features<a class="headerlink" href="#Create-Features" title="Link to this heading">#</a></h1>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_simplex_attributes</span><span class="p">(</span><span class="s2">&quot;edge_feat&quot;</span><span class="p">)</span>

<span class="n">ld</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">down_laplacian_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span>
<span class="n">L_tilde_pinv</span> <span class="o">=</span> <span class="n">npla</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">ld</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">ld</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>  <span class="c1"># test inverse</span>
<span class="n">channels_nodes</span> <span class="o">=</span> <span class="mi">78</span>  <span class="c1"># L_tilde_pinv.shape[-1]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">channels_nodes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ld</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>  <span class="c1"># edge features</span>
<span class="nb">print</span><span class="p">(</span><span class="n">L_tilde_pinv</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">adjacency</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">()</span>
<span class="n">Linv</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">L_tilde_pinv</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">()</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">adjacency</span> <span class="o">*</span> <span class="n">Linv</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x_1</span><span class="p">)</span>

<span class="n">x_1e</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">()</span>

<span class="n">incidence_0_1</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">incidence_matrix</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
78
(78, 78)
(78, 78)
(78, 2)
(78, 78)
tensor(indices=tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,
                         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,  2,  2,
                         2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  4,  4,  4,  4,
                         5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  7,  7,  8,  8,
                         8,  8, 10, 10, 11, 11, 11, 11, 11, 11, 12, 12, 13, 13,
                        14, 14, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17,
                        17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19,
                        19, 19, 20, 20, 21, 21, 22, 22, 24, 24, 24, 24, 24, 24,
                        24, 24, 25, 25, 25, 25, 25, 25, 26, 26, 26, 26, 28, 28,
                        28, 28, 28, 28, 31, 31, 32, 32, 32, 32, 32, 32, 33, 33,
                        34, 34, 34, 34, 34, 34, 35, 35, 36, 36, 37, 37, 37, 37,
                        38, 38, 39, 39, 40, 40, 41, 41, 41, 41, 42, 42, 42, 42,
                        42, 42, 43, 43, 43, 43, 46, 46, 47, 47, 48, 48, 49, 49,
                        50, 50, 51, 51, 53, 53, 54, 54, 55, 55, 56, 56, 58, 58,
                        59, 59, 59, 59, 60, 60, 60, 60, 61, 61, 61, 61, 61, 61,
                        62, 62, 64, 64, 65, 65, 66, 66, 67, 67, 68, 68, 69, 69,
                        70, 70, 71, 71, 71, 71, 72, 72, 72, 72, 72, 72, 73, 73,
                        73, 73, 74, 74, 74, 74, 75, 75, 76, 76, 76, 76, 77, 77,
                        77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77,
                        77, 77, 77, 77],
                       [ 1,  2,  6, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22,
                         0,  2,  6,  7, 11, 16, 24, 25, 26, 28,  0,  1,  6, 10,
                        11, 17, 24, 32, 33, 34,  5,  8, 35, 36,  5,  8, 37, 38,
                         3,  4, 35, 37,  0,  1,  2, 18, 25, 32,  1, 26,  3,  4,
                        36, 38,  2, 33,  0,  1,  2, 19, 28, 34,  0, 20,  0, 21,
                         0, 22,  0,  1, 17, 18, 19, 24, 25, 28,  0,  2, 16, 18,
                        19, 24, 32, 34,  0,  6, 16, 17, 25, 32,  0, 11, 16, 17,
                        28, 34,  0, 12,  0, 13,  0, 14,  1,  2, 16, 17, 25, 28,
                        32, 34,  1,  6, 16, 18, 24, 32,  1,  7, 31, 42,  1, 11,
                        16, 19, 24, 34, 26, 42,  2,  6, 17, 18, 24, 25,  2, 10,
                         2, 11, 17, 19, 24, 28,  3,  5,  3,  8,  4,  5, 39, 40,
                         4,  8, 37, 40, 37, 39, 42, 43, 73, 74, 26, 31, 41, 43,
                        73, 77, 41, 42, 74, 77, 47, 77, 46, 77, 49, 77, 48, 77,
                        51, 77, 50, 77, 54, 77, 53, 77, 56, 77, 55, 77, 61, 68,
                        60, 61, 71, 72, 59, 61, 71, 77, 58, 59, 60, 68, 72, 77,
                        64, 65, 62, 65, 62, 64, 67, 72, 66, 72, 58, 61, 70, 76,
                        69, 76, 59, 60, 72, 77, 59, 61, 66, 67, 71, 77, 41, 42,
                        74, 77, 41, 43, 73, 77, 76, 77, 69, 70, 75, 77, 42, 43,
                        46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 60, 61, 71, 72,
                        73, 74, 75, 76]]),
       values=tensor([-0.0650, -0.0663, -0.0701, -0.0685, -0.0731, -0.0699,
                      -0.0731,  0.0971,  0.0959,  0.0920,  0.0937,  0.0891,
                       0.0923,  0.0891, -0.0650, -0.0687, -0.0721, -0.0754,
                      -0.0725, -0.0968,  0.0930,  0.0897,  0.0864,  0.0892,
                      -0.0663, -0.0687, -0.0789, -0.0864, -0.0749, -0.1380,
                      -0.1356,  0.1255,  0.1179,  0.1294, -0.1009, -0.1080,
                       0.2140,  0.2069, -0.1106, -0.1009,  0.1724,  0.1821,
                      -0.1009, -0.1106, -0.1821, -0.1724, -0.0701, -0.0721,
                      -0.0789, -0.1851, -0.1831, -0.1763, -0.0754, -0.1628,
                      -0.1080, -0.1009, -0.2069, -0.2140, -0.0864, -0.2927,
                      -0.0685, -0.0725, -0.0749, -0.1560, -0.1519, -0.1495,
                      -0.0731, -0.3018, -0.0699, -0.2309, -0.0731, -0.3018,
                       0.0971, -0.0968, -0.0996, -0.0992, -0.1012,  0.0943,
                       0.0948,  0.0927,  0.0959, -0.1380, -0.0996, -0.1046,
                      -0.1023, -0.1343,  0.1293,  0.1316,  0.0920, -0.1851,
                      -0.0992, -0.1046, -0.1780, -0.1725,  0.0937, -0.1560,
                      -0.1012, -0.1023, -0.1484, -0.1473,  0.0891, -0.3018,
                       0.0923, -0.2309,  0.0891, -0.3018,  0.0930, -0.1356,
                       0.0943, -0.1343, -0.0998, -0.0954,  0.1288,  0.1332,
                       0.0897, -0.1831,  0.0948, -0.1780, -0.0998, -0.1730,
                       0.0864, -0.1628, -0.1006,  0.1487,  0.0892, -0.1519,
                       0.0927, -0.1484, -0.0954, -0.1457, -0.1006, -0.0891,
                       0.1255, -0.1763,  0.1293, -0.1725,  0.1288, -0.1730,
                       0.1179, -0.2927,  0.1294, -0.1495,  0.1316, -0.1473,
                       0.1332, -0.1457,  0.2140, -0.1821,  0.2069, -0.2069,
                       0.1724, -0.1724, -0.1724,  0.1724,  0.1821, -0.2140,
                      -0.1724, -0.2678,  0.1724, -0.2678, -0.1429, -0.1426,
                       0.1734,  0.1738,  0.1487, -0.0891, -0.1429, -0.1654,
                      -0.0948,  0.0724, -0.1426, -0.1654, -0.0804, -0.0576,
                      -0.3090,  0.0693, -0.3090, -0.0607, -0.3090,  0.0693,
                      -0.3090, -0.0607, -0.3090,  0.0693, -0.3090, -0.0607,
                      -0.3090,  0.0693, -0.3090, -0.0607, -0.3090,  0.0693,
                      -0.3090, -0.0607, -0.1474,  0.1836, -0.1511, -0.1518,
                       0.1812,  0.1804, -0.1511, -0.1724, -0.0960,  0.0746,
                      -0.1474, -0.1518, -0.1724, -0.0803, -0.0759, -0.0553,
                      -0.2077,  0.2056, -0.2077, -0.1475,  0.2056, -0.1475,
                      -0.2813,  0.1545, -0.2813, -0.1019,  0.1836, -0.0803,
                      -0.2206,  0.1293, -0.2206, -0.0819,  0.1812, -0.0960,
                      -0.2017,  0.0754,  0.1804, -0.0759,  0.1545, -0.1019,
                      -0.2017, -0.0546,  0.1734, -0.0948, -0.1962,  0.0720,
                       0.1738, -0.0804, -0.1962, -0.0580, -0.1575,  0.0762,
                       0.1293, -0.0819, -0.1575, -0.0537,  0.0724, -0.0576,
                       0.0693, -0.0607,  0.0693, -0.0607,  0.0693, -0.0607,
                       0.0693, -0.0607,  0.0693, -0.0607,  0.0746, -0.0553,
                       0.0754, -0.0546,  0.0720, -0.0580,  0.0762, -0.0537]),
       size=(78, 78), nnz=270, layout=torch.sparse_coo)
[[ 2.40770523e-02  6.11494370e-02]
 [-4.97384816e-02  9.02294368e-02]
 [-1.64641943e-02  4.86156419e-02]
 [-4.83606968e-08 -1.49915427e-01]
 [-5.00650188e-08 -1.83463633e-01]
 [-5.75156136e-08 -1.83463678e-01]
 [-1.05313901e-02  4.90156896e-02]
 [-1.20998740e-01  8.07190537e-02]
 [-4.09101162e-08 -1.49915427e-01]
 [ 1.62092721e-08 -4.98118326e-02]
 [-8.23208503e-03  7.53657054e-03]
 [-5.43603450e-02  7.50192329e-02]
 [ 1.20385336e-02  1.53667741e-02]
 [ 1.72664091e-01  8.49207789e-02]
 [ 1.20385485e-02  1.53667741e-02]
 [ 3.95071507e-02  2.25182593e-01]
 [-7.38155320e-02  2.95849722e-02]
 [-4.05412391e-02 -1.36992298e-02]
 [-3.46084312e-02 -1.20638106e-02]
 [-7.84373805e-02  1.39397243e-02]
 [-1.20385038e-02 -3.50549929e-02]
 [ 1.48587048e-01  3.44989747e-02]
 [-1.20385019e-02 -3.50550078e-02]
 [ 1.26969576e-01  7.39617124e-02]
 [ 3.32742967e-02 -4.32841964e-02]
 [ 3.92070971e-02 -4.09105867e-02]
 [-7.12601468e-02  1.28915999e-02]
 [ 1.50366500e-01  3.93094122e-02]
 [-4.62186569e-03 -1.49070593e-02]
 [-3.30901868e-03  5.55232428e-02]
 [-1.51894227e-01  2.22967193e-02]
 [-1.15316376e-01  6.22131526e-02]
 [ 5.93280513e-03  1.29361625e-03]
 [ 8.23212508e-03 -3.29043306e-02]
 [-3.78961600e-02  2.72971559e-02]
 [-2.76038641e-08 -3.18312794e-02]
 [ 1.32374076e-08  5.55317712e-08]
 [ 9.97262095e-09  3.42880568e-08]
 [-1.96564454e-09  3.18312198e-02]
 [-2.07279651e-08 -8.27834606e-02]
 [-4.21484074e-08 -8.27835426e-02]
 [-7.98071399e-02  5.66642778e-03]
 [-4.40563001e-02  4.23841551e-02]
 [-6.83955252e-02  2.74787247e-02]
 [ 1.50366411e-01  2.16282904e-03]
 [-1.75315768e-01  8.67087543e-02]
 [ 1.21695530e-02 -2.16733683e-02]
 [-1.21695669e-02 -2.97473371e-02]
 [ 1.21695530e-02 -2.16734018e-02]
 [-1.21695707e-02 -2.97473222e-02]
 [ 1.21695530e-02 -2.16733590e-02]
 [-1.21695707e-02 -2.97473371e-02]
 [ 3.21251035e-01  1.11335017e-01]
 [ 1.21695511e-02 -2.16733608e-02]
 [-1.21695651e-02 -2.97473371e-02]
 [ 1.21695530e-02 -2.16733944e-02]
 [-1.21695725e-02 -2.97473520e-02]
 [ 5.66296689e-02 -1.70098506e-02]
 [ 8.54005478e-03 -1.45874349e-02]
 [-1.84309315e-02  1.33008221e-02]
 [-1.11998310e-02 -1.11719538e-02]
 [-3.55389528e-02 -2.02689916e-02]
 [-2.43989541e-03  7.58042466e-03]
 [-4.93099503e-02 -2.70438008e-03]
 [ 5.17499000e-02 -4.70586307e-02]
 [ 5.41898049e-02 -5.46390563e-02]
 [ 8.55402555e-03 -1.45243965e-02]
 [-8.55398457e-03 -4.46499884e-02]
 [-4.40789945e-02 -3.23143601e-03]
 [-8.49792436e-02 -2.31365804e-02]
 [-6.69150501e-02  1.28155053e-02]
 [ 7.23110419e-03 -2.44727693e-02]
 [-1.71080101e-02 -3.37488726e-02]
 [ 3.57507989e-02  3.30902189e-02]
 [ 1.14116156e-02  2.18122974e-02]
 [ 4.24033478e-02  4.10169996e-02]
 [ 1.80642232e-02  3.59393880e-02]
 [-2.43391562e-02 -9.89420712e-03]]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/Users/gbg141/Documents/TopoProjectX/TopoModelX/venv_modelx/lib/python3.11/site-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.
  self._set_arrayXarray(i, j, x)
</pre></div></div>
</div>
</section>
<section id="Create-the-Neural-Network">
<h1>Create the Neural Network<a class="headerlink" href="#Create-the-Neural-Network" title="Link to this heading">#</a></h1>
<p>Using the SAN class, we create our neural network with stacked layers. Given the considered dataset and task (Karate Club, node classification), a linear layer at the end produces an output with shape <span class="math notranslate nohighlight">\(n_\text{nodes} \times 2\)</span>, so we can compare with our binary labels.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">Dist2Cycle</span><span class="p">(</span>
            <span class="n">channels</span><span class="o">=</span><span class="n">channels</span><span class="p">,</span>
            <span class="n">n_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">incidence_1</span><span class="p">,</span> <span class="n">adjacency_0</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">incidence_1</span><span class="p">,</span> <span class="n">adjacency_0</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">out_channels</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_layers</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span>
    <span class="n">channels</span><span class="o">=</span><span class="n">channels_nodes</span><span class="p">,</span>
    <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
    <span class="n">n_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Train-the-Neural-Network">
<h1>Train the Neural Network<a class="headerlink" href="#Train-the-Neural-Network" title="Link to this heading">#</a></h1>
<p>We specify the model with our pre-made neighborhood structures and specify an optimizer.</p>
<p>The following cell performs the training, looping over the network for a low number of epochs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_interval</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">y_hat_edge</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_1e</span><span class="p">,</span> <span class="n">Linv</span><span class="p">,</span> <span class="n">adjacency</span><span class="p">)</span>
    <span class="c1"># We project the edge-level output of the model to the node-level</span>
    <span class="c1"># and apply softmax fn to get the final node-level classification output</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">incidence_0_1</span><span class="p">,</span> <span class="n">y_hat_edge</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span>
        <span class="n">y_hat</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)]</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">epoch_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_hat</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)]</span> <span class="o">==</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch_i</span><span class="si">}</span><span class="s2"> loss: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> Train_acc: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">epoch_i</span> <span class="o">%</span> <span class="n">test_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">y_hat_edge_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_1e</span><span class="p">,</span> <span class="n">Linv</span><span class="p">,</span> <span class="n">adjacency</span><span class="p">)</span>
            <span class="c1"># Projection to node-level</span>
            <span class="n">y_hat_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">incidence_0_1</span><span class="p">,</span> <span class="n">y_hat_edge_test</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span>
            <span class="p">)</span>
            <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">y_hat_test</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="c1"># _pred_test = torch.softmax(y_hat_test,dim=1).ge(0.5).float()</span>
            <span class="n">test_accuracy</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y_pred_test</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span> <span class="p">:],</span> <span class="n">y_test</span><span class="p">)</span>
                <span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="o">.</span><span class="n">float</span><span class="p">()</span>
                <span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                <span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test_acc: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch: 1 loss: 0.7234 Train_acc: 0.6333
Epoch: 2 loss: 0.6930 Train_acc: 0.6667
Epoch: 3 loss: 0.6769 Train_acc: 0.7000
Epoch: 4 loss: 0.6718 Train_acc: 0.7000
Epoch: 5 loss: 0.6701 Train_acc: 0.7000
Epoch: 6 loss: 0.6694 Train_acc: 0.7000
Epoch: 7 loss: 0.6691 Train_acc: 0.7000
Epoch: 8 loss: 0.6689 Train_acc: 0.7000
Epoch: 9 loss: 0.6689 Train_acc: 0.7000
Epoch: 10 loss: 0.6688 Train_acc: 0.7000
Test_acc: 0.2500
Epoch: 11 loss: 0.6688 Train_acc: 0.7000
Epoch: 12 loss: 0.6688 Train_acc: 0.7000
Epoch: 13 loss: 0.6688 Train_acc: 0.7000
Epoch: 14 loss: 0.6688 Train_acc: 0.7000
Epoch: 15 loss: 0.6688 Train_acc: 0.7000
Epoch: 16 loss: 0.6688 Train_acc: 0.7000
Epoch: 17 loss: 0.6688 Train_acc: 0.7000
Epoch: 18 loss: 0.6688 Train_acc: 0.7000
Epoch: 19 loss: 0.6688 Train_acc: 0.7000
Epoch: 20 loss: 0.6688 Train_acc: 0.7000
Test_acc: 0.2500
Epoch: 21 loss: 0.6688 Train_acc: 0.7000
Epoch: 22 loss: 0.6688 Train_acc: 0.7000
Epoch: 23 loss: 0.6688 Train_acc: 0.7000
Epoch: 24 loss: 0.6688 Train_acc: 0.7000
Epoch: 25 loss: 0.6688 Train_acc: 0.7000
Epoch: 26 loss: 0.6688 Train_acc: 0.7000
Epoch: 27 loss: 0.6688 Train_acc: 0.7000
Epoch: 28 loss: 0.6688 Train_acc: 0.7000
Epoch: 29 loss: 0.6688 Train_acc: 0.7000
Epoch: 30 loss: 0.6688 Train_acc: 0.7000
Test_acc: 0.2500
Epoch: 31 loss: 0.6688 Train_acc: 0.7000
Epoch: 32 loss: 0.6688 Train_acc: 0.7000
Epoch: 33 loss: 0.6688 Train_acc: 0.7000
Epoch: 34 loss: 0.6688 Train_acc: 0.7000
Epoch: 35 loss: 0.6688 Train_acc: 0.7000
Epoch: 36 loss: 0.6688 Train_acc: 0.7000
Epoch: 37 loss: 0.6688 Train_acc: 0.7000
Epoch: 38 loss: 0.6688 Train_acc: 0.7000
Epoch: 39 loss: 0.6688 Train_acc: 0.7000
Epoch: 40 loss: 0.6688 Train_acc: 0.7000
Test_acc: 0.2500
Epoch: 41 loss: 0.6688 Train_acc: 0.7000
Epoch: 42 loss: 0.6688 Train_acc: 0.7000
Epoch: 43 loss: 0.6688 Train_acc: 0.7000
Epoch: 44 loss: 0.6688 Train_acc: 0.7000
Epoch: 45 loss: 0.6688 Train_acc: 0.7000
Epoch: 46 loss: 0.6688 Train_acc: 0.7000
Epoch: 47 loss: 0.6688 Train_acc: 0.7000
Epoch: 48 loss: 0.6688 Train_acc: 0.7000
Epoch: 49 loss: 0.6688 Train_acc: 0.7000
Epoch: 50 loss: 0.6688 Train_acc: 0.7000
Test_acc: 0.2500
Epoch: 51 loss: 0.6688 Train_acc: 0.7000
Epoch: 52 loss: 0.6688 Train_acc: 0.7000
Epoch: 53 loss: 0.6688 Train_acc: 0.7000
Epoch: 54 loss: 0.6688 Train_acc: 0.7000
Epoch: 55 loss: 0.6688 Train_acc: 0.7000
Epoch: 56 loss: 0.6688 Train_acc: 0.7000
Epoch: 57 loss: 0.6688 Train_acc: 0.7000
Epoch: 58 loss: 0.6688 Train_acc: 0.7000
Epoch: 59 loss: 0.6688 Train_acc: 0.7000
Epoch: 60 loss: 0.6688 Train_acc: 0.7000
Test_acc: 0.2500
Epoch: 61 loss: 0.6688 Train_acc: 0.7000
Epoch: 62 loss: 0.6688 Train_acc: 0.7000
Epoch: 63 loss: 0.6688 Train_acc: 0.7000
Epoch: 64 loss: 0.6688 Train_acc: 0.7000
Epoch: 65 loss: 0.6688 Train_acc: 0.7000
Epoch: 66 loss: 0.6688 Train_acc: 0.7000
Epoch: 67 loss: 0.6688 Train_acc: 0.7000
Epoch: 68 loss: 0.6688 Train_acc: 0.7000
Epoch: 69 loss: 0.6688 Train_acc: 0.7000
Epoch: 70 loss: 0.6688 Train_acc: 0.7000
Test_acc: 0.2500
Epoch: 71 loss: 0.6688 Train_acc: 0.7000
Epoch: 72 loss: 0.6688 Train_acc: 0.7000
Epoch: 73 loss: 0.6688 Train_acc: 0.7000
Epoch: 74 loss: 0.6688 Train_acc: 0.7000
Epoch: 75 loss: 0.6688 Train_acc: 0.7000
Epoch: 76 loss: 0.6688 Train_acc: 0.7000
Epoch: 77 loss: 0.6688 Train_acc: 0.7000
Epoch: 78 loss: 0.6688 Train_acc: 0.7000
Epoch: 79 loss: 0.6688 Train_acc: 0.7000
Epoch: 80 loss: 0.6688 Train_acc: 0.7000
Test_acc: 0.2500
Epoch: 81 loss: 0.6688 Train_acc: 0.7000
Epoch: 82 loss: 0.6688 Train_acc: 0.7000
Epoch: 83 loss: 0.6688 Train_acc: 0.7000
Epoch: 84 loss: 0.6688 Train_acc: 0.7000
Epoch: 85 loss: 0.6688 Train_acc: 0.7000
Epoch: 86 loss: 0.6688 Train_acc: 0.7000
Epoch: 87 loss: 0.6688 Train_acc: 0.7000
Epoch: 88 loss: 0.6688 Train_acc: 0.7000
Epoch: 89 loss: 0.6688 Train_acc: 0.7000
Epoch: 90 loss: 0.6688 Train_acc: 0.7000
Test_acc: 0.2500
Epoch: 91 loss: 0.6688 Train_acc: 0.7000
Epoch: 92 loss: 0.6688 Train_acc: 0.7000
Epoch: 93 loss: 0.6688 Train_acc: 0.7000
Epoch: 94 loss: 0.6688 Train_acc: 0.7000
Epoch: 95 loss: 0.6688 Train_acc: 0.7000
Epoch: 96 loss: 0.6688 Train_acc: 0.7000
Epoch: 97 loss: 0.6688 Train_acc: 0.7000
Epoch: 98 loss: 0.6688 Train_acc: 0.7000
Epoch: 99 loss: 0.6688 Train_acc: 0.7000
Epoch: 100 loss: 0.6688 Train_acc: 0.7000
Test_acc: 0.2500
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../hypergraph/unisage_train.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Train a Uni-sage TNN</p>
      </div>
    </a>
    <a class="right-next"
       href="hsn_train.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Train a Simplicial High-Skip Network (HSN)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Pre-processing">Pre-processing</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Import-dataset">Import dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Define-neighborhood-structures.">Define neighborhood structures.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Import-signal">Import signal</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Define-binary-labels">Define binary labels</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Create-Features">Create Features</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Create-the-Neural-Network">Create the Neural Network</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Train-the-Neural-Network">Train the Neural Network</a></li>
</ul>

  </nav></div>

  <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/pyt-team/TopoModelX/edit/main/docs/notebooks/simplicial/dist2cycle_train.ipynb">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2022-2023, PyT-Team, Inc..
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>