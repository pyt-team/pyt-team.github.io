
<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Train a Simplicial Complex Convolutional Network (SCCN) &#8212; TopoModelX latest documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script src="../../_static/documentation_options.js?v=f4332903"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/simplicial/sccn_train';</script>
    <link rel="canonical" href="pyt-team.github.io/notebooks/simplicial/sccn_train.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Train a SCCNN" href="sccnn_train.html" />
    <link rel="prev" title="Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)" href="sca_cmps_train.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  <div class="navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    <p class="title logo__title">TopoModelX latest documentation</p>
  
</a></div>
    
  </div>
  
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../api/index.html">
                        API Reference
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../contributing/index.html">
                        Contributing
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../../tutorials/index.html">
                        Tutorials
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../challenge/index.html">
                        ICML 2023 Topological Deep Learning Challenge
                      </a>
                    </li>
                
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../api/index.html">
                        API Reference
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../contributing/index.html">
                        Contributing
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../../tutorials/index.html">
                        Tutorials
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../challenge/index.html">
                        ICML 2023 Topological Deep Learning Challenge
                      </a>
                    </li>
                
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item"><nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../cell/can_train.html">Train a Cell Attention Network (CAN)</a></li>




<li class="toctree-l1"><a class="reference internal" href="../cell/can_train_bis.html">Train a Cellular Attention Network (CAN)</a></li>





<li class="toctree-l1"><a class="reference internal" href="../cell/ccxn_train.html">Train a Convolutional Cell Complex Network (CCXN)</a></li>





<li class="toctree-l1"><a class="reference internal" href="../cell/cwn_train.html">Train a CW Network (CWN)</a></li>




<li class="toctree-l1"><a class="reference internal" href="../hypergraph/allset_train.html">Train a Hypergraph Neural Network</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/allset_transformer_train.html">Train a Hypergraph Neural Network</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/dhgcn_train.html">Train a Hypergraph Neural Network</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hmpnn_train.html">Train a Hypergraph Message Passing Neural Network (HMPNN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hnhn_train.html">Train a Hypergraph Networks with Hyperedge Neurons (HNHN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hnhn_train_bis.html">Train a Hypergraph Network with Hyperedge Neurons (HNHN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hypergat_train.html">Train a Hypergraph Neural Network</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hypersage_train.html">Train a Hypergraph Neural Network</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/template_train.html">Train a Hypergraph Neural Network</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unigcn_train.html">Pre-processing</a></li>


<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unigcnii_train.html">Train a hypergraph neural network using UniGCNII layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unigin_train.html">Pre-processing</a></li>


<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unisage_train.html">Pre-processing</a></li>


<li class="toctree-l1"><a class="reference internal" href="dist2cycle_train.html">Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)</a></li>




<li class="toctree-l1"><a class="reference internal" href="hsn_train.html">Train a Simplicial High-Skip Network (HSN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="san_train.html">Train a Simplicial Attention Network (SAN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="sca_cmps_train.html">Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)</a></li>




<li class="toctree-l1 current active"><a class="current reference internal" href="#">Train a Simplicial Complex Convolutional Network (SCCN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="sccnn_train.html">Train a SCCNN</a></li>







<li class="toctree-l1"><a class="reference internal" href="scconv_train.html">Train a Simplicial 2-complex convolutional neural network (SCConv)</a></li>




<li class="toctree-l1"><a class="reference internal" href="scn2_train.html">Train a Simplex Convolutional Network (SCN) of Rank 2</a></li>



<li class="toctree-l1"><a class="reference internal" href="scnn_train.html">Train a Simplicial Convolutional Neural Network (SCNN)</a></li>







<li class="toctree-l1"><a class="reference internal" href="scone_train.html">Train a Simplicial Complex Net (SCoNe)</a></li>






<li class="toctree-l1"><a class="reference internal" href="scone_train_bis.html">Train a Simplicial Complex Network (SCoNe)</a></li>






</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumbs">
  <ul class="bd-breadcrumbs" role="navigation" aria-label="Breadcrumb">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../tutorials/index.html" class="nav-link">Tutorials</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Train a Simplicial Complex Convolutional Network (SCCN)</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="Train-a-Simplicial-Complex-Convolutional-Network-(SCCN)">
<h1>Train a Simplicial Complex Convolutional Network (SCCN)<a class="headerlink" href="#Train-a-Simplicial-Complex-Convolutional-Network-(SCCN)" title="Link to this heading">#</a></h1>
<p>We create a SCCN model a la <a class="reference external" href="https://proceedings.mlr.press/v198/yang22a/yang22a.pdf">Yang et al : Efficient Representation Learning for Higher-Order Data with Simplicial Complexes (LoG 2022)</a></p>
<p>We train the model to perform binary node classification using the KarateClub benchmark dataset.</p>
<p>The model operates on cells of all ranks up to some max rank <span class="math notranslate nohighlight">\(r_\mathrm{max}\)</span>. The equations of one layer of this neural network are given by:</p>
<p>ðŸŸ¥ <span class="math notranslate nohighlight">\(\quad m_{{y \rightarrow x}}^{(r \rightarrow r)} = (H_{r})_{xy} \cdot h^{t,(r)}_y \cdot \Theta^{t,(r\to r)}\)</span>, (for <span class="math notranslate nohighlight">\(0\leq r \leq r_\mathrm{max}\)</span>)</p>
<p>ðŸŸ¥ <span class="math notranslate nohighlight">\(\quad m_{{y \rightarrow x}}^{(r-1 \rightarrow r)} = (B_{r}^T)_{xy} \cdot h^{t,(r-1)}_y \cdot \Theta^{t,(r-1\to r)}\)</span>, (for <span class="math notranslate nohighlight">\(1\leq r \leq r_\mathrm{max}\)</span>)</p>
<p>ðŸŸ¥ <span class="math notranslate nohighlight">\(\quad m_{{y \rightarrow x}}^{(r+1 \rightarrow r)} = (B_{r+1})_{xy} \cdot h^{t,(r+1)}_y \cdot \Theta^{t,(r+1\to r)}\)</span>, (for <span class="math notranslate nohighlight">\(0\leq r \leq r_\mathrm{max}-1\)</span>)</p>
<p>ðŸŸ§ <span class="math notranslate nohighlight">\(\quad m_{x}^{(r \rightarrow r)} = \sum_{y \in \mathcal{L}_\downarrow(x)\bigcup \mathcal{L}_\uparrow(x)} m_{y \rightarrow x}^{(r \rightarrow r)}\)</span></p>
<p>ðŸŸ§ <span class="math notranslate nohighlight">\(\quad m_{x}^{(r-1 \rightarrow r)} = \sum_{y \in \mathcal{B}(x)} m_{y \rightarrow x}^{(r-1 \rightarrow r)}\)</span></p>
<p>ðŸŸ§ <span class="math notranslate nohighlight">\(\quad m_{x}^{(r+1 \rightarrow r)} = \sum_{y \in \mathcal{C}(x)} m_{y \rightarrow x}^{(r+1 \rightarrow r)}\)</span></p>
<p>ðŸŸ© <span class="math notranslate nohighlight">\(\quad m_x^{(r)} = m_x^{(r \rightarrow r)} + m_x^{(r-1 \rightarrow r)} + m_x^{(r+1 \rightarrow r)}\)</span></p>
<p>ðŸŸ¦ <span class="math notranslate nohighlight">\(\quad h_x^{t+1,(r)} = \sigma(m_x^{(r)})\)</span></p>
<p>Where the notations are defined in <a class="reference external" href="https://arxiv.org/abs/2304.10031">Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)</a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">toponetx.datasets.graph</span> <span class="k">as</span> <span class="nn">graph</span>

<span class="kn">from</span> <span class="nn">topomodelx.nn.simplicial.sccn_layer</span> <span class="kn">import</span> <span class="n">SCCNLayer</span>
</pre></div>
</div>
</div>
</section>
<section id="Pre-processing">
<h1>Pre-processing<a class="headerlink" href="#Pre-processing" title="Link to this heading">#</a></h1>
<section id="Import-dataset">
<h2>Import dataset<a class="headerlink" href="#Import-dataset" title="Link to this heading">#</a></h2>
<p>The first step is to import the Karate Club (<a class="reference external" href="https://www.jstor.org/stable/3629752">https://www.jstor.org/stable/3629752</a>) dataset. This is a singular graph with 34 nodes that belong to two different social groups. We will use these groups for the task of node-level binary classification.</p>
<p>We must first lift our graph dataset into the simplicial complex domain.</p>
<p>Since our task will be node classification, we must retrieve an input signal on the nodes. The signal will have shape <span class="math notranslate nohighlight">\(n_\text{nodes} \times\)</span> in_channels, where in_channels is the dimension of each cellâ€™s feature. The feature dimension is <code class="docutils literal notranslate"><span class="pre">feat_dim</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">karate_club</span><span class="p">(</span><span class="n">complex_type</span><span class="o">=</span><span class="s2">&quot;simplicial&quot;</span><span class="p">,</span> <span class="n">feat_dim</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Simplicial Complex with shape (34, 78, 45, 11, 2) and dimension 4
</pre></div></div>
</div>
</section>
<section id="Define-neighborhood-structures.">
<h2>Define neighborhood structures.<a class="headerlink" href="#Define-neighborhood-structures." title="Link to this heading">#</a></h2>
<p>Our implementation allows for features on cells up to an arbitrary maximum rank. In this dataset, we can use at most <code class="docutils literal notranslate"><span class="pre">max_rank</span> <span class="pre">=</span> <span class="pre">3</span></code>, which is what we choose.</p>
<p>We define incidence and adjacency matrices up to the max rank and put them in dictionaries indexed by the rank, as is expected by the <code class="docutils literal notranslate"><span class="pre">SCCNLayer</span></code>. The form of tha adjacency and incidence matrices could be chosen arbitrarily, here we follow the original formulation by Yang et al. quite closely and select the adjacencies as r-Hodge Laplacians <span class="math notranslate nohighlight">\(H_r\)</span>, summed with <span class="math notranslate nohighlight">\(2I\)</span> (or just <span class="math notranslate nohighlight">\(I\)</span> for <span class="math notranslate nohighlight">\(r\in\{0, r_\mathrm{max}\}\)</span>) to allow cells to pass messages to themselves. The incidence
matrices are the usual boundary matrices <span class="math notranslate nohighlight">\(B_r\)</span>. One could additionally weight/normalize these matrices as suggested by Yang et al., but we refrain from doing this for simplicity.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_rank</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># There are features up to tetrahedron order in the dataset</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sparse_to_torch</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">todense</span><span class="p">())</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">()</span>


<span class="n">incidences</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sa">f</span><span class="s2">&quot;rank_</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">sparse_to_torch</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">incidence_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="n">r</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">}</span>

<span class="n">adjacencies</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">adjacencies</span><span class="p">[</span><span class="s2">&quot;rank_0&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">sparse_to_torch</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">()</span>
<span class="p">)</span>
<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_rank</span><span class="p">):</span>
    <span class="n">adjacencies</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;rank_</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">sparse_to_torch</span><span class="p">(</span>
            <span class="n">dataset</span><span class="o">.</span><span class="n">adjacency_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="n">r</span><span class="p">)</span> <span class="o">+</span> <span class="n">dataset</span><span class="o">.</span><span class="n">coadjacency_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="n">r</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">r</span><span class="p">])</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">()</span>
    <span class="p">)</span>
<span class="n">adjacencies</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;rank_</span><span class="si">{</span><span class="n">max_rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">sparse_to_torch</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">coadjacency_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="n">max_rank</span><span class="p">))</span>
    <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">max_rank</span><span class="p">])</span><span class="o">.</span><span class="n">to_sparse</span><span class="p">()</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">r</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The adjacency matrix H</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2"> has shape: </span><span class="si">{</span><span class="n">adjacencies</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;rank_</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">r</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The incidence matrix B</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s2"> has shape: </span><span class="si">{</span><span class="n">incidences</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;rank_</span><span class="si">{</span><span class="n">r</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The adjacency matrix H0 has shape: torch.Size([34, 34]).
The adjacency matrix H1 has shape: torch.Size([78, 78]).
The incidence matrix B1 has shape: torch.Size([34, 78]).
The adjacency matrix H2 has shape: torch.Size([45, 45]).
The incidence matrix B2 has shape: torch.Size([78, 45]).
The adjacency matrix H3 has shape: torch.Size([11, 11]).
The incidence matrix B3 has shape: torch.Size([45, 11]).
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/Users/ninamiolane/opt/anaconda3/envs/tmx/lib/python3.11/site-packages/scipy/sparse/_index.py:143: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.
  self._set_arrayXarray(i, j, x)
</pre></div></div>
</div>
</section>
<section id="Import-signal">
<h2>Import signal<a class="headerlink" href="#Import-signal" title="Link to this heading">#</a></h2>
<p>We import the features at each rank.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_0</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_simplex_attributes</span><span class="p">(</span><span class="s2">&quot;node_feat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">x_0</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_0</span><span class="p">))</span>
<span class="n">channels_nodes</span> <span class="o">=</span> <span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> nodes with features of dimension </span><span class="si">{</span><span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
There are 34 nodes with features of dimension 8.
</pre></div></div>
</div>
<p>Load edge features.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_1</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_simplex_attributes</span><span class="p">(</span><span class="s2">&quot;edge_feat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">x_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="n">x_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> edges with features of dimension </span><span class="si">{</span><span class="n">x_1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
There are 78 edges with features of dimension 8.
</pre></div></div>
</div>
<p>Similarly for face features:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_2</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_simplex_attributes</span><span class="p">(</span><span class="s2">&quot;face_feat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">x_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="n">x_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> faces with features of dimension </span><span class="si">{</span><span class="n">x_2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
There are 45 faces with features of dimension 8.
</pre></div></div>
</div>
<p>Higher order features:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_3</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_simplex_attributes</span><span class="p">(</span><span class="s2">&quot;tetrahedron_feat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">x_3</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="n">x_3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_3</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> tetrahedrons with features of dimension </span><span class="si">{</span><span class="n">x_3</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
There are 11 tetrahedrons with features of dimension 8.
</pre></div></div>
</div>
<p>The features are organized in a dictionary keeping track of their rank, similar to the adjacencies/incidences earlier.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;rank_0&quot;</span><span class="p">:</span> <span class="n">x_0</span><span class="p">,</span> <span class="s2">&quot;rank_1&quot;</span><span class="p">:</span> <span class="n">x_1</span><span class="p">,</span> <span class="s2">&quot;rank_2&quot;</span><span class="p">:</span> <span class="n">x_2</span><span class="p">,</span> <span class="s2">&quot;rank_3&quot;</span><span class="p">:</span> <span class="n">x_3</span><span class="p">}</span>
</pre></div>
</div>
</div>
</section>
<section id="Define-binary-labels">
<h2>Define binary labels<a class="headerlink" href="#Define-binary-labels" title="Link to this heading">#</a></h2>
<p>We retrieve the labels associated to the nodes of each input simplex. In the KarateClub dataset, two social groups emerge. So we assign binary labels to the nodes indicating of which group they are a part.</p>
<p>We keep the last four nodesâ€™ true labels for the purpose of testing.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">[:</span><span class="mi">30</span><span class="p">])</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">30</span><span class="p">:])</span>
<span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> Out [14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,
         0, 0, 0, 0, 0, 0]),
 tensor([0, 0, 0, 0]))
</pre></div></div>
</div>
</section>
</section>
<section id="Create-the-Neural-Network">
<h1>Create the Neural Network<a class="headerlink" href="#Create-the-Neural-Network" title="Link to this heading">#</a></h1>
<p>Using the HSNLayer class, we create a neural network with stacked layers. A linear layer at the end produces an output with shape <span class="math notranslate nohighlight">\(n_\text{nodes}\)</span>, so we can compare with our binary labels.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SCCN</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Simplicial Complex Convolutional Network Implementation for binary node classification.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ---------</span>
<span class="sd">    channels : int</span>
<span class="sd">        Dimension of features</span>
<span class="sd">    n_layers : int</span>
<span class="sd">        Number of message passing layers.</span>
<span class="sd">    n_classes : int</span>
<span class="sd">        Number of classes.</span>
<span class="sd">    update_func : str</span>
<span class="sd">        Activation function used in aggregation layers.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">max_rank</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">update_func</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">SCCNLayer</span><span class="p">(</span>
                    <span class="n">channels</span><span class="o">=</span><span class="n">channels</span><span class="p">,</span>
                    <span class="n">max_rank</span><span class="o">=</span><span class="n">max_rank</span><span class="p">,</span>
                    <span class="n">update_func</span><span class="o">=</span><span class="n">update_func</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="k">assert</span> <span class="n">n_classes</span> <span class="o">&gt;=</span> <span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;n_classes must be &gt;= 2&quot;</span>

        <span class="k">if</span> <span class="n">n_classes</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">n_classes</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">incidences</span><span class="p">,</span> <span class="n">adjacencies</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Forward computation.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ---------</span>
<span class="sd">        features: Dict[int, torch.Tensor],</span>
<span class="sd">                length=max_rank+1,</span>
<span class="sd">                shape=[n_rank_r_cells, channels]</span>
<span class="sd">            Input features on the cells of the simplicial complex.</span>
<span class="sd">        incidences : Dict[int, torch.sparse],</span>
<span class="sd">                length=max_rank,</span>
<span class="sd">                shape=[n_rank_r_minus_1_cells, n_rank_r_cells]</span>
<span class="sd">            Incidence matrices :math:`B_r` mapping r-cells to (r-1)-cells.</span>
<span class="sd">        adjacencies : Dict[int, torch.sparse],</span>
<span class="sd">                length=max_rank,</span>
<span class="sd">                shape=[n_rank_r_cells, n_rank_r_cells]</span>
<span class="sd">            Adjacency matrices :math:`H_r` mapping cells to cells</span>
<span class="sd">                via lower and upper cells.</span>

<span class="sd">        Returns</span>
<span class="sd">        --------</span>
<span class="sd">        _ : tensor</span>
<span class="sd">            If n_classes &gt; 2:</span>
<span class="sd">                shape = [n_nodes, n_classes]</span>
<span class="sd">                Logits assigned to each node.</span>
<span class="sd">            If n_classes == 2:</span>
<span class="sd">                shape = [n_nodes,]</span>
<span class="sd">                Binary logits assigned to each node.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">features</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">incidences</span><span class="p">,</span> <span class="n">adjacencies</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">features</span><span class="p">[</span><span class="s2">&quot;rank_0&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">logits</span>
</pre></div>
</div>
</div>
</section>
<section id="Train-the-Neural-Network">
<h1>Train the Neural Network<a class="headerlink" href="#Train-the-Neural-Network" title="Link to this heading">#</a></h1>
<p>We specify the model with our pre-made neighborhood structures and specify an optimizer.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">SCCN</span><span class="p">(</span>
    <span class="n">channels</span><span class="o">=</span><span class="n">channels_nodes</span><span class="p">,</span>
    <span class="n">max_rank</span><span class="o">=</span><span class="n">max_rank</span><span class="p">,</span>
    <span class="n">n_layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">update_func</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>The following cell performs the training, looping over the network for a low number of epochs. Typically achieves 100% train accuracy. Test accuracy is more arbitrary between runs, likely due to the small dataset set size.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_interval</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">incidences</span><span class="p">,</span> <span class="n">adjacencies</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span>
        <span class="n">y_hat</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)]</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">epoch_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_hat</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)]</span> <span class="o">==</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch_i</span><span class="si">}</span><span class="s2"> loss: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> Train_acc: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">epoch_i</span> <span class="o">%</span> <span class="n">test_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">y_hat_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">incidences</span><span class="p">,</span> <span class="n">adjacencies</span><span class="p">)</span>
            <span class="n">y_pred_test</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_hat_test</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
            <span class="n">test_accuracy</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">(</span><span class="n">y_pred_test</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span> <span class="p">:]</span> <span class="o">==</span> <span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test_acc: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch: 1 loss: 0.6721 Train_acc: 0.6333
Epoch: 2 loss: 0.6891 Train_acc: 0.5667
Epoch: 3 loss: 0.6284 Train_acc: 0.5667
Epoch: 4 loss: 0.6173 Train_acc: 0.6667
Epoch: 5 loss: 0.6110 Train_acc: 0.7000
Epoch: 6 loss: 0.5831 Train_acc: 0.7000
Epoch: 7 loss: 0.5695 Train_acc: 0.7000
Epoch: 8 loss: 0.5638 Train_acc: 0.7000
Epoch: 9 loss: 0.5493 Train_acc: 0.7333
Epoch: 10 loss: 0.5384 Train_acc: 0.7667
Epoch: 11 loss: 0.5141 Train_acc: 0.7333
Epoch: 12 loss: 0.5201 Train_acc: 0.6667
Epoch: 13 loss: 0.5201 Train_acc: 0.7000
Epoch: 14 loss: 0.5038 Train_acc: 0.6667
Epoch: 15 loss: 0.5016 Train_acc: 0.7333
Epoch: 16 loss: 0.4906 Train_acc: 0.7333
Epoch: 17 loss: 0.4763 Train_acc: 0.7000
Epoch: 18 loss: 0.4545 Train_acc: 0.7667
Epoch: 19 loss: 0.4483 Train_acc: 0.7667
Epoch: 20 loss: 0.4153 Train_acc: 0.8000
Epoch: 21 loss: 0.4062 Train_acc: 0.8000
Epoch: 22 loss: 0.3790 Train_acc: 0.8333
Epoch: 23 loss: 0.3916 Train_acc: 0.7667
Epoch: 24 loss: 0.3529 Train_acc: 0.8667
Epoch: 25 loss: 0.2900 Train_acc: 0.8667
Epoch: 26 loss: 0.2359 Train_acc: 0.9333
Epoch: 27 loss: 0.2002 Train_acc: 0.9667
Epoch: 28 loss: 0.2970 Train_acc: 0.9000
Epoch: 29 loss: 0.2032 Train_acc: 0.9333
Epoch: 30 loss: 0.2329 Train_acc: 0.9000
Epoch: 31 loss: 0.1913 Train_acc: 0.8667
Epoch: 32 loss: 0.1516 Train_acc: 0.9667
Epoch: 33 loss: 0.1348 Train_acc: 0.9667
Epoch: 34 loss: 0.1257 Train_acc: 0.9333
Epoch: 35 loss: 0.1283 Train_acc: 0.9667
Epoch: 36 loss: 0.1136 Train_acc: 0.9333
Epoch: 37 loss: 0.0851 Train_acc: 0.9667
Epoch: 38 loss: 0.2019 Train_acc: 0.8667
Epoch: 39 loss: 0.1101 Train_acc: 0.9667
Epoch: 40 loss: 0.0873 Train_acc: 0.9667
Epoch: 41 loss: 0.0674 Train_acc: 0.9667
Epoch: 42 loss: 0.0562 Train_acc: 1.0000
Epoch: 43 loss: 0.0529 Train_acc: 1.0000
Epoch: 44 loss: 0.0512 Train_acc: 1.0000
Epoch: 45 loss: 0.0469 Train_acc: 1.0000
Epoch: 46 loss: 0.0363 Train_acc: 1.0000
Epoch: 47 loss: 0.0293 Train_acc: 1.0000
Epoch: 48 loss: 0.0272 Train_acc: 1.0000
Epoch: 49 loss: 0.0264 Train_acc: 1.0000
Epoch: 50 loss: 0.0245 Train_acc: 1.0000
Test_acc: 0.5000
Epoch: 51 loss: 0.0207 Train_acc: 1.0000
Epoch: 52 loss: 0.0165 Train_acc: 1.0000
Epoch: 53 loss: 0.0132 Train_acc: 1.0000
Epoch: 54 loss: 0.0114 Train_acc: 1.0000
Epoch: 55 loss: 0.0113 Train_acc: 1.0000
Epoch: 56 loss: 0.0117 Train_acc: 1.0000
Epoch: 57 loss: 0.0101 Train_acc: 1.0000
Epoch: 58 loss: 0.0081 Train_acc: 1.0000
Epoch: 59 loss: 0.0071 Train_acc: 1.0000
Epoch: 60 loss: 0.0065 Train_acc: 1.0000
Epoch: 61 loss: 0.0061 Train_acc: 1.0000
Epoch: 62 loss: 0.0057 Train_acc: 1.0000
Epoch: 63 loss: 0.0054 Train_acc: 1.0000
Epoch: 64 loss: 0.0050 Train_acc: 1.0000
Epoch: 65 loss: 0.0046 Train_acc: 1.0000
Epoch: 66 loss: 0.0043 Train_acc: 1.0000
Epoch: 67 loss: 0.0040 Train_acc: 1.0000
Epoch: 68 loss: 0.0038 Train_acc: 1.0000
Epoch: 69 loss: 0.0036 Train_acc: 1.0000
Epoch: 70 loss: 0.0034 Train_acc: 1.0000
Epoch: 71 loss: 0.0033 Train_acc: 1.0000
Epoch: 72 loss: 0.0032 Train_acc: 1.0000
Epoch: 73 loss: 0.0031 Train_acc: 1.0000
Epoch: 74 loss: 0.0030 Train_acc: 1.0000
Epoch: 75 loss: 0.0030 Train_acc: 1.0000
Epoch: 76 loss: 0.0029 Train_acc: 1.0000
Epoch: 77 loss: 0.0028 Train_acc: 1.0000
Epoch: 78 loss: 0.0027 Train_acc: 1.0000
Epoch: 79 loss: 0.0026 Train_acc: 1.0000
Epoch: 80 loss: 0.0026 Train_acc: 1.0000
Epoch: 81 loss: 0.0025 Train_acc: 1.0000
Epoch: 82 loss: 0.0024 Train_acc: 1.0000
Epoch: 83 loss: 0.0024 Train_acc: 1.0000
Epoch: 84 loss: 0.0023 Train_acc: 1.0000
Epoch: 85 loss: 0.0023 Train_acc: 1.0000
Epoch: 86 loss: 0.0023 Train_acc: 1.0000
Epoch: 87 loss: 0.0022 Train_acc: 1.0000
Epoch: 88 loss: 0.0022 Train_acc: 1.0000
Epoch: 89 loss: 0.0022 Train_acc: 1.0000
Epoch: 90 loss: 0.0021 Train_acc: 1.0000
Epoch: 91 loss: 0.0021 Train_acc: 1.0000
Epoch: 92 loss: 0.0021 Train_acc: 1.0000
Epoch: 93 loss: 0.0020 Train_acc: 1.0000
Epoch: 94 loss: 0.0020 Train_acc: 1.0000
Epoch: 95 loss: 0.0020 Train_acc: 1.0000
Epoch: 96 loss: 0.0019 Train_acc: 1.0000
Epoch: 97 loss: 0.0019 Train_acc: 1.0000
Epoch: 98 loss: 0.0019 Train_acc: 1.0000
Epoch: 99 loss: 0.0019 Train_acc: 1.0000
Epoch: 100 loss: 0.0018 Train_acc: 1.0000
Test_acc: 0.7500
Epoch: 101 loss: 0.0018 Train_acc: 1.0000
Epoch: 102 loss: 0.0018 Train_acc: 1.0000
Epoch: 103 loss: 0.0018 Train_acc: 1.0000
Epoch: 104 loss: 0.0018 Train_acc: 1.0000
Epoch: 105 loss: 0.0017 Train_acc: 1.0000
Epoch: 106 loss: 0.0017 Train_acc: 1.0000
Epoch: 107 loss: 0.0017 Train_acc: 1.0000
Epoch: 108 loss: 0.0017 Train_acc: 1.0000
Epoch: 109 loss: 0.0017 Train_acc: 1.0000
Epoch: 110 loss: 0.0017 Train_acc: 1.0000
Epoch: 111 loss: 0.0016 Train_acc: 1.0000
Epoch: 112 loss: 0.0016 Train_acc: 1.0000
Epoch: 113 loss: 0.0016 Train_acc: 1.0000
Epoch: 114 loss: 0.0016 Train_acc: 1.0000
Epoch: 115 loss: 0.0016 Train_acc: 1.0000
Epoch: 116 loss: 0.0016 Train_acc: 1.0000
Epoch: 117 loss: 0.0015 Train_acc: 1.0000
Epoch: 118 loss: 0.0015 Train_acc: 1.0000
Epoch: 119 loss: 0.0015 Train_acc: 1.0000
Epoch: 120 loss: 0.0015 Train_acc: 1.0000
Epoch: 121 loss: 0.0015 Train_acc: 1.0000
Epoch: 122 loss: 0.0015 Train_acc: 1.0000
Epoch: 123 loss: 0.0015 Train_acc: 1.0000
Epoch: 124 loss: 0.0014 Train_acc: 1.0000
Epoch: 125 loss: 0.0014 Train_acc: 1.0000
Epoch: 126 loss: 0.0014 Train_acc: 1.0000
Epoch: 127 loss: 0.0014 Train_acc: 1.0000
Epoch: 128 loss: 0.0014 Train_acc: 1.0000
Epoch: 129 loss: 0.0014 Train_acc: 1.0000
Epoch: 130 loss: 0.0014 Train_acc: 1.0000
Epoch: 131 loss: 0.0014 Train_acc: 1.0000
Epoch: 132 loss: 0.0013 Train_acc: 1.0000
Epoch: 133 loss: 0.0013 Train_acc: 1.0000
Epoch: 134 loss: 0.0013 Train_acc: 1.0000
Epoch: 135 loss: 0.0013 Train_acc: 1.0000
Epoch: 136 loss: 0.0013 Train_acc: 1.0000
Epoch: 137 loss: 0.0013 Train_acc: 1.0000
Epoch: 138 loss: 0.0013 Train_acc: 1.0000
Epoch: 139 loss: 0.0013 Train_acc: 1.0000
Epoch: 140 loss: 0.0013 Train_acc: 1.0000
Epoch: 141 loss: 0.0013 Train_acc: 1.0000
Epoch: 142 loss: 0.0012 Train_acc: 1.0000
Epoch: 143 loss: 0.0012 Train_acc: 1.0000
Epoch: 144 loss: 0.0012 Train_acc: 1.0000
Epoch: 145 loss: 0.0012 Train_acc: 1.0000
Epoch: 146 loss: 0.0012 Train_acc: 1.0000
Epoch: 147 loss: 0.0012 Train_acc: 1.0000
Epoch: 148 loss: 0.0012 Train_acc: 1.0000
Epoch: 149 loss: 0.0012 Train_acc: 1.0000
Epoch: 150 loss: 0.0012 Train_acc: 1.0000
Test_acc: 0.7500
Epoch: 151 loss: 0.0012 Train_acc: 1.0000
Epoch: 152 loss: 0.0011 Train_acc: 1.0000
Epoch: 153 loss: 0.0011 Train_acc: 1.0000
Epoch: 154 loss: 0.0011 Train_acc: 1.0000
Epoch: 155 loss: 0.0011 Train_acc: 1.0000
Epoch: 156 loss: 0.0011 Train_acc: 1.0000
Epoch: 157 loss: 0.0011 Train_acc: 1.0000
Epoch: 158 loss: 0.0011 Train_acc: 1.0000
Epoch: 159 loss: 0.0011 Train_acc: 1.0000
Epoch: 160 loss: 0.0011 Train_acc: 1.0000
Epoch: 161 loss: 0.0011 Train_acc: 1.0000
Epoch: 162 loss: 0.0011 Train_acc: 1.0000
Epoch: 163 loss: 0.0011 Train_acc: 1.0000
Epoch: 164 loss: 0.0011 Train_acc: 1.0000
Epoch: 165 loss: 0.0010 Train_acc: 1.0000
Epoch: 166 loss: 0.0010 Train_acc: 1.0000
Epoch: 167 loss: 0.0010 Train_acc: 1.0000
Epoch: 168 loss: 0.0010 Train_acc: 1.0000
Epoch: 169 loss: 0.0010 Train_acc: 1.0000
Epoch: 170 loss: 0.0010 Train_acc: 1.0000
Epoch: 171 loss: 0.0010 Train_acc: 1.0000
Epoch: 172 loss: 0.0010 Train_acc: 1.0000
Epoch: 173 loss: 0.0010 Train_acc: 1.0000
Epoch: 174 loss: 0.0010 Train_acc: 1.0000
Epoch: 175 loss: 0.0010 Train_acc: 1.0000
Epoch: 176 loss: 0.0010 Train_acc: 1.0000
Epoch: 177 loss: 0.0010 Train_acc: 1.0000
Epoch: 178 loss: 0.0010 Train_acc: 1.0000
Epoch: 179 loss: 0.0009 Train_acc: 1.0000
Epoch: 180 loss: 0.0009 Train_acc: 1.0000
Epoch: 181 loss: 0.0009 Train_acc: 1.0000
Epoch: 182 loss: 0.0009 Train_acc: 1.0000
Epoch: 183 loss: 0.0009 Train_acc: 1.0000
Epoch: 184 loss: 0.0009 Train_acc: 1.0000
Epoch: 185 loss: 0.0009 Train_acc: 1.0000
Epoch: 186 loss: 0.0009 Train_acc: 1.0000
Epoch: 187 loss: 0.0009 Train_acc: 1.0000
Epoch: 188 loss: 0.0009 Train_acc: 1.0000
Epoch: 189 loss: 0.0009 Train_acc: 1.0000
Epoch: 190 loss: 0.0009 Train_acc: 1.0000
Epoch: 191 loss: 0.0009 Train_acc: 1.0000
Epoch: 192 loss: 0.0009 Train_acc: 1.0000
Epoch: 193 loss: 0.0009 Train_acc: 1.0000
Epoch: 194 loss: 0.0009 Train_acc: 1.0000
Epoch: 195 loss: 0.0009 Train_acc: 1.0000
Epoch: 196 loss: 0.0008 Train_acc: 1.0000
Epoch: 197 loss: 0.0008 Train_acc: 1.0000
Epoch: 198 loss: 0.0008 Train_acc: 1.0000
Epoch: 199 loss: 0.0008 Train_acc: 1.0000
Epoch: 200 loss: 0.0008 Train_acc: 1.0000
Test_acc: 0.7500
</pre></div></div>
</div>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="sca_cmps_train.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)</p>
      </div>
    </a>
    <a class="right-next"
       href="sccnn_train.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Train a SCCNN</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Train a Simplicial Complex Convolutional Network (SCCN)</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Pre-processing">Pre-processing</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Import-dataset">Import dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Define-neighborhood-structures.">Define neighborhood structures.</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Import-signal">Import signal</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Define-binary-labels">Define binary labels</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Create-the-Neural-Network">Create the Neural Network</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Train-the-Neural-Network">Train the Neural Network</a></li>
</ul>

  </nav></div>

  <div class="sidebar-secondary-item">
  <div class="tocsection sourcelink">
    <a href="../../_sources/notebooks/simplicial/sccn_train.ipynb.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  <p class="copyright">
    
      Â© Copyright 2022-2023, PyT-Team, Inc..
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.13.3.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>