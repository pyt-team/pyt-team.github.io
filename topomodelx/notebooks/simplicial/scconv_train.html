
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Train a Simplicial 2-complex convolutional neural network (SCConv) &#8212; TopoModelX latest documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=61a4c737" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../_static/documentation_options.js?v=c6e86fd7"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/simplicial/scconv_train';</script>
    <link rel="canonical" href="pyt-team.github.io/notebooks/simplicial/scconv_train.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Train a Simplex Convolutional Network (SCN) of Rank 2" href="scn2_train.html" />
    <link rel="prev" title="Train a SCCNN" href="sccnn_train.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
    <meta name="docbuild:last-update" content="Feb 20, 2024, 3:47:04â€¯PM"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">TopoModelX latest documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav class="navbar-nav">
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../api/index.html">
                        API Reference
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../contributing/index.html">
                        Contributing
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../../tutorials/index.html">
                        Tutorials
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../challenge/index.html">
                        ICML 2023 Topological Deep Learning Challenge
                      </a>
                    </li>
                
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary" tabindex="0">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item">
<nav class="navbar-nav">
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../api/index.html">
                        API Reference
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../contributing/index.html">
                        Contributing
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../../tutorials/index.html">
                        Tutorials
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../../challenge/index.html">
                        ICML 2023 Topological Deep Learning Challenge
                      </a>
                    </li>
                
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../cell/can_train.html">Train a Cell Attention Network (CAN)</a></li>




<li class="toctree-l1"><a class="reference internal" href="../cell/ccxn_train.html">Train a Convolutional Cell Complex Network (CCXN)</a></li>





<li class="toctree-l1"><a class="reference internal" href="../cell/cwn_train.html">Train a CW Network (CWN)</a></li>




</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../hypergraph/allset_train.html">Train an All-Set TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/allset_transformer_train.html">Train an All-Set-Transformer TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/dhgcn_train.html">Train a DHGCN TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hmpnn_train.html">Train a Hypergraph Message Passing Neural Network (HMPNN)</a></li>


<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hnhn_train.html">Train a Hypergraph Networks with Hyperedge Neurons (HNHN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hypergat_train.html">Train a Hypergraph Neural Network</a></li>


<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hypersage_train.html">Train a Hypersage TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unigcn_train.html">Train a UNIGCN TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unigcnii_train.html">Train a hypergraph neural network using UniGCNII layers</a></li>

<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unigin_train.html">Train a UNIGIN TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unisage_train.html">Train a Uni-sage TNN</a></li>



</ul>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dist2cycle_train.html">Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)</a></li>




<li class="toctree-l1"><a class="reference internal" href="hsn_train.html">Train a Simplicial High-Skip Network (HSN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="san_train.html">Train a Simplicial Attention Network (SAN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="sca_cmps_train.html">Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)</a></li>



<li class="toctree-l1"><a class="reference internal" href="sccn_train.html">Train a Simplicial Complex Convolutional Network (SCCN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="sccnn_train.html">Train a SCCNN</a></li>





<li class="toctree-l1 current active"><a class="current reference internal" href="#">Train a Simplicial 2-complex convolutional neural network (SCConv)</a></li>




<li class="toctree-l1"><a class="reference internal" href="scn2_train.html">Train a Simplex Convolutional Network (SCN) of Rank 2</a></li>


<li class="toctree-l1"><a class="reference internal" href="scnn_train.html">Train a Simplicial Convolutional Neural Network (SCNN)</a></li>






<li class="toctree-l1"><a class="reference internal" href="scone_train.html">Train a Simplicial Complex Net (SCoNe)</a></li>






</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../tutorials/index.html" class="nav-link">Tutorials</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Train a...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="Train-a-Simplicial-2-complex-convolutional-neural-network-(SCConv)">
<h1>Train a Simplicial 2-complex convolutional neural network (SCConv)<a class="headerlink" href="#Train-a-Simplicial-2-complex-convolutional-neural-network-(SCConv)" title="Link to this heading">#</a></h1>
<p>In this notebook, we will create and train a Simplicial 2-complex convolutional neural in the simplicial complex domain, as proposed in the paper by <a class="reference external" href="https://openreview.net/pdf?id=Sc8glB-k6e9">Bunch et. al : Simplicial 2-Complex Convolutional Neural Networks (2020)</a>.</p>
<p>We train the model to perform</p>
<p>The equations of one layer of this neural network are given by:</p>
<p>ðŸŸ¥ <span class="math notranslate nohighlight">\(\quad m_{y\rightarrow x}^{(0\rightarrow 0)} = ({\tilde{A}_{\uparrow,0}})_{xy} \cdot h_y^{t,(0)} \cdot \Theta^{t,(0\rightarrow0)}\)</span></p>
<p>ðŸŸ¥ <span class="math notranslate nohighlight">\(\quad m^{(1\rightarrow0)}_{y\rightarrow x} = (B_1)_{xy} \cdot h_y^{t,(0)} \cdot \Theta^{t,(1\rightarrow 0)}\)</span></p>
<p>ðŸŸ¥ <span class="math notranslate nohighlight">\(\quad m^{(0 \rightarrow 1)}_{y \rightarrow x} = (\tilde B_1)_{xy} \cdot h_y^{t,(0)} \cdot \Theta^{t,(0 \rightarrow1)}\)</span></p>
<p>ðŸŸ¥ <span class="math notranslate nohighlight">\(\quad m^{(1\rightarrow1)}_{y\rightarrow x} = ({\tilde{A}_{\downarrow,1}} + {\tilde{A}_{\uparrow,1}})_{xy} \cdot h_y^{t,(1)} \cdot \Theta^{t,(1\rightarrow1)}\)</span></p>
<p>ðŸŸ¥ <span class="math notranslate nohighlight">\(\quad m^{(2\rightarrow1)}_{y \rightarrow x} = (B_2)_{xy} \cdot h_y^{t,(2)} \cdot \Theta^{t,(2 \rightarrow1)}\)</span></p>
<p>ðŸŸ¥ <span class="math notranslate nohighlight">\(\quad m^{(1 \rightarrow 2)}_{y \rightarrow x} = (\tilde B_2)_{xy} \cdot h_y^{t,(1)} \cdot \Theta^{t,(1 \rightarrow 2)}\)</span></p>
<p>ðŸŸ¥ <span class="math notranslate nohighlight">\(\quad m^{(2 \rightarrow 2)}_{y \rightarrow x} = ({\tilde{A}_{\downarrow,2}})_{xy} \cdot h_y^{t,(2)} \cdot \Theta^{t,(2 \rightarrow 2)}\)</span></p>
<p>ðŸŸ§ <span class="math notranslate nohighlight">\(\quad m_x^{(0 \rightarrow 0)} = \sum_{y \in \mathcal{L}_\uparrow(x)} m_{y \rightarrow x}^{(0 \rightarrow 0)}\)</span></p>
<p>ðŸŸ§ <span class="math notranslate nohighlight">\(\quad m_x^{(1 \rightarrow 0)} = \sum_{y \in \mathcal{C}(x)} m_{y \rightarrow x}^{(1 \rightarrow 0)}\)</span></p>
<p>ðŸŸ§ <span class="math notranslate nohighlight">\(\quad m_x^{(0 \rightarrow 1)} = \sum_{y \in \mathcal{B}(x)} m_{y \rightarrow x}^{(0 \rightarrow 1)}\)</span></p>
<p>ðŸŸ§ <span class="math notranslate nohighlight">\(\quad m_x^{(1 \rightarrow 1)} = \sum_{y \in (\mathcal{L}_\uparrow(x) + \mathcal{L}_\downarrow(x))} m_{y \rightarrow x}^{(1 \rightarrow 1)}\)</span></p>
<p>ðŸŸ§ <span class="math notranslate nohighlight">\(\quad m_x^{(2 \rightarrow 1)} = \sum_{y \in \mathcal{C}(x)} m_{y \rightarrow x}^{(2 \rightarrow 1)}\)</span></p>
<p>ðŸŸ§ <span class="math notranslate nohighlight">\(\quad m_x^{(1 \rightarrow 2)} = \sum_{y \in \mathcal{B}(x)} m_{y \rightarrow x}^{(1 \rightarrow 2)}\)</span></p>
<p>ðŸŸ§ <span class="math notranslate nohighlight">\(\quad m_x^{(2 \rightarrow 2)} = \sum_{y \in \mathcal{L}_\downarrow(x)} m_{y \rightarrow x}^{(2 \rightarrow 2)}\)</span></p>
<p>ðŸŸ© <span class="math notranslate nohighlight">\(\quad m_x^{(0)} = m_x^{(1\rightarrow0)}+ m_x^{(0\rightarrow0)}\)</span></p>
<p>ðŸŸ© <span class="math notranslate nohighlight">\(\quad m_x^{(1)} = m_x^{(2\rightarrow1)}+ m_x^{(1\rightarrow1)}\)</span></p>
<p>ðŸŸ¦ <span class="math notranslate nohighlight">\(\quad h^{t+1, (0)}_x = \sigma(m_x^{(0)})\)</span></p>
<p>ðŸŸ¦ <span class="math notranslate nohighlight">\(\quad h^{t+1, (1)}_x = \sigma(m_x^{(1)})\)</span></p>
<p>ðŸŸ¦ <span class="math notranslate nohighlight">\(\quad h^{t+1, (2)}_x = \sigma(m_x^{(2)})\)</span></p>
<p>Where the notations are defined in <a class="reference external" href="https://arxiv.org/abs/2304.10031">Papillon et al : Architectures of Topological Deep Learning: A Survey of Topological Neural Networks (2023)</a>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [52]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">toponetx.datasets.graph</span> <span class="k">as</span> <span class="nn">graph</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">coo_matrix</span><span class="p">,</span> <span class="n">diags</span>

<span class="kn">from</span> <span class="nn">topomodelx.nn.simplicial.scconv</span> <span class="kn">import</span> <span class="n">SCConv</span>
<span class="kn">from</span> <span class="nn">topomodelx.utils.sparse</span> <span class="kn">import</span> <span class="n">from_sparse</span>

<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [53]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
cpu
</pre></div></div>
</div>
</section>
<section id="Pre-processing">
<h1>Pre-processing<a class="headerlink" href="#Pre-processing" title="Link to this heading">#</a></h1>
<section id="Import-dataset">
<h2>Import dataset<a class="headerlink" href="#Import-dataset" title="Link to this heading">#</a></h2>
<p>The first step is to import the Karate Club (<a class="reference external" href="https://www.jstor.org/stable/3629752">https://www.jstor.org/stable/3629752</a>) dataset. This is a singular graph with 34 nodes that belong to two different social groups. We will use these groups for the task of node-level binary classification.</p>
<p>We must first lift our graph dataset into the simplicial complex domain.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [54]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">graph</span><span class="o">.</span><span class="n">karate_club</span><span class="p">(</span><span class="n">complex_type</span><span class="o">=</span><span class="s2">&quot;simplicial&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Simplicial Complex with shape (34, 78, 45, 11, 2) and dimension 4
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [55]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> Out [55]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(34, 78, 45, 11, 2)
</pre></div></div>
</div>
</section>
</section>
<section id="Define-Neighbourhood-Structures">
<h1>Define Neighbourhood Structures<a class="headerlink" href="#Define-Neighbourhood-Structures" title="Link to this heading">#</a></h1>
<p>We create the neigborood structures expected by SSConv. The SSConv layer expects the following neighbourhood structures: * incidence_1 <span class="math notranslate nohighlight">\(B_1\)</span> * incidence_1_norm <span class="math notranslate nohighlight">\(\tilde{B}_1\)</span> * incidence_2 <span class="math notranslate nohighlight">\(B_2\)</span> * incidence_2_norm <span class="math notranslate nohighlight">\(\tilde{B}_1\)</span> * adjacency_up_0_norm <span class="math notranslate nohighlight">\(\tilde{A}_{\uparrow,0}\)</span> * adjacency_up_1_norm <span class="math notranslate nohighlight">\(\tilde{A}_{\uparrow,1}\)</span> * adjacency_down_1_norm <span class="math notranslate nohighlight">\(\tilde{A}_{\downarrow,1}\)</span> * adjacency_down_2_norm <span class="math notranslate nohighlight">\(\tilde{A}_{\downarrow,2}\)</span></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [56]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Not working, it needs to be reviewed</span>
<span class="k">def</span> <span class="nf">normalize_higher_order_adj</span><span class="p">(</span><span class="n">A_opt</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Args:</span>
<span class="sd">        A_opt is an opt that maps a j-cochain to a k-cochain.</span>
<span class="sd">        shape [num_of_k_simplices num_of_j_simplices]</span>

<span class="sd">    return:</span>
<span class="sd">         D^{-0.5}* (A_opt)* D^{-0.5}.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">rowsum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">A_opt</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">r_inv_sqrt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">rowsum</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="n">r_inv_sqrt</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">r_inv_sqrt</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">r_mat_inv_sqrt</span> <span class="o">=</span> <span class="n">diags</span><span class="p">(</span><span class="n">r_inv_sqrt</span><span class="p">)</span>
    <span class="n">A_opt_to</span> <span class="o">=</span> <span class="n">A_opt</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">r_mat_inv_sqrt</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">r_mat_inv_sqrt</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">coo_matrix</span><span class="p">(</span><span class="n">A_opt_to</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [78]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">incidence_1_norm</span> <span class="o">=</span> <span class="n">incidence_0_1</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">incidence_matrix</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">incidence_1</span> <span class="o">=</span> <span class="n">incidence_1_0</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">coincidence_matrix</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">incidence_2_norm</span> <span class="o">=</span> <span class="n">incidence_1_2</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">incidence_matrix</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="n">incidence_2</span> <span class="o">=</span> <span class="n">incidence_2_1</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">coincidence_matrix</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="n">adjacency_up_0_norm</span> <span class="o">=</span> <span class="n">adjacency_0</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">up_laplacian_matrix</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
<span class="n">adjacency_up_1_norm</span> <span class="o">=</span> <span class="n">adjacency_1_up</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">up_laplacian_matrix</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">adjacency_down_1_norm</span> <span class="o">=</span> <span class="n">adjacency_1_down</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">down_laplacian_matrix</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">adjacency_down_2_norm</span> <span class="o">=</span> <span class="n">adjacency_2</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">down_laplacian_matrix</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<section id="Import-signal">
<h2>Import signal<a class="headerlink" href="#Import-signal" title="Link to this heading">#</a></h2>
<p>We retrieve an input signal on the nodes, edges and faces. The signal will have shape <span class="math notranslate nohighlight">\(n_\text{simplicial} \times\)</span> in_channels, where in_channels is the dimension of each simplicialâ€™s feature. Here, we have in_channels = channels_nodes $ = 2$.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [89]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_0</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_simplex_attributes</span><span class="p">(</span><span class="s2">&quot;node_feat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">x_0</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_0</span><span class="p">))</span>
<span class="n">channels_nodes</span> <span class="o">=</span> <span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> nodes with features of dimension </span><span class="si">{</span><span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

<span class="n">x_1</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_simplex_attributes</span><span class="p">(</span><span class="s2">&quot;edge_feat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">x_1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="n">x_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> edges with features of dimension </span><span class="si">{</span><span class="n">x_1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

<span class="n">x_2</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset</span><span class="o">.</span><span class="n">get_simplex_attributes</span><span class="p">(</span><span class="s2">&quot;face_feat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">x_2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="n">x_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x_2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> faces with features of dimension </span><span class="si">{</span><span class="n">x_2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
There are 34 nodes with features of dimension 2.
There are 78 edges with features of dimension 2.
There are 45 faces with features of dimension 2.
</pre></div></div>
</div>
<p>We also pre-define the number output channels of the model, in this case the number of node classes.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [90]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">in_channels</span> <span class="o">=</span> <span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
</div>
</section>
<section id="Define-binary-labels">
<h2>Define binary labels<a class="headerlink" href="#Define-binary-labels" title="Link to this heading">#</a></h2>
<p>We retrieve the labels associated to the nodes of each input simplex. In the KarateClub dataset, two social groups emerge. So we assign binary labels to the nodes indicating of which group they are a part.</p>
<p>We convert one-hot encode the binary labels, and keep the first four nodes for the purpose of testing.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [91]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">34</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">y_true</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
<span class="n">y_true</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[:</span><span class="mi">30</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">:]</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Create-the-Neural-Network">
<h1>Create the Neural Network<a class="headerlink" href="#Create-the-Neural-Network" title="Link to this heading">#</a></h1>
<p>Using the SAN class, we create our neural network with stacked layers. Given the considered dataset and task (Karate Club, node classification), a linear layer at the end produces an output with shape <span class="math notranslate nohighlight">\(n_\text{nodes} \times 2\)</span>, so we can compare with our binary labels.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [99]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">SCConv</span><span class="p">(</span>
            <span class="n">node_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
            <span class="n">n_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_x1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_x2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x_0</span><span class="p">,</span>
        <span class="n">x_1</span><span class="p">,</span>
        <span class="n">x_2</span><span class="p">,</span>
        <span class="n">incidence_1</span><span class="p">,</span>
        <span class="n">incidence_1_norm</span><span class="p">,</span>
        <span class="n">incidence_2</span><span class="p">,</span>
        <span class="n">incidence_2_norm</span><span class="p">,</span>
        <span class="n">adjacency_up_0_norm</span><span class="p">,</span>
        <span class="n">adjacency_up_1_norm</span><span class="p">,</span>
        <span class="n">adjacency_down_1_norm</span><span class="p">,</span>
        <span class="n">adjacency_down_2_norm</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">x_0</span><span class="p">,</span> <span class="n">x_1</span><span class="p">,</span> <span class="n">x_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">(</span>
            <span class="n">x_0</span><span class="p">,</span>
            <span class="n">x_1</span><span class="p">,</span>
            <span class="n">x_2</span><span class="p">,</span>
            <span class="n">incidence_1</span><span class="p">,</span>
            <span class="n">incidence_1_norm</span><span class="p">,</span>
            <span class="n">incidence_2</span><span class="p">,</span>
            <span class="n">incidence_2_norm</span><span class="p">,</span>
            <span class="n">adjacency_up_0_norm</span><span class="p">,</span>
            <span class="n">adjacency_up_1_norm</span><span class="p">,</span>
            <span class="n">adjacency_down_1_norm</span><span class="p">,</span>
            <span class="n">adjacency_down_2_norm</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">x_0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_x0</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>
        <span class="n">x_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_x1</span><span class="p">(</span><span class="n">x_1</span><span class="p">)</span>
        <span class="n">x_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_x2</span><span class="p">(</span><span class="n">x_2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [100]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span>
    <span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
    <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
    <span class="n">n_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Train-the-Neural-Network">
<h1>Train the Neural Network<a class="headerlink" href="#Train-the-Neural-Network" title="Link to this heading">#</a></h1>
<p>The following cell performs the training, looping over the network for a low number of epochs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [102]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_interval</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">200</span>
<span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>
        <span class="n">x_0</span><span class="p">,</span>
        <span class="n">x_1</span><span class="p">,</span>
        <span class="n">x_2</span><span class="p">,</span>
        <span class="n">incidence_1</span><span class="p">,</span>
        <span class="n">incidence_1_norm</span><span class="p">,</span>
        <span class="n">incidence_2</span><span class="p">,</span>
        <span class="n">incidence_2_norm</span><span class="p">,</span>
        <span class="n">adjacency_up_0_norm</span><span class="p">,</span>
        <span class="n">adjacency_up_1_norm</span><span class="p">,</span>
        <span class="n">adjacency_down_1_norm</span><span class="p">,</span>
        <span class="n">adjacency_down_2_norm</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span>
        <span class="n">y_hat</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)]</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">epoch_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_hat</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)]</span> <span class="o">==</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch_i</span><span class="si">}</span><span class="s2"> loss: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> Train_acc: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">epoch_i</span> <span class="o">%</span> <span class="n">test_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">y_hat_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span>
                <span class="n">x_0</span><span class="p">,</span>
                <span class="n">x_1</span><span class="p">,</span>
                <span class="n">x_2</span><span class="p">,</span>
                <span class="n">incidence_1</span><span class="p">,</span>
                <span class="n">incidence_1_norm</span><span class="p">,</span>
                <span class="n">incidence_2</span><span class="p">,</span>
                <span class="n">incidence_2_norm</span><span class="p">,</span>
                <span class="n">adjacency_up_0_norm</span><span class="p">,</span>
                <span class="n">adjacency_up_1_norm</span><span class="p">,</span>
                <span class="n">adjacency_down_1_norm</span><span class="p">,</span>
                <span class="n">adjacency_down_2_norm</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">y_hat_test</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">test_accuracy</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y_pred_test</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span> <span class="p">:],</span> <span class="n">y_test</span><span class="p">)</span>
                <span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="o">.</span><span class="n">float</span><span class="p">()</span>
                <span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                <span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test_acc: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch: 1 loss: 0.7134 Train_acc: 0.5667
Epoch: 2 loss: 0.7133 Train_acc: 0.5667
Epoch: 3 loss: 0.7132 Train_acc: 0.5667
Epoch: 4 loss: 0.7131 Train_acc: 0.5667
Epoch: 5 loss: 0.7128 Train_acc: 0.5667
Epoch: 6 loss: 0.7125 Train_acc: 0.5667
Epoch: 7 loss: 0.7120 Train_acc: 0.5667
Epoch: 8 loss: 0.7117 Train_acc: 0.5667
Epoch: 9 loss: 0.7113 Train_acc: 0.5667
Epoch: 10 loss: 0.7109 Train_acc: 0.5667
Test_acc: 0.0000
Epoch: 11 loss: 0.7105 Train_acc: 0.5667
Epoch: 12 loss: 0.7099 Train_acc: 0.5667
Epoch: 13 loss: 0.7093 Train_acc: 0.5667
Epoch: 14 loss: 0.7086 Train_acc: 0.5667
Epoch: 15 loss: 0.7079 Train_acc: 0.5667
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch: 16 loss: 0.7070 Train_acc: 0.5667
Epoch: 17 loss: 0.7062 Train_acc: 0.5667
Epoch: 18 loss: 0.7052 Train_acc: 0.5667
Epoch: 19 loss: 0.7042 Train_acc: 0.5667
Epoch: 20 loss: 0.7030 Train_acc: 0.5667
Test_acc: 0.0000
Epoch: 21 loss: 0.7017 Train_acc: 0.5667
Epoch: 22 loss: 0.7003 Train_acc: 0.5667
Epoch: 23 loss: 0.6988 Train_acc: 0.5667
Epoch: 24 loss: 0.6971 Train_acc: 0.5667
Epoch: 25 loss: 0.6954 Train_acc: 0.5667
Epoch: 26 loss: 0.6935 Train_acc: 0.5667
Epoch: 27 loss: 0.6916 Train_acc: 0.5667
Epoch: 28 loss: 0.6894 Train_acc: 0.5667
Epoch: 29 loss: 0.6872 Train_acc: 0.5667
Epoch: 30 loss: 0.6849 Train_acc: 0.5667
Test_acc: 0.5000
Epoch: 31 loss: 0.6824 Train_acc: 0.6000
Epoch: 32 loss: 0.6799 Train_acc: 0.6000
Epoch: 33 loss: 0.6772 Train_acc: 0.6333
Epoch: 34 loss: 0.6745 Train_acc: 0.6333
Epoch: 35 loss: 0.6716 Train_acc: 0.6667
Epoch: 36 loss: 0.6687 Train_acc: 0.7000
Epoch: 37 loss: 0.6657 Train_acc: 0.7333
Epoch: 38 loss: 0.6626 Train_acc: 0.7333
Epoch: 39 loss: 0.6596 Train_acc: 0.7667
Epoch: 40 loss: 0.6564 Train_acc: 0.9333
Test_acc: 1.0000
Epoch: 41 loss: 0.6533 Train_acc: 0.9667
Epoch: 42 loss: 0.6501 Train_acc: 0.9333
Epoch: 43 loss: 0.6469 Train_acc: 0.9333
Epoch: 44 loss: 0.6437 Train_acc: 0.9333
Epoch: 45 loss: 0.6406 Train_acc: 0.9333
Epoch: 46 loss: 0.6374 Train_acc: 0.9333
Epoch: 47 loss: 0.6343 Train_acc: 0.9667
Epoch: 48 loss: 0.6313 Train_acc: 0.9667
Epoch: 49 loss: 0.6282 Train_acc: 0.9667
Epoch: 50 loss: 0.6253 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 51 loss: 0.6223 Train_acc: 0.9667
Epoch: 52 loss: 0.6195 Train_acc: 0.9667
Epoch: 53 loss: 0.6167 Train_acc: 0.9667
Epoch: 54 loss: 0.6140 Train_acc: 0.9667
Epoch: 55 loss: 0.6113 Train_acc: 0.9667
Epoch: 56 loss: 0.6087 Train_acc: 0.9667
Epoch: 57 loss: 0.6062 Train_acc: 0.9667
Epoch: 58 loss: 0.6038 Train_acc: 0.9667
Epoch: 59 loss: 0.6014 Train_acc: 0.9667
Epoch: 60 loss: 0.5991 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 61 loss: 0.5969 Train_acc: 0.9667
Epoch: 62 loss: 0.5948 Train_acc: 0.9667
Epoch: 63 loss: 0.5927 Train_acc: 0.9667
Epoch: 64 loss: 0.5907 Train_acc: 0.9667
Epoch: 65 loss: 0.5887 Train_acc: 0.9667
Epoch: 66 loss: 0.5869 Train_acc: 0.9667
Epoch: 67 loss: 0.5851 Train_acc: 0.9667
Epoch: 68 loss: 0.5833 Train_acc: 0.9667
Epoch: 69 loss: 0.5817 Train_acc: 0.9667
Epoch: 70 loss: 0.5801 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 71 loss: 0.5785 Train_acc: 0.9667
Epoch: 72 loss: 0.5770 Train_acc: 0.9667
Epoch: 73 loss: 0.5756 Train_acc: 0.9667
Epoch: 74 loss: 0.5742 Train_acc: 0.9667
Epoch: 75 loss: 0.5728 Train_acc: 0.9667
Epoch: 76 loss: 0.5715 Train_acc: 0.9667
Epoch: 77 loss: 0.5703 Train_acc: 0.9667
Epoch: 78 loss: 0.5691 Train_acc: 0.9667
Epoch: 79 loss: 0.5679 Train_acc: 0.9667
Epoch: 80 loss: 0.5668 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 81 loss: 0.5657 Train_acc: 0.9667
Epoch: 82 loss: 0.5647 Train_acc: 0.9667
Epoch: 83 loss: 0.5637 Train_acc: 0.9667
Epoch: 84 loss: 0.5627 Train_acc: 0.9667
Epoch: 85 loss: 0.5618 Train_acc: 0.9667
Epoch: 86 loss: 0.5609 Train_acc: 0.9667
Epoch: 87 loss: 0.5601 Train_acc: 0.9667
Epoch: 88 loss: 0.5592 Train_acc: 0.9667
Epoch: 89 loss: 0.5584 Train_acc: 0.9667
Epoch: 90 loss: 0.5577 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 91 loss: 0.5569 Train_acc: 0.9667
Epoch: 92 loss: 0.5562 Train_acc: 0.9667
Epoch: 93 loss: 0.5555 Train_acc: 0.9667
Epoch: 94 loss: 0.5548 Train_acc: 0.9667
Epoch: 95 loss: 0.5542 Train_acc: 0.9667
Epoch: 96 loss: 0.5535 Train_acc: 0.9667
Epoch: 97 loss: 0.5529 Train_acc: 0.9667
Epoch: 98 loss: 0.5523 Train_acc: 0.9667
Epoch: 99 loss: 0.5518 Train_acc: 0.9667
Epoch: 100 loss: 0.5512 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 101 loss: 0.5507 Train_acc: 0.9667
Epoch: 102 loss: 0.5502 Train_acc: 0.9667
Epoch: 103 loss: 0.5497 Train_acc: 0.9667
Epoch: 104 loss: 0.5492 Train_acc: 0.9667
Epoch: 105 loss: 0.5487 Train_acc: 0.9667
Epoch: 106 loss: 0.5483 Train_acc: 0.9667
Epoch: 107 loss: 0.5478 Train_acc: 0.9667
Epoch: 108 loss: 0.5474 Train_acc: 0.9667
Epoch: 109 loss: 0.5470 Train_acc: 0.9667
Epoch: 110 loss: 0.5466 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 111 loss: 0.5462 Train_acc: 0.9667
Epoch: 112 loss: 0.5458 Train_acc: 0.9667
Epoch: 113 loss: 0.5455 Train_acc: 0.9667
Epoch: 114 loss: 0.5451 Train_acc: 0.9667
Epoch: 115 loss: 0.5448 Train_acc: 0.9667
Epoch: 116 loss: 0.5444 Train_acc: 0.9667
Epoch: 117 loss: 0.5441 Train_acc: 0.9667
Epoch: 118 loss: 0.5438 Train_acc: 0.9667
Epoch: 119 loss: 0.5435 Train_acc: 0.9667
Epoch: 120 loss: 0.5432 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 121 loss: 0.5429 Train_acc: 0.9667
Epoch: 122 loss: 0.5426 Train_acc: 0.9667
Epoch: 123 loss: 0.5423 Train_acc: 0.9667
Epoch: 124 loss: 0.5421 Train_acc: 0.9667
Epoch: 125 loss: 0.5418 Train_acc: 0.9667
Epoch: 126 loss: 0.5416 Train_acc: 0.9667
Epoch: 127 loss: 0.5413 Train_acc: 0.9667
Epoch: 128 loss: 0.5411 Train_acc: 0.9667
Epoch: 129 loss: 0.5408 Train_acc: 0.9667
Epoch: 130 loss: 0.5406 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 131 loss: 0.5404 Train_acc: 0.9667
Epoch: 132 loss: 0.5402 Train_acc: 0.9667
Epoch: 133 loss: 0.5400 Train_acc: 0.9667
Epoch: 134 loss: 0.5398 Train_acc: 0.9667
Epoch: 135 loss: 0.5395 Train_acc: 0.9667
Epoch: 136 loss: 0.5393 Train_acc: 0.9667
Epoch: 137 loss: 0.5392 Train_acc: 0.9667
Epoch: 138 loss: 0.5390 Train_acc: 0.9667
Epoch: 139 loss: 0.5388 Train_acc: 0.9667
Epoch: 140 loss: 0.5386 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 141 loss: 0.5384 Train_acc: 0.9667
Epoch: 142 loss: 0.5383 Train_acc: 0.9667
Epoch: 143 loss: 0.5381 Train_acc: 0.9667
Epoch: 144 loss: 0.5379 Train_acc: 0.9667
Epoch: 145 loss: 0.5378 Train_acc: 0.9667
Epoch: 146 loss: 0.5376 Train_acc: 0.9667
Epoch: 147 loss: 0.5374 Train_acc: 0.9667
Epoch: 148 loss: 0.5373 Train_acc: 0.9667
Epoch: 149 loss: 0.5371 Train_acc: 0.9667
Epoch: 150 loss: 0.5370 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 151 loss: 0.5369 Train_acc: 0.9667
Epoch: 152 loss: 0.5367 Train_acc: 0.9667
Epoch: 153 loss: 0.5366 Train_acc: 0.9667
Epoch: 154 loss: 0.5364 Train_acc: 0.9667
Epoch: 155 loss: 0.5363 Train_acc: 0.9667
Epoch: 156 loss: 0.5362 Train_acc: 0.9667
Epoch: 157 loss: 0.5361 Train_acc: 0.9667
Epoch: 158 loss: 0.5359 Train_acc: 0.9667
Epoch: 159 loss: 0.5358 Train_acc: 0.9667
Epoch: 160 loss: 0.5357 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 161 loss: 0.5356 Train_acc: 0.9667
Epoch: 162 loss: 0.5355 Train_acc: 0.9667
Epoch: 163 loss: 0.5354 Train_acc: 0.9667
Epoch: 164 loss: 0.5352 Train_acc: 0.9667
Epoch: 165 loss: 0.5351 Train_acc: 0.9667
Epoch: 166 loss: 0.5350 Train_acc: 0.9667
Epoch: 167 loss: 0.5349 Train_acc: 0.9667
Epoch: 168 loss: 0.5348 Train_acc: 0.9667
Epoch: 169 loss: 0.5347 Train_acc: 0.9667
Epoch: 170 loss: 0.5346 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 171 loss: 0.5345 Train_acc: 0.9667
Epoch: 172 loss: 0.5344 Train_acc: 0.9667
Epoch: 173 loss: 0.5343 Train_acc: 0.9667
Epoch: 174 loss: 0.5342 Train_acc: 0.9667
Epoch: 175 loss: 0.5341 Train_acc: 0.9667
Epoch: 176 loss: 0.5341 Train_acc: 0.9667
Epoch: 177 loss: 0.5340 Train_acc: 0.9667
Epoch: 178 loss: 0.5339 Train_acc: 0.9667
Epoch: 179 loss: 0.5338 Train_acc: 0.9667
Epoch: 180 loss: 0.5337 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 181 loss: 0.5336 Train_acc: 0.9667
Epoch: 182 loss: 0.5335 Train_acc: 0.9667
Epoch: 183 loss: 0.5335 Train_acc: 0.9667
Epoch: 184 loss: 0.5334 Train_acc: 0.9667
Epoch: 185 loss: 0.5333 Train_acc: 0.9667
Epoch: 186 loss: 0.5332 Train_acc: 0.9667
Epoch: 187 loss: 0.5332 Train_acc: 0.9667
Epoch: 188 loss: 0.5331 Train_acc: 0.9667
Epoch: 189 loss: 0.5330 Train_acc: 0.9667
Epoch: 190 loss: 0.5329 Train_acc: 0.9667
Test_acc: 1.0000
Epoch: 191 loss: 0.5329 Train_acc: 0.9667
Epoch: 192 loss: 0.5328 Train_acc: 0.9667
Epoch: 193 loss: 0.5327 Train_acc: 0.9667
Epoch: 194 loss: 0.5327 Train_acc: 0.9667
Epoch: 195 loss: 0.5326 Train_acc: 0.9667
Epoch: 196 loss: 0.5325 Train_acc: 0.9667
Epoch: 197 loss: 0.5325 Train_acc: 0.9667
Epoch: 198 loss: 0.5324 Train_acc: 0.9667
Epoch: 199 loss: 0.5323 Train_acc: 0.9667
Epoch: 200 loss: 0.5323 Train_acc: 0.9667
Test_acc: 1.0000
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span> In [ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="sccnn_train.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Train a SCCNN</p>
      </div>
    </a>
    <a class="right-next"
       href="scn2_train.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Train a Simplex Convolutional Network (SCN) of Rank 2</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Train a Simplicial 2-complex convolutional neural network (SCConv)</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Pre-processing">Pre-processing</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Import-dataset">Import dataset</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Define-Neighbourhood-Structures">Define Neighbourhood Structures</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Import-signal">Import signal</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Define-binary-labels">Define binary labels</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Create-the-Neural-Network">Create the Neural Network</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Train-the-Neural-Network">Train the Neural Network</a></li>
</ul>

  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../../_sources/notebooks/simplicial/scconv_train.ipynb.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      Â© Copyright 2022-2023, PyT-Team, Inc..
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.2.6.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.2.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>