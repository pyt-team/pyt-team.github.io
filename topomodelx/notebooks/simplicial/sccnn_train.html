
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Train a SCCNN &#8212; TopoModelX latest documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css?v=2aa19091" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=c6e86fd7"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=5ae071a5"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/simplicial/sccnn_train';</script>
    <link rel="canonical" href="https://pyt-team.github.io/topomodelx/notebooks/simplicial/sccnn_train.html" />
    <link rel="icon" href="../../_static/favicon-48.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Train a Simplicial 2-complex convolutional neural network (SCConv)" href="scconv_train.html" />
    <link rel="prev" title="Train a Simplicial Complex Convolutional Network (SCCN)" href="sccn_train.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="latest" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">TopoModelX latest documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contributing/index.html">
    Contributing
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../tutorials/index.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../challenge/index.html">
    ICML 2023 Topological Deep Learning Challenge
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pyt-team/TopoModelX" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contributing/index.html">
    Contributing
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../tutorials/index.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../challenge/index.html">
    ICML 2023 Topological Deep Learning Challenge
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pyt-team/TopoModelX" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../cell/can_train.html">Train a Cell Attention Network (CAN)</a></li>




<li class="toctree-l1"><a class="reference internal" href="../cell/ccxn_train.html">Train a Convolutional Cell Complex Network (CCXN)</a></li>





<li class="toctree-l1"><a class="reference internal" href="../cell/cwn_train.html">Train a CW Network (CWN)</a></li>




</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../hypergraph/allset_train.html">Train an All-Set TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/allset_transformer_train.html">Train an All-Set-Transformer TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/dhgcn_train.html">Train a DHGCN TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hmpnn_train.html">Train a Hypergraph Message Passing Neural Network (HMPNN)</a></li>


<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hnhn_train.html">Train a Hypergraph Networks with Hyperedge Neurons (HNHN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hypergat_train.html">Train a Hypergraph Neural Network</a></li>


<li class="toctree-l1"><a class="reference internal" href="../hypergraph/hypersage_train.html">Train a Hypersage TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unigcn_train.html">Train a UNIGCN TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unigcnii_train.html">Train a hypergraph neural network using UniGCNII layers</a></li>

<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unigin_train.html">Train a UNIGIN TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="../hypergraph/unisage_train.html">Train a Uni-sage TNN</a></li>



</ul>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="dist2cycle_train.html">Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)</a></li>




<li class="toctree-l1"><a class="reference internal" href="hsn_train.html">Train a Simplicial High-Skip Network (HSN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="san_train.html">Train a Simplicial Attention Network (SAN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="sca_cmps_train.html">Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)</a></li>



<li class="toctree-l1"><a class="reference internal" href="sccn_train.html">Train a Simplicial Complex Convolutional Network (SCCN)</a></li>



<li class="toctree-l1 current active"><a class="current reference internal" href="#">Train a SCCNN</a></li>





<li class="toctree-l1"><a class="reference internal" href="scconv_train.html">Train a Simplicial 2-complex convolutional neural network (SCConv)</a></li>




<li class="toctree-l1"><a class="reference internal" href="scn2_train.html">Train a Simplex Convolutional Network (SCN) of Rank 2</a></li>


<li class="toctree-l1"><a class="reference internal" href="scnn_train.html">Train a Simplicial Convolutional Neural Network (SCNN)</a></li>






<li class="toctree-l1"><a class="reference internal" href="scone_train.html">Train a Simplicial Complex Net (SCoNe)</a></li>






</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../tutorials/index.html" class="nav-link">Tutorials</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Train a SCCNN</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="Train-a-SCCNN">
<h1>Train a SCCNN<a class="headerlink" href="#Train-a-SCCNN" title="Link to this heading">#</a></h1>
<p>In this notebook, we will create and train a convolutional neural network in the simplicial complex domain, as proposed in the paper by <a class="reference external" href="https://arxiv.org/abs/2301.11163">Yang et. al : Convolutional Learning on Simplicial Complexes (2023)</a>.</p>
<section id="We-train-the-model-to-perform:">
<h2>We train the model to perform:<a class="headerlink" href="#We-train-the-model-to-perform:" title="Link to this heading">#</a></h2>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>1.  Complex classification using the shrec16 benchmark dataset.
2.  Node classification using the karate dataset
</pre></div>
</div>
<section id="Simplicial-Complex-Convolutional-Neural-Networks-[SCCNN]">
<h3>Simplicial Complex Convolutional Neural Networks [SCCNN]<a class="headerlink" href="#Simplicial-Complex-Convolutional-Neural-Networks-[SCCNN]" title="Link to this heading">#</a></h3>
<p>SCCNN extends the SCNN to the complex domain by accounting for inter-simplicial connections, i.e., contributions from simplices of adjacent orders.</p>
<p>For example, we consider SCCNN layers in an SC of order two. At layer <span class="math notranslate nohighlight">\(t\)</span>, given the inputs on nodes, edges and faces, <span class="math notranslate nohighlight">\(\mathbf{h}_{t}^0,\mathbf{h}_{t}^1\)</span> and <span class="math notranslate nohighlight">\(\mathbf{h}_{t}^2\)</span>, the SCCNN layer contains the following</p>
<div class="math notranslate nohighlight">
\[\mathbf{h}_{t+1}^1 = \sigma \bigg[ \mathbf{F}_{t,\downarrow} \mathbf{B}_{1}^\top \mathbf{h}_{t}^{0} + \mathbf{F}_{t} \mathbf{h}_t^1 + \mathbf{F}_{t,\uparrow} \mathbf{B}_{2}  \mathbf{h}_t^{2} \bigg]\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{F}_t\)</span> is the simplicial convolutional filter defined in the edge space, and <span class="math notranslate nohighlight">\(\mathbf{F}_{t,\downarrow}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{F}_{t,\uparrow}\)</span> are the convolutional filters based on, respectively, only the lower and upper Laplacians. They are given by</p>
<div class="math notranslate nohighlight">
\[\mathbf{F}_{t} = {\theta}_t + \sum_{p_d=1}^{P_d} {\theta}_{t,p_d} (\mathbf{L}_{\downarrow,1})^{p_d}  + \sum_{p_u=1}^{P_u} {\theta}_{t,p_u}  (\mathbf{L}_{\uparrow,1})^{p_u}\]</div>
<div class="math notranslate nohighlight">
\[\mathbf{F}_{t,\downarrow} = {\theta}_t + \sum_{p_d=1}^{P_d} {\theta}_{t,p_d} (\mathbf{L}_{\downarrow,1})^{p_d}
\text{ and }
\mathbf{F}_{t,\uparrow} = {\theta}_t + \sum_{p_u=1}^{P_u} {\theta}_{t,p_u}  (\mathbf{L}_{\uparrow,1})^{p_u}\]</div>
<p>Likewise, for the node output, we have</p>
<div class="math notranslate nohighlight">
\[\mathbf{h}_{t+1}^0 = \sigma \bigg[ \mathbf{F}_{t} \mathbf{h}_t^0 + \mathbf{F}_{t,\uparrow} \mathbf{B}_{1}  \mathbf{h}_t^{1} \bigg]\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{F}_t\)</span> and <span class="math notranslate nohighlight">\(\mathbf{F}_{t,\uparrow}\)</span> are two graph filters essentially.</p>
<p>For the face output, we have</p>
<div class="math notranslate nohighlight">
\[\mathbf{h}_{t+1}^2 = \sigma \bigg[ \mathbf{F}_{t} \mathbf{h}_{t}^{2}  + \mathbf{F}_{t,\downarrow} \mathbf{B}_{2}^\top  \mathbf{h}_t^{1} \bigg]\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{F}_t\)</span> and <span class="math notranslate nohighlight">\(\mathbf{F}_{t,\downarrow}\)</span> are two simplicial filters defined in the triangle (face) space.</p>
</section>
</section>
</section>
<section id="1.-Complex-Classification">
<h1>1. Complex Classification<a class="headerlink" href="#1.-Complex-Classification" title="Link to this heading">#</a></h1>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">toponetx</span> <span class="k">as</span> <span class="nn">tnx</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="kn">from</span> <span class="nn">topomodelx.nn.simplicial.sccnn</span> <span class="kn">import</span> <span class="n">SCCNN</span>
<span class="kn">from</span> <span class="nn">topomodelx.utils.sparse</span> <span class="kn">import</span> <span class="n">from_sparse</span>

<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
</pre></div></div>
</div>
<section id="Import-shrec-dataset">
<h2>Import shrec dataset<a class="headerlink" href="#Import-shrec-dataset" title="Link to this heading">#</a></h2>
<p>We must first lift our graph dataset into the simplicial complex domain.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">shrec</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tnx</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">shrec_16</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="s2">&quot;small&quot;</span><span class="p">)</span>
<span class="n">shrec</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">shrec</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">x_0s</span> <span class="o">=</span> <span class="n">shrec</span><span class="p">[</span><span class="s2">&quot;node_feat&quot;</span><span class="p">]</span>
<span class="n">x_1s</span> <span class="o">=</span> <span class="n">shrec</span><span class="p">[</span><span class="s2">&quot;edge_feat&quot;</span><span class="p">]</span>
<span class="n">x_2s</span> <span class="o">=</span> <span class="n">shrec</span><span class="p">[</span><span class="s2">&quot;face_feat&quot;</span><span class="p">]</span>

<span class="n">ys</span> <span class="o">=</span> <span class="n">shrec</span><span class="p">[</span><span class="s2">&quot;label&quot;</span><span class="p">]</span>
<span class="n">simplexes</span> <span class="o">=</span> <span class="n">shrec</span><span class="p">[</span><span class="s2">&quot;complexes&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Loading shrec 16 small dataset...

done!
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">in_channels_0</span> <span class="o">=</span> <span class="n">x_0s</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">in_channels_1</span> <span class="o">=</span> <span class="n">x_1s</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">in_channels_2</span> <span class="o">=</span> <span class="n">x_2s</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="n">in_channels_all</span> <span class="o">=</span> <span class="p">(</span><span class="n">in_channels_0</span><span class="p">,</span> <span class="n">in_channels_1</span><span class="p">,</span> <span class="n">in_channels_2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">in_channels_all</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(6, 10, 7)
</pre></div></div>
</div>
</section>
<section id="Define-Neighborhood-Strctures">
<h2>Define Neighborhood Strctures<a class="headerlink" href="#Define-Neighborhood-Strctures" title="Link to this heading">#</a></h2>
<p>Get incidence matrices <span class="math notranslate nohighlight">\(\mathbf{B}_1,\mathbf{B}_2\)</span> and Hodge Laplacians <span class="math notranslate nohighlight">\(\mathbf{L}_0, \mathbf{L}_1\)</span> and <span class="math notranslate nohighlight">\(\mathbf{L}_2\)</span>.</p>
<p>Note that the original paper considered the weighted versions of these operators. However, the current TOPONETX package does not provide such feature yet.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_rank</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># the order of the SC is two</span>
<span class="n">incidence_1_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">incidence_2_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">laplacian_0_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">laplacian_down_1_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">laplacian_up_1_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">laplacian_2_list</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">simplex</span> <span class="ow">in</span> <span class="n">simplexes</span><span class="p">:</span>
    <span class="n">incidence_1</span> <span class="o">=</span> <span class="n">simplex</span><span class="o">.</span><span class="n">incidence_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">incidence_2</span> <span class="o">=</span> <span class="n">simplex</span><span class="o">.</span><span class="n">incidence_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">laplacian_0</span> <span class="o">=</span> <span class="n">simplex</span><span class="o">.</span><span class="n">hodge_laplacian_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">laplacian_down_1</span> <span class="o">=</span> <span class="n">simplex</span><span class="o">.</span><span class="n">down_laplacian_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">laplacian_up_1</span> <span class="o">=</span> <span class="n">simplex</span><span class="o">.</span><span class="n">up_laplacian_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">laplacian_2</span> <span class="o">=</span> <span class="n">simplex</span><span class="o">.</span><span class="n">hodge_laplacian_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">incidence_1</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">incidence_1</span><span class="p">)</span>
    <span class="n">incidence_2</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">incidence_2</span><span class="p">)</span>
    <span class="n">laplacian_0</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">laplacian_0</span><span class="p">)</span>
    <span class="n">laplacian_down_1</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">laplacian_down_1</span><span class="p">)</span>
    <span class="n">laplacian_up_1</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">laplacian_up_1</span><span class="p">)</span>
    <span class="n">laplacian_2</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">laplacian_2</span><span class="p">)</span>

    <span class="n">incidence_1_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">incidence_1</span><span class="p">)</span>
    <span class="n">incidence_2_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">incidence_2</span><span class="p">)</span>
    <span class="n">laplacian_0_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">laplacian_0</span><span class="p">)</span>
    <span class="n">laplacian_down_1_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">laplacian_down_1</span><span class="p">)</span>
    <span class="n">laplacian_up_1_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">laplacian_up_1</span><span class="p">)</span>
    <span class="n">laplacian_2_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">laplacian_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
<section id="Create-and-Train-the-Neural-Network">
<h1>Create and Train the Neural Network<a class="headerlink" href="#Create-and-Train-the-Neural-Network" title="Link to this heading">#</a></h1>
<p>We specify the model with our pre-made neighborhood structures and specify an optimizer.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_channels_all</span><span class="p">,</span>
        <span class="n">hidden_channels_all</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="p">,</span>
        <span class="n">conv_order</span><span class="p">,</span>
        <span class="n">max_rank</span><span class="p">,</span>
        <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">SCCNN</span><span class="p">(</span>
            <span class="n">in_channels_all</span><span class="o">=</span><span class="n">in_channels_all</span><span class="p">,</span>
            <span class="n">hidden_channels_all</span><span class="o">=</span><span class="n">hidden_channels_all</span><span class="p">,</span>
            <span class="n">conv_order</span><span class="o">=</span><span class="n">conv_order</span><span class="p">,</span>
            <span class="n">sc_order</span><span class="o">=</span><span class="n">max_rank</span><span class="p">,</span>
            <span class="n">n_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">out_channels_0</span><span class="p">,</span> <span class="n">out_channels_1</span><span class="p">,</span> <span class="n">out_channels_2</span> <span class="o">=</span> <span class="n">hidden_channels_all</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_linear_0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">out_channels_0</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_linear_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">out_channels_1</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_linear_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">out_channels_2</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_all</span><span class="p">,</span> <span class="n">laplacian_all</span><span class="p">,</span> <span class="n">incidence_all</span><span class="p">):</span>
        <span class="n">x_all</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">(</span><span class="n">x_all</span><span class="p">,</span> <span class="n">laplacian_all</span><span class="p">,</span> <span class="n">incidence_all</span><span class="p">)</span>
        <span class="n">x_0</span><span class="p">,</span> <span class="n">x_1</span><span class="p">,</span> <span class="n">x_2</span> <span class="o">=</span> <span class="n">x_all</span>

        <span class="n">x_0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_linear_0</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>
        <span class="n">x_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_linear_1</span><span class="p">(</span><span class="n">x_1</span><span class="p">)</span>
        <span class="n">x_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_linear_2</span><span class="p">(</span><span class="n">x_2</span><span class="p">)</span>

        <span class="c1"># Take the average of the 2D, 1D, and 0D cell features. If they are NaN, convert them to 0.</span>
        <span class="n">two_dimensional_cells_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">x_2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">two_dimensional_cells_mean</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">two_dimensional_cells_mean</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">one_dimensional_cells_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">x_1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">one_dimensional_cells_mean</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">one_dimensional_cells_mean</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">zero_dimensional_cells_mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">zero_dimensional_cells_mean</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">zero_dimensional_cells_mean</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="c1"># Return the sum of the averages</span>
        <span class="k">return</span> <span class="p">(</span>
            <span class="n">two_dimensional_cells_mean</span>
            <span class="o">+</span> <span class="n">one_dimensional_cells_mean</span>
            <span class="o">+</span> <span class="n">zero_dimensional_cells_mean</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">conv_order</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">intermediate_channels_all</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># num classes</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span>
    <span class="n">in_channels_all</span><span class="o">=</span><span class="n">in_channels_all</span><span class="p">,</span>
    <span class="n">hidden_channels_all</span><span class="o">=</span><span class="n">intermediate_channels_all</span><span class="p">,</span>
    <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
    <span class="n">conv_order</span><span class="o">=</span><span class="n">conv_order</span><span class="p">,</span>
    <span class="n">max_rank</span><span class="o">=</span><span class="n">max_rank</span><span class="p">,</span>
    <span class="n">n_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">(</span><span class="n">size_average</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Network(
  (base_model): SCCNN(
    (in_linear_0): Linear(in_features=6, out_features=16, bias=True)
    (in_linear_1): Linear(in_features=10, out_features=16, bias=True)
    (in_linear_2): Linear(in_features=7, out_features=16, bias=True)
    (layers): ModuleList(
      (0-1): 2 x SCCNNLayer()
    )
  )
  (out_linear_0): Linear(in_features=16, out_features=1, bias=True)
  (out_linear_1): Linear(in_features=16, out_features=1, bias=True)
  (out_linear_2): Linear(in_features=16, out_features=1, bias=True)
)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/Users/gbg141/Documents/TopoProjectX/TopoModelX/venv_modelx/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction=&#39;mean&#39; instead.
  warnings.warn(warning.format(ret))
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">x_0_train</span><span class="p">,</span> <span class="n">x_0_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x_0s</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">x_1_train</span><span class="p">,</span> <span class="n">x_1_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x_1s</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">x_2_train</span><span class="p">,</span> <span class="n">x_2_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x_2s</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">incidence_1_train</span><span class="p">,</span> <span class="n">incidence_1_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">incidence_1_list</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">incidence_2_train</span><span class="p">,</span> <span class="n">incidence_2_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">incidence_2_list</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">laplacian_0_train</span><span class="p">,</span> <span class="n">laplacian_0_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">laplacian_0_list</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">laplacian_down_1_train</span><span class="p">,</span> <span class="n">laplacian_down_1_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">laplacian_down_1_list</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">laplacian_up_1_train</span><span class="p">,</span> <span class="n">laplacian_up_1_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">laplacian_up_1_list</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>
<span class="n">laplacian_2_train</span><span class="p">,</span> <span class="n">laplacian_2_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">laplacian_2_list</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">ys</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>We train the SCCNN using low amount of epochs: we keep training minimal for the purpose of rapid testing.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_interval</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="k">for</span> <span class="p">(</span>
        <span class="n">x_0</span><span class="p">,</span>
        <span class="n">x_1</span><span class="p">,</span>
        <span class="n">x_2</span><span class="p">,</span>
        <span class="n">incidence_1</span><span class="p">,</span>
        <span class="n">incidence_2</span><span class="p">,</span>
        <span class="n">laplacian_0</span><span class="p">,</span>
        <span class="n">laplacian_down_1</span><span class="p">,</span>
        <span class="n">laplacian_up_1</span><span class="p">,</span>
        <span class="n">laplacian_2</span><span class="p">,</span>
        <span class="n">y</span><span class="p">,</span>
    <span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
        <span class="n">x_0_train</span><span class="p">,</span>
        <span class="n">x_1_train</span><span class="p">,</span>
        <span class="n">x_2_train</span><span class="p">,</span>
        <span class="n">incidence_1_train</span><span class="p">,</span>
        <span class="n">incidence_2_train</span><span class="p">,</span>
        <span class="n">laplacian_0_train</span><span class="p">,</span>
        <span class="n">laplacian_down_1_train</span><span class="p">,</span>
        <span class="n">laplacian_up_1_train</span><span class="p">,</span>
        <span class="n">laplacian_2_train</span><span class="p">,</span>
        <span class="n">y_train</span><span class="p">,</span>
        <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>
        <span class="n">x_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_1</span><span class="p">)</span>
        <span class="n">x_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_2</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">x_all</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_0</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">x_1</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">x_2</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
        <span class="n">laplacian_all</span> <span class="o">=</span> <span class="p">(</span><span class="n">laplacian_0</span><span class="p">,</span> <span class="n">laplacian_down_1</span><span class="p">,</span> <span class="n">laplacian_up_1</span><span class="p">,</span> <span class="n">laplacian_2</span><span class="p">)</span>
        <span class="n">incidence_all</span> <span class="o">=</span> <span class="p">(</span><span class="n">incidence_1</span><span class="p">,</span> <span class="n">incidence_2</span><span class="p">)</span>

        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_all</span><span class="p">,</span> <span class="n">laplacian_all</span><span class="p">,</span> <span class="n">incidence_all</span><span class="p">)</span>

        <span class="c1"># print(y_hat)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="n">epoch_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch_i</span><span class="si">}</span><span class="s2"> loss: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">epoch_i</span> <span class="o">%</span> <span class="n">test_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="p">(</span>
                <span class="n">x_0</span><span class="p">,</span>
                <span class="n">x_1</span><span class="p">,</span>
                <span class="n">x_2</span><span class="p">,</span>
                <span class="n">incidence_1</span><span class="p">,</span>
                <span class="n">incidence_2</span><span class="p">,</span>
                <span class="n">laplacian_0</span><span class="p">,</span>
                <span class="n">laplacian_down_1</span><span class="p">,</span>
                <span class="n">laplacian_up_1</span><span class="p">,</span>
                <span class="n">laplacian_2</span><span class="p">,</span>
                <span class="n">y</span><span class="p">,</span>
            <span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">x_0_test</span><span class="p">,</span>
                <span class="n">x_1_test</span><span class="p">,</span>
                <span class="n">x_2_test</span><span class="p">,</span>
                <span class="n">incidence_1_test</span><span class="p">,</span>
                <span class="n">incidence_2_test</span><span class="p">,</span>
                <span class="n">laplacian_0_test</span><span class="p">,</span>
                <span class="n">laplacian_down_1_test</span><span class="p">,</span>
                <span class="n">laplacian_up_1_test</span><span class="p">,</span>
                <span class="n">laplacian_2_test</span><span class="p">,</span>
                <span class="n">y_test</span><span class="p">,</span>
                <span class="n">strict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">):</span>
                <span class="n">x_0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>
                <span class="n">x_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_1</span><span class="p">)</span>
                <span class="n">x_2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_2</span><span class="p">)</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">x_all</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_0</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">x_1</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">x_2</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
                <span class="n">laplacian_all</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">laplacian_0</span><span class="p">,</span>
                    <span class="n">laplacian_down_1</span><span class="p">,</span>
                    <span class="n">laplacian_up_1</span><span class="p">,</span>
                    <span class="n">laplacian_2</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">incidence_all</span> <span class="o">=</span> <span class="p">(</span><span class="n">incidence_1</span><span class="p">,</span> <span class="n">incidence_2</span><span class="p">)</span>

                <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_all</span><span class="p">,</span> <span class="n">laplacian_all</span><span class="p">,</span> <span class="n">incidence_all</span><span class="p">)</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test_loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/Users/gbg141/Documents/TopoProjectX/TopoModelX/venv_modelx/lib/python3.11/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch: 1 loss: 399008.0930
Test_loss: 926.6080
Epoch: 2 loss: 477.8325
Test_loss: 204.4115
Epoch: 3 loss: 299.4982
Test_loss: 243.1712
Epoch: 4 loss: 202.5915
Test_loss: 302.4839
Epoch: 5 loss: 147.9002
Test_loss: 311.9497
</pre></div></div>
</div>
</section>
<section id="2.-Node-Classification">
<h1>2. Node Classification<a class="headerlink" href="#2.-Node-Classification" title="Link to this heading">#</a></h1>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
</pre></div></div>
</div>
</section>
<section id="Pre-processing">
<h1>Pre-processing<a class="headerlink" href="#Pre-processing" title="Link to this heading">#</a></h1>
<p>The first step is to import the Karate Club (<a class="reference external" href="https://www.jstor.org/stable/3629752">https://www.jstor.org/stable/3629752</a>) dataset. This is a singular graph with 34 nodes that belong to two different social groups. We will use these groups for the task of node-level binary classification.</p>
<p>We must first lift our graph dataset into the simplicial complex domain.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">tnx</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">karate_club</span><span class="p">(</span><span class="n">complex_type</span><span class="o">=</span><span class="s2">&quot;simplicial&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">max_rank</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">dim</span>
<span class="nb">print</span><span class="p">(</span><span class="n">max_rank</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Simplicial Complex with shape (34, 78, 45, 11, 2) and dimension 4
4
</pre></div></div>
</div>
<section id="id1">
<h2>Define Neighborhood Strctures<a class="headerlink" href="#id1" title="Link to this heading">#</a></h2>
<p>Get incidence matrices <span class="math notranslate nohighlight">\(\mathbf{B}_1,\mathbf{B}_2\)</span> and Hodge Laplacians <span class="math notranslate nohighlight">\(\mathbf{L}_0, \mathbf{L}_1\)</span> and <span class="math notranslate nohighlight">\(\mathbf{L}_2\)</span>.</p>
<p>Note that the original paper considered the weighted versions of these operators. However, the current TOPONETX package does not provide such feature yet.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">incidence_1</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">incidence_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">incidence_2</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">incidence_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The incidence matrix B1 has shape: </span><span class="si">{</span><span class="n">incidence_1</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The incidence matrix B2 has shape: </span><span class="si">{</span><span class="n">incidence_2</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
The incidence matrix B1 has shape: (34, 78).
The incidence matrix B2 has shape: (78, 45).
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">laplacian_0</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">hodge_laplacian_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">laplacian_down_1</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">down_laplacian_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">laplacian_up_1</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">up_laplacian_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">laplacian_down_2</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">down_laplacian_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">laplacian_up_2</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">up_laplacian_matrix</span><span class="p">(</span><span class="n">rank</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">laplacian_0</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">laplacian_0</span><span class="p">)</span>
<span class="n">laplacian_down_1</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">laplacian_down_1</span><span class="p">)</span>
<span class="n">laplacian_up_1</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">laplacian_up_1</span><span class="p">)</span>
<span class="n">laplacian_down_2</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">laplacian_down_2</span><span class="p">)</span>
<span class="n">laplacian_up_2</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">laplacian_up_2</span><span class="p">)</span>

<span class="n">incidence_1</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">incidence_1</span><span class="p">)</span>
<span class="n">incidence_2</span> <span class="o">=</span> <span class="n">from_sparse</span><span class="p">(</span><span class="n">incidence_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<section id="Import-signal">
<h3>Import signal<a class="headerlink" href="#Import-signal" title="Link to this heading">#</a></h3>
<p>We retrieve an input signal on the nodes, edges and faces. The signal will have shape <span class="math notranslate nohighlight">\(n_\text{simplicial} \times\)</span> in_channels, where in_channels is the dimension of each simplicials feature. Here, we have in_channels = channels_nodes $ = 2$.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;A function to obtain features based on the input: rank</span>
<span class="sd">&quot;&quot;&quot;</span>


<span class="k">def</span> <span class="nf">get_simplicial_features</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">rank</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">which_feat</span> <span class="o">=</span> <span class="s2">&quot;node_feat&quot;</span>
    <span class="k">elif</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">which_feat</span> <span class="o">=</span> <span class="s2">&quot;edge_feat&quot;</span>
    <span class="k">elif</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">which_feat</span> <span class="o">=</span> <span class="s2">&quot;face_feat&quot;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;input dimension must be 0, 1 or 2, because features are supported on nodes, edges and faces&quot;</span>
        <span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">get_simplex_attributes</span><span class="p">(</span><span class="n">which_feat</span><span class="p">)</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_0</span> <span class="o">=</span> <span class="n">get_simplicial_features</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">x_1</span> <span class="o">=</span> <span class="n">get_simplicial_features</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x_2</span> <span class="o">=</span> <span class="n">get_simplicial_features</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> nodes with features of dimension </span><span class="si">{</span><span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> edges with features of dimension </span><span class="si">{</span><span class="n">x_1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;There are </span><span class="si">{</span><span class="n">x_2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> faces with features of dimension </span><span class="si">{</span><span class="n">x_2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
There are 34 nodes with features of dimension 2.
There are 78 edges with features of dimension 2.
There are 45 faces with features of dimension 2.
</pre></div></div>
</div>
</section>
<section id="Define-binary-labels">
<h3>Define binary labels<a class="headerlink" href="#Define-binary-labels" title="Link to this heading">#</a></h3>
<p>We retrieve the labels associated to the nodes of each input simplex. In the KarateClub dataset, two social groups emerge. So we assign binary labels to the nodes indicating of which group they are a part.</p>
<p>We convert the binary labels into one-hot encoder form, and keep the first four nodes true labels for the purpose of testing.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[34]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">1</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
        <span class="mi">0</span><span class="p">,</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">34</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">y_true</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span>
<span class="n">y_true</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">y</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[:</span><span class="mi">30</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y_true</span><span class="p">[</span><span class="o">-</span><span class="mi">4</span><span class="p">:]</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
</section>
</section>
<section id="id2">
<h1>Create and Train the Neural Network<a class="headerlink" href="#id2" title="Link to this heading">#</a></h1>
<p>We specify the model with our pre-made neighborhood structures and specify an optimizer.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[45]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_channels_all</span><span class="p">,</span>
        <span class="n">hidden_channels_all</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="p">,</span>
        <span class="n">conv_order</span><span class="p">,</span>
        <span class="n">max_rank</span><span class="p">,</span>
        <span class="n">update_func</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_layers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">SCCNN</span><span class="p">(</span>
            <span class="n">in_channels_all</span><span class="o">=</span><span class="n">in_channels_all</span><span class="p">,</span>
            <span class="n">hidden_channels_all</span><span class="o">=</span><span class="n">hidden_channels_all</span><span class="p">,</span>
            <span class="n">conv_order</span><span class="o">=</span><span class="n">conv_order</span><span class="p">,</span>
            <span class="n">sc_order</span><span class="o">=</span><span class="n">max_rank</span><span class="p">,</span>
            <span class="n">update_func</span><span class="o">=</span><span class="n">update_func</span><span class="p">,</span>
            <span class="n">n_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">out_channels_0</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">hidden_channels_all</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_linear_0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">out_channels_0</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_all</span><span class="p">,</span> <span class="n">laplacian_all</span><span class="p">,</span> <span class="n">incidence_all</span><span class="p">):</span>
        <span class="n">x_all</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">(</span><span class="n">x_all</span><span class="p">,</span> <span class="n">laplacian_all</span><span class="p">,</span> <span class="n">incidence_all</span><span class="p">)</span>
        <span class="n">x_0</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">x_all</span>

<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        We pass the output on the nodes to a linear layer and use that to generate a probability label for nodes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x_0</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">x_all</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_linear_0</span><span class="p">(</span><span class="n">x_0</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[46]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;Obtain the initial features on all simplices&quot;&quot;&quot;</span>
<span class="n">x_all</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">x_1</span><span class="p">,</span> <span class="n">x_2</span><span class="p">)</span>

<span class="n">conv_order</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">in_channels_all</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_0</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">x_1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">x_2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">intermediate_channels_all</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># num classes</span>

<span class="n">laplacian_all</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">laplacian_0</span><span class="p">,</span>
    <span class="n">laplacian_down_1</span><span class="p">,</span>
    <span class="n">laplacian_up_1</span><span class="p">,</span>
    <span class="n">laplacian_down_2</span><span class="p">,</span>
    <span class="n">laplacian_up_2</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">incidence_all</span> <span class="o">=</span> <span class="p">(</span><span class="n">incidence_1</span><span class="p">,</span> <span class="n">incidence_2</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span>
    <span class="n">in_channels_all</span><span class="o">=</span><span class="n">in_channels_all</span><span class="p">,</span>
    <span class="n">hidden_channels_all</span><span class="o">=</span><span class="n">intermediate_channels_all</span><span class="p">,</span>
    <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
    <span class="n">conv_order</span><span class="o">=</span><span class="n">conv_order</span><span class="p">,</span>
    <span class="n">max_rank</span><span class="o">=</span><span class="n">max_rank</span><span class="p">,</span>
    <span class="n">update_func</span><span class="o">=</span><span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
    <span class="n">n_layers</span><span class="o">=</span><span class="n">num_layers</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[47]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_interval</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">epoch_loss</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_all</span><span class="p">,</span> <span class="n">laplacian_all</span><span class="p">,</span> <span class="n">incidence_all</span><span class="p">)</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">(</span>
        <span class="n">y_hat</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)]</span><span class="o">.</span><span class="n">float</span><span class="p">(),</span> <span class="n">y_train</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">epoch_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">y_hat</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_pred</span><span class="p">[:</span> <span class="nb">len</span><span class="p">(</span><span class="n">y_train</span><span class="p">)]</span> <span class="o">==</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch_i</span><span class="si">}</span><span class="s2"> loss: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2"> Train_acc: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">epoch_i</span> <span class="o">%</span> <span class="n">test_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">y_hat_test</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_all</span><span class="p">,</span> <span class="n">laplacian_all</span><span class="p">,</span> <span class="n">incidence_all</span><span class="p">)</span>
            <span class="c1"># Projection to node-level</span>
            <span class="n">y_hat_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">y_hat_test</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">y_pred_test</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                <span class="n">y_hat_test</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">test_accuracy</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y_pred_test</span><span class="p">[</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span> <span class="p">:],</span> <span class="n">y_test</span><span class="p">)</span>
                <span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="o">.</span><span class="n">float</span><span class="p">()</span>
                <span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                <span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Test_acc: </span><span class="si">{</span><span class="n">test_accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch: 1 loss: 0.6788 Train_acc: 0.4667
Epoch: 2 loss: 0.6248 Train_acc: 0.8000
Epoch: 3 loss: 0.6677 Train_acc: 0.7667
Epoch: 4 loss: 0.5903 Train_acc: 0.8000
Epoch: 5 loss: 0.5934 Train_acc: 0.8000
Epoch: 6 loss: 0.5666 Train_acc: 0.8000
Epoch: 7 loss: 0.5496 Train_acc: 0.8000
Epoch: 8 loss: 0.5381 Train_acc: 0.8000
Epoch: 9 loss: 0.5306 Train_acc: 0.8000
Epoch: 10 loss: 0.5257 Train_acc: 0.8000
Test_acc: 0.5000
Epoch: 11 loss: 0.5223 Train_acc: 0.8000
Epoch: 12 loss: 0.5198 Train_acc: 0.8000
Epoch: 13 loss: 0.5182 Train_acc: 0.8000
Epoch: 14 loss: 0.5170 Train_acc: 0.8000
Epoch: 15 loss: 0.5162 Train_acc: 0.8000
Epoch: 16 loss: 0.5156 Train_acc: 0.8000
Epoch: 17 loss: 0.5151 Train_acc: 0.8000
Epoch: 18 loss: 0.5147 Train_acc: 0.8000
Epoch: 19 loss: 0.5144 Train_acc: 0.8000
Epoch: 20 loss: 0.5142 Train_acc: 0.8000
Test_acc: 0.5000
Epoch: 21 loss: 0.5140 Train_acc: 0.8000
Epoch: 22 loss: 0.5139 Train_acc: 0.8000
Epoch: 23 loss: 0.5138 Train_acc: 0.8000
Epoch: 24 loss: 0.5137 Train_acc: 0.8000
Epoch: 25 loss: 0.5136 Train_acc: 0.8000
Epoch: 26 loss: 0.5135 Train_acc: 0.8000
Epoch: 27 loss: 0.5135 Train_acc: 0.8000
Epoch: 28 loss: 0.5134 Train_acc: 0.8000
Epoch: 29 loss: 0.5134 Train_acc: 0.8000
Epoch: 30 loss: 0.5133 Train_acc: 0.8000
Test_acc: 0.5000
Epoch: 31 loss: 0.5133 Train_acc: 0.8000
Epoch: 32 loss: 0.5133 Train_acc: 0.8000
Epoch: 33 loss: 0.5132 Train_acc: 0.8000
Epoch: 34 loss: 0.5132 Train_acc: 0.8000
Epoch: 35 loss: 0.5132 Train_acc: 0.8000
Epoch: 36 loss: 0.5132 Train_acc: 0.8000
Epoch: 37 loss: 0.5131 Train_acc: 0.8000
Epoch: 38 loss: 0.5131 Train_acc: 0.8000
Epoch: 39 loss: 0.5131 Train_acc: 0.8000
Epoch: 40 loss: 0.5131 Train_acc: 0.8000
Test_acc: 0.5000
Epoch: 41 loss: 0.5130 Train_acc: 0.8000
Epoch: 42 loss: 0.5130 Train_acc: 0.8000
Epoch: 43 loss: 0.5130 Train_acc: 0.8000
Epoch: 44 loss: 0.5130 Train_acc: 0.8000
Epoch: 45 loss: 0.5129 Train_acc: 0.8000
Epoch: 46 loss: 0.5129 Train_acc: 0.8000
Epoch: 47 loss: 0.5129 Train_acc: 0.8000
Epoch: 48 loss: 0.5128 Train_acc: 0.8000
Epoch: 49 loss: 0.5128 Train_acc: 0.8000
Epoch: 50 loss: 0.5128 Train_acc: 0.8000
Test_acc: 0.5000
Epoch: 51 loss: 0.5127 Train_acc: 0.8000
Epoch: 52 loss: 0.5127 Train_acc: 0.8000
Epoch: 53 loss: 0.5126 Train_acc: 0.8000
Epoch: 54 loss: 0.5126 Train_acc: 0.8000
Epoch: 55 loss: 0.5125 Train_acc: 0.8000
Epoch: 56 loss: 0.5124 Train_acc: 0.8000
Epoch: 57 loss: 0.5124 Train_acc: 0.8000
Epoch: 58 loss: 0.5123 Train_acc: 0.8000
Epoch: 59 loss: 0.5122 Train_acc: 0.8000
Epoch: 60 loss: 0.5121 Train_acc: 0.8000
Test_acc: 0.5000
Epoch: 61 loss: 0.5120 Train_acc: 0.8000
Epoch: 62 loss: 0.5119 Train_acc: 0.8000
Epoch: 63 loss: 0.5118 Train_acc: 0.8000
Epoch: 64 loss: 0.5116 Train_acc: 0.8000
Epoch: 65 loss: 0.5115 Train_acc: 0.8000
Epoch: 66 loss: 0.5113 Train_acc: 0.8000
Epoch: 67 loss: 0.5111 Train_acc: 0.8000
Epoch: 68 loss: 0.5109 Train_acc: 0.8000
Epoch: 69 loss: 0.5107 Train_acc: 0.8000
Epoch: 70 loss: 0.5105 Train_acc: 0.8000
Test_acc: 0.5000
Epoch: 71 loss: 0.5103 Train_acc: 0.8000
Epoch: 72 loss: 0.5101 Train_acc: 0.8000
Epoch: 73 loss: 0.5099 Train_acc: 0.8000
Epoch: 74 loss: 0.5098 Train_acc: 0.8000
Epoch: 75 loss: 0.5096 Train_acc: 0.8000
Epoch: 76 loss: 0.5094 Train_acc: 0.8000
Epoch: 77 loss: 0.5092 Train_acc: 0.8000
Epoch: 78 loss: 0.5089 Train_acc: 0.8000
Epoch: 79 loss: 0.5085 Train_acc: 0.8000
Epoch: 80 loss: 0.5082 Train_acc: 0.8000
Test_acc: 0.5000
Epoch: 81 loss: 0.5078 Train_acc: 0.8000
Epoch: 82 loss: 0.5075 Train_acc: 0.8000
Epoch: 83 loss: 0.5071 Train_acc: 0.8000
Epoch: 84 loss: 0.5068 Train_acc: 0.8000
Epoch: 85 loss: 0.5064 Train_acc: 0.8000
Epoch: 86 loss: 0.5060 Train_acc: 0.8000
Epoch: 87 loss: 0.5056 Train_acc: 0.8000
Epoch: 88 loss: 0.5051 Train_acc: 0.8000
Epoch: 89 loss: 0.5046 Train_acc: 0.8000
Epoch: 90 loss: 0.5041 Train_acc: 0.8000
Test_acc: 0.5000
Epoch: 91 loss: 0.5037 Train_acc: 0.8000
Epoch: 92 loss: 0.5032 Train_acc: 0.8000
Epoch: 93 loss: 0.5027 Train_acc: 0.8000
Epoch: 94 loss: 0.5022 Train_acc: 0.8000
Epoch: 95 loss: 0.5016 Train_acc: 0.8000
Epoch: 96 loss: 0.5011 Train_acc: 0.8000
Epoch: 97 loss: 0.5005 Train_acc: 0.8000
Epoch: 98 loss: 0.5000 Train_acc: 0.8000
Epoch: 99 loss: 0.4994 Train_acc: 0.8000
Epoch: 100 loss: 0.4989 Train_acc: 0.8000
Test_acc: 0.5000
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="sccn_train.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Train a Simplicial Complex Convolutional Network (SCCN)</p>
      </div>
    </a>
    <a class="right-next"
       href="scconv_train.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Train a Simplicial 2-complex convolutional neural network (SCConv)</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Train a SCCNN</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#We-train-the-model-to-perform:">We train the model to perform:</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Simplicial-Complex-Convolutional-Neural-Networks-[SCCNN]">Simplicial Complex Convolutional Neural Networks [SCCNN]</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#1.-Complex-Classification">1. Complex Classification</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Import-shrec-dataset">Import shrec dataset</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Define-Neighborhood-Strctures">Define Neighborhood Strctures</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Create-and-Train-the-Neural-Network">Create and Train the Neural Network</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#2.-Node-Classification">2. Node Classification</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Pre-processing">Pre-processing</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Define Neighborhood Strctures</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Import-signal">Import signal</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#Define-binary-labels">Define binary labels</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Create and Train the Neural Network</a></li>
</ul>

  </nav></div>

  <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/pyt-team/TopoModelX/edit/main/docs/notebooks/simplicial/sccnn_train.ipynb">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
       Copyright 2022-2023, PyT-Team, Inc..
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>