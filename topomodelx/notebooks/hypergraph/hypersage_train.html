
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Train a Hypersage TNN &#8212; TopoModelX latest documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../../_static/nbsphinx-code-cells.css?v=2aa19091" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=c6e86fd7"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=5ae071a5"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/hypergraph/hypersage_train';</script>
    <link rel="canonical" href="https://pyt-team.github.io/topomodelx/notebooks/hypergraph/hypersage_train.html" />
    <link rel="icon" href="../../_static/favicon-48.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Train a UNIGCN TNN" href="unigcn_train.html" />
    <link rel="prev" title="Train a Hypergraph Neural Network" href="hypergat_train.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="latest" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class="col-lg-3 navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">TopoModelX latest documentation</p>
  
</a></div>
    
  </div>
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contributing/index.html">
    Contributing
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../tutorials/index.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../challenge/index.html">
    ICML 2023 Topological Deep Learning Challenge
  </a>
</li>

  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
        </div>
      
      
        <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pyt-team/TopoModelX" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../api/index.html">
    API Reference
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../contributing/index.html">
    Contributing
  </a>
</li>


<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../../tutorials/index.html">
    Tutorials
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../challenge/index.html">
    ICML 2023 Topological Deep Learning Challenge
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/pyt-team/TopoModelX" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../cell/can_train.html">Train a Cell Attention Network (CAN)</a></li>




<li class="toctree-l1"><a class="reference internal" href="../cell/ccxn_train.html">Train a Convolutional Cell Complex Network (CCXN)</a></li>





<li class="toctree-l1"><a class="reference internal" href="../cell/cwn_train.html">Train a CW Network (CWN)</a></li>




</ul>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="allset_train.html">Train an All-Set TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="allset_transformer_train.html">Train an All-Set-Transformer TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="dhgcn_train.html">Train a DHGCN TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="hmpnn_train.html">Train a Hypergraph Message Passing Neural Network (HMPNN)</a></li>


<li class="toctree-l1"><a class="reference internal" href="hnhn_train.html">Train a Hypergraph Networks with Hyperedge Neurons (HNHN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="hypergat_train.html">Train a Hypergraph Neural Network</a></li>


<li class="toctree-l1 current active"><a class="current reference internal" href="#">Train a Hypersage TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="unigcn_train.html">Train a UNIGCN TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="unigcnii_train.html">Train a hypergraph neural network using UniGCNII layers</a></li>

<li class="toctree-l1"><a class="reference internal" href="unigin_train.html">Train a UNIGIN TNN</a></li>



<li class="toctree-l1"><a class="reference internal" href="unisage_train.html">Train a Uni-sage TNN</a></li>



</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../simplicial/dist2cycle_train.html">Train a Simplicial Neural Network for Homology Localization (Dist2Cycle)</a></li>




<li class="toctree-l1"><a class="reference internal" href="../simplicial/hsn_train.html">Train a Simplicial High-Skip Network (HSN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="../simplicial/san_train.html">Train a Simplicial Attention Network (SAN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="../simplicial/sca_cmps_train.html">Train a Simplicial Complex Autoencoder (SCA) with Coadjacency Message Passing Scheme (CMPS)</a></li>



<li class="toctree-l1"><a class="reference internal" href="../simplicial/sccn_train.html">Train a Simplicial Complex Convolutional Network (SCCN)</a></li>



<li class="toctree-l1"><a class="reference internal" href="../simplicial/sccnn_train.html">Train a SCCNN</a></li>





<li class="toctree-l1"><a class="reference internal" href="../simplicial/scconv_train.html">Train a Simplicial 2-complex convolutional neural network (SCConv)</a></li>




<li class="toctree-l1"><a class="reference internal" href="../simplicial/scn2_train.html">Train a Simplex Convolutional Network (SCN) of Rank 2</a></li>


<li class="toctree-l1"><a class="reference internal" href="../simplicial/scnn_train.html">Train a Simplicial Convolutional Neural Network (SCNN)</a></li>






<li class="toctree-l1"><a class="reference internal" href="../simplicial/scone_train.html">Train a Simplicial Complex Net (SCoNe)</a></li>






</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../tutorials/index.html" class="nav-link">Tutorials</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Train a Hypersage TNN</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="Train-a-Hypersage-TNN">
<h1>Train a Hypersage TNN<a class="headerlink" href="#Train-a-Hypersage-TNN" title="Link to this heading">#</a></h1>
<p>In this notebook, we will create and train HyperSAGE layer (Arya et al., <a class="reference external" href="https://arxiv.org/abs/2010.04558">2020</a>) - two-levels message passing strategy for hypergraphs learning. We will use a benchmark dataset, shrec16, a collection of 3D meshes, to train the model to perform classification at the level of the hypergraph.</p>
<p>Following the “awesome-tnns” <a class="reference external" href="https://github.com/awesome-tnns/awesome-tnns/blob/main/Hypergraphs.md">github repo.</a></p>
<p>🟥 <span class="math notranslate nohighlight">\(\quad m_{y \rightarrow z}^{(0 \rightarrow 1)} = (B_1)^T_{zy} \cdot w_y \cdot (h_y^{(0)})^p\)</span></p>
<p>🟥 <span class="math notranslate nohighlight">\(\quad m_z^{(0 \rightarrow 1)} = \left(\frac{1}{\vert \mathcal{B}(z)\vert}\sum_{y \in \mathcal{B}(z)} m_{y \rightarrow z}^{(0 \rightarrow 1)}\right)^{\frac{1}{p}}\)</span></p>
<p>🟥 <span class="math notranslate nohighlight">\(\quad m_{z \rightarrow x}^{(1 \rightarrow 0)} = (B_1)_{xz} \cdot w_z \cdot (m_z^{(0 \rightarrow 1)})^p\)</span></p>
<p>🟧 <span class="math notranslate nohighlight">\(\quad m_x^{(1 \rightarrow 0)} = \left(\frac{1}{\vert \mathcal{C}(x) \vert}\sum_{z \in \mathcal{C}(x)} m_{z \rightarrow x}^{(1 \rightarrow 0)}\right)^{\frac{1}{p}}\)</span></p>
<p>🟩 <span class="math notranslate nohighlight">\(\quad m_x^{(0)} = m_x^{(1 \rightarrow 0)}\)</span></p>
<p>🟦 <span class="math notranslate nohighlight">\(\quad h_x^{t+1, (0)} = \sigma \left(\frac{m_x^{(0)} + h_x^{t,(0)}}{\lvert m_x^{(0)} + h_x^{t,(0)}\rvert} \cdot \Theta^t\right)\)</span></p>
<section id="Additional-theoretical-clarifications">
<h2>Additional theoretical clarifications<a class="headerlink" href="#Additional-theoretical-clarifications" title="Link to this heading">#</a></h2>
<p>Arya et al propose to interpret the propagation of information in a given hypergraph as a two-level aggregation problem, where the neighborhood of any node is divided into intra-edge neighbors and inter-edge neighbors. Given a hypergraph <span class="math notranslate nohighlight">\(H=(\mathcal{V}, \mathcal{E})\)</span>, let <span class="math notranslate nohighlight">\(\textbf{X}\)</span> denote the feature matrix, such that <span class="math notranslate nohighlight">\(\textbf{x}_{i} \in \textbf{X}\)</span> is the feature set for node <span class="math notranslate nohighlight">\(\textbf{v}_{i} \in \textbf{V}\)</span> . For two-level aggregation, let <span class="math notranslate nohighlight">\(\mathcal{F}_{1}(·)\)</span>
and <span class="math notranslate nohighlight">\(\mathcal{F}_{2}(·)\)</span> denote the intra-edge and inter-edge aggregation functions, respectively. Message passing at node vi for aggregation of information at the <span class="math notranslate nohighlight">\(\mathcal{l}^{th}\)</span> layer can then be stated as</p>
<p>$ <span class="math">\mathcal{x}</span><em>{i,l}^{(e)} :nbsphinx-math:`leftarrow `:nbsphinx-math:`mathcal{F}`</em>{1}({ <span class="math">\mathcal{x}</span><em>{j,l-1} | :nbsphinx-math:`mathcal{v}`</em>{j} <span class="math">\in `:nbsphinx-math:</span>mathcal{N}`( <span class="math">\mathcal{v}</span>_{i}, <span class="math">\textbf{e}</span>,:nbsphinx-math:<cite>alpha</cite>) }), $</p>
<p>$ <span class="math">\mathcal{x}</span><em>{i,l} :nbsphinx-math:`leftarrow `:nbsphinx-math:`mathcal{x}`</em>{i,l-1} + <span class="math">\mathcal{F}</span><em>{2}({ :nbsphinx-math:`mathcal{x}`</em>{i,l}^{(e)} | <span class="math">\mathcal{v}</span><em>{i} :nbsphinx-math:`in {E}`( :nbsphinx-math:`mathcal{v}`</em>{i}) }), $</p>
<p>where, $ <span class="math">\mathcal{x}</span>_{i,l}^{(e)}$ refers to the aggregated feature set at <span class="math notranslate nohighlight">\(\mathcal{v}_{i}\)</span> obtained with intra-edge aggregation for edge <span class="math notranslate nohighlight">\(\textbf{e}\)</span>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">This module contains the HyperSAGE class for hypergraph-based neural networks.</span>

<span class="sd">The AllSet class implements a specific hypergraph-based neural network architecture</span>
<span class="sd">used for solving certain types of problems.</span>

<span class="sd">Author: Your Name</span>

<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch_geometric.datasets</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">geom_datasets</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch_geometric.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">to_undirected</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">topomodelx.nn.hypergraph.hypersage</span><span class="w"> </span><span class="kn">import</span> <span class="n">HyperSAGE</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>If GPU’s are available, we will make use of them. Otherwise, this will run on CPU.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
cuda
</pre></div></div>
</div>
</section>
</section>
<section id="Pre-processing">
<h1>Pre-processing<a class="headerlink" href="#Pre-processing" title="Link to this heading">#</a></h1>
<p>The first step is to import the dataset, Cora, a benchmark classification datase. We then lift the graph into our domain of choice, a hypergraph.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cora</span> <span class="o">=</span> <span class="n">geom_datasets</span><span class="o">.</span><span class="n">Planetoid</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s2">&quot;tmp/&quot;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;cora&quot;</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">cora</span><span class="o">.</span><span class="n">data</span>

<span class="n">x_0s</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">x</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">y</span>
<span class="n">edge_index</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span>

<span class="n">train_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">train_mask</span>
<span class="n">val_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">val_mask</span>
<span class="n">test_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">test_mask</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/usr/local/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an &#39;InMemoryDataset&#39;. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
</pre></div></div>
</div>
<p>Now we retrieve the neighborhood structure (i.e. their representative matrice) that we will use to send messges from node to hyperedges. In the case of this architecture, we need the boundary matrix (or incidence matrix) <span class="math notranslate nohighlight">\(B_1\)</span> with shape <span class="math notranslate nohighlight">\(n_\text{nodes} \times n_\text{edges}\)</span>.</p>
<p>In citation Cora dataset we lift graph structure to the hypergraph domain by creating hyperedges from 1-hop graph neighbourhood of each node.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Ensure the graph is undirected (optional but often useful for one-hop neighborhoods).</span>
<span class="n">edge_index</span> <span class="o">=</span> <span class="n">to_undirected</span><span class="p">(</span><span class="n">edge_index</span><span class="p">)</span>

<span class="c1"># Create a list of one-hop neighborhoods for each node.</span>
<span class="n">one_hop_neighborhoods</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">num_nodes</span><span class="p">):</span>
    <span class="c1"># Get the one-hop neighbors of the current node.</span>
    <span class="n">neighbors</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">node</span><span class="p">]</span>

    <span class="c1"># Append the neighbors to the list of one-hop neighborhoods.</span>
    <span class="n">one_hop_neighborhoods</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">neighbors</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

<span class="c1"># Detect and eliminate duplicate hyperedges.</span>
<span class="n">unique_hyperedges</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="n">hyperedges</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">neighborhood</span> <span class="ow">in</span> <span class="n">one_hop_neighborhoods</span><span class="p">:</span>
    <span class="c1"># Sort the neighborhood to ensure consistent comparison.</span>
    <span class="n">neighborhood</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">neighborhood</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">neighborhood</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">unique_hyperedges</span><span class="p">:</span>
        <span class="n">hyperedges</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">neighborhood</span><span class="p">))</span>
        <span class="n">unique_hyperedges</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">neighborhood</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Additionally we print the statictis associated with obtained incidence matrix</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate hyperedge statistics.</span>
<span class="n">hyperedge_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">he</span><span class="p">)</span> <span class="k">for</span> <span class="n">he</span> <span class="ow">in</span> <span class="n">hyperedges</span><span class="p">]</span>
<span class="n">min_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">hyperedge_sizes</span><span class="p">)</span>
<span class="n">max_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">hyperedge_sizes</span><span class="p">)</span>
<span class="n">mean_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">hyperedge_sizes</span><span class="p">)</span>
<span class="n">median_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">hyperedge_sizes</span><span class="p">)</span>
<span class="n">std_size</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">hyperedge_sizes</span><span class="p">)</span>
<span class="n">num_single_node_hyperedges</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">hyperedge_sizes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Print the hyperedge statistics.</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Hyperedge statistics: &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of hyperedges without duplicated hyperedges&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">hyperedges</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;min = </span><span class="si">{</span><span class="n">min_size</span><span class="si">}</span><span class="s2">, &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;max = </span><span class="si">{</span><span class="n">max_size</span><span class="si">}</span><span class="s2">, &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mean = </span><span class="si">{</span><span class="n">mean_size</span><span class="si">}</span><span class="s2">, &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;median = </span><span class="si">{</span><span class="n">median_size</span><span class="si">}</span><span class="s2">, &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;std = </span><span class="si">{</span><span class="n">std_size</span><span class="si">}</span><span class="s2">, &quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Number of hyperedges with size equal to one = </span><span class="si">{</span><span class="n">num_single_node_hyperedges</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Hyperedge statistics:
Number of hyperedges without duplicated hyperedges 2581
min = 1,
max = 168,
mean = 4.003099573808601,
median = 3.0,
std = 5.327622607829558,
Number of hyperedges with size equal to one = 412
</pre></div></div>
</div>
<p>Construct incidence matrix</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">max_edges</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">hyperedges</span><span class="p">)</span>
<span class="n">incidence_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">x_0s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">max_edges</span><span class="p">))</span>
<span class="k">for</span> <span class="n">col</span><span class="p">,</span> <span class="n">neighibourhood</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hyperedges</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">neighibourhood</span><span class="p">:</span>
        <span class="n">incidence_1</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">incidence_1</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;Some hyperedges are empty&quot;</span>
<span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">incidence_1</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;Some nodes are not in any hyperedges&quot;</span>
<span class="n">incidence_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">incidence_1</span><span class="p">)</span><span class="o">.</span><span class="n">to_sparse_coo</span><span class="p">()</span>
</pre></div>
</div>
</div>
</section>
<section id="Create-the-Neural-Network">
<h1>Create the Neural Network<a class="headerlink" href="#Create-the-Neural-Network" title="Link to this heading">#</a></h1>
<p>Define the network that initializes the base model and sets up the readout operation. Different downstream tasks might require different pooling procedures.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">Network</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Network class that initializes the base model and readout layer.</span>

<span class="sd">    Base model parameters:</span>
<span class="sd">    ----------</span>
<span class="sd">    Reqired:</span>
<span class="sd">    in_channels : int</span>
<span class="sd">        Dimension of the input features.</span>
<span class="sd">    hidden_channels : int</span>
<span class="sd">        Dimension of the hidden features.</span>

<span class="sd">    Optitional:</span>
<span class="sd">    **kwargs : dict</span>
<span class="sd">        Additional arguments for the base model.</span>

<span class="sd">    Readout layer parameters:</span>
<span class="sd">    ----------</span>
<span class="sd">    out_channels : int</span>
<span class="sd">        Dimension of the output features.</span>
<span class="sd">    task_level : str</span>
<span class="sd">        Level of the task. Either &quot;graph&quot; or &quot;node&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">task_level</span><span class="o">=</span><span class="s2">&quot;graph&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Define the model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span> <span class="o">=</span> <span class="n">HyperSAGE</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="o">=</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>

        <span class="c1"># Readout</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_pool</span> <span class="o">=</span> <span class="n">task_level</span> <span class="o">==</span> <span class="s2">&quot;graph&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_0</span><span class="p">,</span> <span class="n">incidence_1</span><span class="p">):</span>
        <span class="c1"># Base model</span>
        <span class="n">x_0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_model</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">incidence_1</span><span class="p">)</span>

        <span class="c1"># Pool over all nodes in the hypergraph</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x_0</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_pool</span> <span class="ow">is</span> <span class="kc">True</span> <span class="k">else</span> <span class="n">x_0</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Initialize the model</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Base model hyperparameters</span>
<span class="n">in_channels</span> <span class="o">=</span> <span class="n">x_0s</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">hidden_channels</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">n_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">mlp_num_layers</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Readout hyperparameters</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">task_level</span> <span class="o">=</span> <span class="s2">&quot;graph&quot;</span> <span class="k">if</span> <span class="n">out_channels</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="s2">&quot;node&quot;</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">Network</span><span class="p">(</span>
    <span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
    <span class="n">hidden_channels</span><span class="o">=</span><span class="n">hidden_channels</span><span class="p">,</span>
    <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
    <span class="n">n_layers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
    <span class="n">task_level</span><span class="o">=</span><span class="n">task_level</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Train-the-Neural-Network">
<h1>Train the Neural Network<a class="headerlink" href="#Train-the-Neural-Network" title="Link to this heading">#</a></h1>
<p>We specify the model, the loss, and an optimizer.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Optimizer and loss</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># Categorial cross-entropy loss</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>


<span class="c1"># Accuracy</span>
<span class="k">def</span><span class="w"> </span><span class="nf">acc_fn</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="n">y_hat</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_0s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_0s</span><span class="p">)</span>
<span class="n">x_0s</span><span class="p">,</span> <span class="n">incidence_1</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">x_0s</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
    <span class="n">incidence_1</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/tmp/ipykernel_33450/1422611997.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x_0s = torch.tensor(x_0s)
/tmp/ipykernel_33450/1422611997.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(y, dtype=torch.long).to(device),
</pre></div></div>
</div>
<p>The following cell performs the training, looping over the network for a low amount of epochs. We keep training minimal for the purpose of rapid testing.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_0s</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_0s</span><span class="p">)</span>
<span class="n">x_0s</span><span class="p">,</span> <span class="n">incidence_1</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">x_0s</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
    <span class="n">incidence_1</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/tmp/ipykernel_33450/1422611997.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x_0s = torch.tensor(x_0s)
/tmp/ipykernel_33450/1422611997.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(y, dtype=torch.long).to(device),
</pre></div></div>
</div>
<p><strong>Note: The number of epochs below have been kept low to facilitate debugging and testing. Real use cases should likely require more epochs.</strong></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">test_interval</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">5</span>

<span class="n">epoch_loss</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="c1"># Extract edge_index from sparse incidence matrix</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_0s</span><span class="p">,</span> <span class="n">incidence_1</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">[</span><span class="n">train_mask</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train_mask</span><span class="p">])</span>

    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">epoch_loss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="k">if</span> <span class="n">epoch_i</span> <span class="o">%</span> <span class="n">test_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_0s</span><span class="p">,</span> <span class="n">incidence_1</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">[</span><span class="n">train_mask</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train_mask</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch: </span><span class="si">{</span><span class="n">epoch_i</span><span class="si">}</span><span class="s2"> &quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Train_loss: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">epoch_loss</span><span class="p">)</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, acc: </span><span class="si">{</span><span class="n">acc_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">[</span><span class="n">train_mask</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">train_mask</span><span class="p">])</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">[</span><span class="n">val_mask</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">val_mask</span><span class="p">])</span>

        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Val_loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Val_acc: </span><span class="si">{</span><span class="n">acc_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">[</span><span class="n">val_mask</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">val_mask</span><span class="p">])</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">[</span><span class="n">test_mask</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_mask</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Test_loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Test_acc: </span><span class="si">{</span><span class="n">acc_fn</span><span class="p">(</span><span class="n">y_hat</span><span class="p">[</span><span class="n">test_mask</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">y</span><span class="p">[</span><span class="n">test_mask</span><span class="p">])</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">flush</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch: 5
Train_loss: 1.9424, acc: 0.5929
Val_loss: 1.9401, Val_acc: 0.2460
Test_loss: 1.9405, Test_acc: 0.2620
Epoch: 10
Train_loss: 1.9305, acc: 0.9357
Val_loss: 1.9221, Val_acc: 0.5680
Test_loss: 1.9220, Test_acc: 0.5580
Epoch: 15
Train_loss: 1.9105, acc: 0.9714
Val_loss: 1.8899, Val_acc: 0.6560
Test_loss: 1.8904, Test_acc: 0.6490
Epoch: 20
Train_loss: 1.8811, acc: 0.9786
Val_loss: 1.8450, Val_acc: 0.7260
Test_loss: 1.8466, Test_acc: 0.6990
Epoch: 25
Train_loss: 1.8412, acc: 0.9929
Val_loss: 1.7831, Val_acc: 0.7360
Test_loss: 1.7857, Test_acc: 0.7210
Epoch: 30
Train_loss: 1.7905, acc: 1.0000
Val_loss: 1.7067, Val_acc: 0.7420
Test_loss: 1.7103, Test_acc: 0.7220
</pre></div></div>
</div>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="hypergat_train.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Train a Hypergraph Neural Network</p>
      </div>
    </a>
    <a class="right-next"
       href="unigcn_train.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Train a UNIGCN TNN</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Train a Hypersage TNN</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#Additional-theoretical-clarifications">Additional theoretical clarifications</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Pre-processing">Pre-processing</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Create-the-Neural-Network">Create the Neural Network</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#Train-the-Neural-Network">Train the Neural Network</a></li>
</ul>

  </nav></div>

  <div class="sidebar-secondary-item">

  
  <div class="tocsection editthispage">
    <a href="https://github.com/pyt-team/TopoModelX/edit/main/docs/notebooks/hypergraph/hypersage_train.ipynb">
      <i class="fa-solid fa-pencil"></i>
      
      
        
          Edit on GitHub
        
      
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      © Copyright 2022-2023, PyT-Team, Inc..
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 8.1.3.
    <br/>
  </p>
</div>
      
    </div>
  
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  <!-- # L10n: Setting the PST URL as an argument as this does not need to be localized -->
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.16.1.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>